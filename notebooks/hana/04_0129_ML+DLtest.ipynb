{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95622927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 + 머신러닝 모델로 시도...\n",
    "# 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 데이터 경로\n",
    "BASE_DIR = Path.cwd().parent.parent\n",
    "DATA_DIR = BASE_DIR / 'data:raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90a6dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test_x.csv')\n",
    "\n",
    "# 타겟 설정 인코딩\n",
    "TARGET = 'voted'\n",
    "train_df[TARGET] = train_df['voted'].map({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "894c2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 핵심 파생변수 생성\n",
    "def create_features(df):\n",
    "    '''\n",
    "    설문 응답 기반 행동/태도 파생변수 생성 함수\n",
    "\n",
    "    - 실제 존재하는 컬럼만 사용하여 KeyError 방지\n",
    "    - train / test 동일 로직 적용 (데이터 누수 방지)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "\n",
    "# 태도 / 도덕 성향 점수\n",
    "    cynicism_items = ['Qc', 'Qh', 'Qj', 'Qm', 'Qo', 'Qs']\n",
    "    morality_items = ['Qf', 'Qk', 'Qr']\n",
    "    kindness_items = ['Qq']\n",
    "\n",
    "    cynicism_cols = [col for col in df.columns if col in cynicism_items]\n",
    "    morality_cols = [col for col in df.columns if col in morality_items]\n",
    "    kindness_cols = [col for col in df.columns if col in kindness_items]\n",
    "\n",
    "    if len(cynicism_cols) > 0:\n",
    "        df['cynicism_score'] = df[cynicism_cols].mean(axis=1)\n",
    "\n",
    "    if len(morality_cols) > 0:\n",
    "        df['morality_score'] = df[morality_cols].mean(axis=1)\n",
    "\n",
    "    if len(kindness_cols) > 0:\n",
    "        df['kindness_score'] = df[kindness_cols].mean(axis=1)\n",
    "\n",
    "    # 응답 시간 기반 '성실성' 지표\n",
    "    time_cols = [col for col in df.columns if col.startswith('Q_E')]\n",
    "\n",
    "    if len(time_cols) > 0:\n",
    "        df['mean_response_time'] = df[time_cols].mean(axis=1)\n",
    "        df['std_response_time'] = df[time_cols].std(axis=1)\n",
    "        df['long_response_ratio'] = (\n",
    "            df[time_cols] \n",
    "            > df[time_cols].mean(axis=1).values.reshape(-1, 1)\n",
    "        ). mean(axis=1)\n",
    "\n",
    "    # 언어/인지 수준 proxy\n",
    "    wr_cols = [col for col in df.columns if col.startswith('wr_')]\n",
    "    wf_cols = [col for col in df.columns if col.startswith('wf_')]\n",
    "\n",
    "    if len(wr_cols) > 0:\n",
    "        df['real_word_ratio'] = (\n",
    "            df[wr_cols].sum(axis=1) \n",
    "            / (df[wr_cols + wf_cols].sum(axis=1) + 1e-6)\n",
    "        )\n",
    "         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "199f3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d7dfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 Feature 선택\n",
    "DROP_COLS = ['index', 'voted']\n",
    "FEATURES = [col for col in train_df.columns if col not in DROP_COLS]\n",
    "\n",
    "X = train_df[FEATURES]\n",
    "y = train_df['voted']\n",
    "X_test = test_df[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03187cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 전용 칼럼 \n",
    "lgb_cat_cols = ['age_group', 'gender', 'race', 'religion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65e24c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# 범주형 분리\n",
    "X_cat_train = train_df[lgb_cat_cols]\n",
    "X_cat_test = test_df[lgb_cat_cols]\n",
    "\n",
    "# 수치형 분리\n",
    "X_num_train = train_df.drop(columns=lgb_cat_cols + ['voted'])\n",
    "X_num_test = test_df.drop(columns=lgb_cat_cols)\n",
    "\n",
    "# 원핫인코딩\n",
    "X_cat_train_onehot = onehot.fit_transform(X_cat_train)\n",
    "X_cat_test_onehot = onehot.transform(X_cat_test)\n",
    "\n",
    "# 다시 병합\n",
    "X = np.hstack([X_num_train.values, X_cat_train_onehot])\n",
    "X_test = np.hstack([X_num_test.values, X_cat_test_onehot])\n",
    "\n",
    "y = train_df['voted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "080895d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': -1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    **lgb_params, \n",
    "    n_estimators=1200\n",
    ")\n",
    "\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "\n",
    "lgb_pred_train = lgb_model.predict_proba(X)[:, 1]\n",
    "lgb_pred_test = lgb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ac8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8368e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 학습\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_ds = TensorDataset(\n",
    "    torch.tensor(X_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True)\n",
    "\n",
    "device = 'cpu'\n",
    "model = MLP(X.shape[1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb).squeeze(), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08cdc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    dl_pred_train = torch.sigmoid(\n",
    "        model(torch.tensor(X_scaled, dtype=torch.float32).to(device))\n",
    "    ).cpu().numpy().ravel()\n",
    "\n",
    "    dl_pred_test = torch.sigmoid(\n",
    "        model(torch.tensor(X_test_scaled, dtype=torch.float32).to(device))\n",
    "    ).cpu().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c8fbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC 기준 가중 앙상블 (DL 비중 up)\n",
    "\n",
    "final_test_pred = 0.4 * lgb_pred_test + 0.6 * dl_pred_test\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': test_df.index,\n",
    "    'voted': final_test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submit_20260129_hana.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d023aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습용 데이콘 제출 점수 : 퍼블릭 - 0.7791\n",
    "# 머신러닝 + 딥러닝 모델 앙상블... 가능한가??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388879d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6f630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
