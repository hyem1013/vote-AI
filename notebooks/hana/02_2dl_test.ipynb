{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28125d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01660eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed 고정 함수\n",
    "'''\n",
    "[Why?]\n",
    "\n",
    "- 딥러닝은 초기 가중치, 배치 순서 등에 따라 매번 결과가 달라짐\n",
    "- Seed를 고정하면 '재현 가능한 실험' 가능\n",
    "- 이후 여러 Seed를 사용하면 서로 다른 관점의 모델 앙상블 가능\n",
    "'''\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f36a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "BASE_DIR = Path.cwd().parent.parent\n",
    "DATA_DIR = BASE_DIR / 'data:raw'\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a7f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 값 정리 (1, 2 -> 0, 1)\n",
    "TARGET = 'voted'\n",
    "train_df[TARGET] = train_df[TARGET] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11bcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature / Column 분리\n",
    "'''\n",
    "[칼럼 분리 이유]\n",
    "\n",
    "- target은 학습 입력에서 제거\n",
    "- 수치형 / 범주형 분리\n",
    " -> 딥러닝은 수치형 처리에 강점\n",
    " -> 범주형은 이번 baseline에서는 제외\n",
    "'''\n",
    "\n",
    "DROP_COLS = [TARGET]\n",
    "FEATURES = [col for col in train_df.columns if col not in DROP_COLS]\n",
    "\n",
    "NUM_COLS = train_df[FEATURES].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "CAT_COLS = train_df[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e02c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 (결측치 + 스케일링)\n",
    "'''\n",
    "[전처리 전략]\n",
    "\n",
    "1. 결측치 처리\n",
    "    - 수치형: median\n",
    "     -> 이상치에 강건\n",
    "\n",
    "2. 표준화(StandardScaler)\n",
    "    - 딥러닝은 feature scale에 민감\n",
    "    - 평균 0, 분산 1로 맞춤\n",
    "\n",
    "3. 범주형 칼럼 제거\n",
    "    - 현재는 NN baseline\n",
    "    - 이후 embedding으로 확장 가능\n",
    "'''\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 수치형 결측치 처리\n",
    "train_df[NUM_COLS] = num_imputer.fit_transform(train_df[NUM_COLS])\n",
    "test_df[NUM_COLS] = num_imputer.transform(test_df[NUM_COLS])\n",
    "\n",
    "# 스케일링\n",
    "train_df[NUM_COLS] = scaler.fit_transform(train_df[NUM_COLS])\n",
    "test_df[NUM_COLS] = scaler.transform(test_df[NUM_COLS])\n",
    "\n",
    "# 범주형 제거\n",
    "train_df = train_df[NUM_COLS + [TARGET]]\n",
    "test_df = test_df[NUM_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64685a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation 분리\n",
    "'''\n",
    "[Why?]\n",
    "\n",
    "- AUC는 threshold-independent metric\n",
    "- 학습 중 '일반화 성능'을 확인해야 함\n",
    "- strarify=y:\n",
    " -> 클래스 비율 유지 (불균형 방지)\n",
    "'''\n",
    "\n",
    "X = train_df.drop(columns=[TARGET]).values\n",
    "y = train_df[TARGET].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16e8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Dataset 정의\n",
    "'''\n",
    "[Dataset 역할]\n",
    "\n",
    "- numpy -> torch tensor 변환\n",
    "- DataLoader와 결합되어 mini-batch 학습 가능\n",
    "'''\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fc896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 정의 (AUC 최적화 구조)\n",
    "'''\n",
    "[모델 설계 의도]\n",
    "\n",
    "- 깊지 않지만 충분한 표현력\n",
    "- BatchNorm + Dropout\n",
    " -> 과적합 방지\n",
    "- 마지막 출력은 logit (sigmoid X)\n",
    " -> BCEWithLogitsLoss와 결합\n",
    "'''\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e896a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 Seed 학습 함수\n",
    "'''\n",
    "[핵심 함수]\n",
    "- 하나의 seed로 모델 학습\n",
    "- Validation AUC 기준으로 best model 저장\n",
    "- class imbalance -> pos_weight 적용\n",
    "'''\n",
    "\n",
    "def train_one_seed(seed):\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = MLP(X_train.shape[1])\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=1e-3\n",
    "    )\n",
    "\n",
    "# 클래스 불균형 보정\n",
    "    pos = y_train.sum()\n",
    "    neg = len(y_train) - pos\n",
    "    pos_weight = torch.tensor([neg / pos])\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=pos_weight\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "    TabularDataset(X_train, y_train),\n",
    "    batch_size=256,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "    TabularDataset(X_val, y_val),\n",
    "    batch_size=512,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "    best_auc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(30):\n",
    "    #--1.Train--\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # --2.Validataion--\n",
    "        model.eval()\n",
    "        preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                preds.extend(\n",
    "                    torch.sigmoid(model(xb)).cpu().numpy()\n",
    "                )\n",
    "\n",
    "        auc = roc_auc_score(y_val, preds)\n",
    "\n",
    "    # --3. Best model 저장--\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        print(f'[Seed {seed}] Epoch {epoch+1:02d} | Val AUC: {auc:.5f}')\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382b3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seed 0] Epoch 01 | Val AUC: 0.72318\n",
      "[Seed 0] Epoch 02 | Val AUC: 0.72940\n",
      "[Seed 0] Epoch 03 | Val AUC: 0.73244\n",
      "[Seed 0] Epoch 04 | Val AUC: 0.73418\n",
      "[Seed 0] Epoch 05 | Val AUC: 0.73691\n",
      "[Seed 0] Epoch 06 | Val AUC: 0.73710\n",
      "[Seed 0] Epoch 07 | Val AUC: 0.73632\n",
      "[Seed 0] Epoch 08 | Val AUC: 0.73693\n",
      "[Seed 0] Epoch 09 | Val AUC: 0.73866\n",
      "[Seed 0] Epoch 10 | Val AUC: 0.73809\n",
      "[Seed 0] Epoch 11 | Val AUC: 0.74041\n",
      "[Seed 0] Epoch 12 | Val AUC: 0.73856\n",
      "[Seed 0] Epoch 13 | Val AUC: 0.73798\n",
      "[Seed 0] Epoch 14 | Val AUC: 0.73774\n",
      "[Seed 0] Epoch 15 | Val AUC: 0.73777\n",
      "[Seed 0] Epoch 16 | Val AUC: 0.74106\n",
      "[Seed 0] Epoch 17 | Val AUC: 0.73793\n",
      "[Seed 0] Epoch 18 | Val AUC: 0.73966\n",
      "[Seed 0] Epoch 19 | Val AUC: 0.73793\n",
      "[Seed 0] Epoch 20 | Val AUC: 0.73954\n",
      "[Seed 0] Epoch 21 | Val AUC: 0.74040\n",
      "[Seed 0] Epoch 22 | Val AUC: 0.74007\n",
      "[Seed 0] Epoch 23 | Val AUC: 0.73895\n",
      "[Seed 0] Epoch 24 | Val AUC: 0.73889\n",
      "[Seed 0] Epoch 25 | Val AUC: 0.73686\n",
      "[Seed 0] Epoch 26 | Val AUC: 0.73731\n",
      "[Seed 0] Epoch 27 | Val AUC: 0.73792\n",
      "[Seed 0] Epoch 28 | Val AUC: 0.73748\n",
      "[Seed 0] Epoch 29 | Val AUC: 0.73642\n",
      "[Seed 0] Epoch 30 | Val AUC: 0.73762\n",
      "[Seed 1] Epoch 01 | Val AUC: 0.72458\n",
      "[Seed 1] Epoch 02 | Val AUC: 0.72912\n",
      "[Seed 1] Epoch 03 | Val AUC: 0.73203\n",
      "[Seed 1] Epoch 04 | Val AUC: 0.73389\n",
      "[Seed 1] Epoch 05 | Val AUC: 0.73284\n",
      "[Seed 1] Epoch 06 | Val AUC: 0.73619\n",
      "[Seed 1] Epoch 07 | Val AUC: 0.73607\n",
      "[Seed 1] Epoch 08 | Val AUC: 0.73561\n",
      "[Seed 1] Epoch 09 | Val AUC: 0.73822\n",
      "[Seed 1] Epoch 10 | Val AUC: 0.73846\n",
      "[Seed 1] Epoch 11 | Val AUC: 0.73866\n",
      "[Seed 1] Epoch 12 | Val AUC: 0.73967\n",
      "[Seed 1] Epoch 13 | Val AUC: 0.73853\n",
      "[Seed 1] Epoch 14 | Val AUC: 0.73986\n",
      "[Seed 1] Epoch 15 | Val AUC: 0.73886\n",
      "[Seed 1] Epoch 16 | Val AUC: 0.73960\n",
      "[Seed 1] Epoch 17 | Val AUC: 0.74020\n",
      "[Seed 1] Epoch 18 | Val AUC: 0.74015\n",
      "[Seed 1] Epoch 19 | Val AUC: 0.73901\n",
      "[Seed 1] Epoch 20 | Val AUC: 0.74061\n",
      "[Seed 1] Epoch 21 | Val AUC: 0.74002\n",
      "[Seed 1] Epoch 22 | Val AUC: 0.73952\n",
      "[Seed 1] Epoch 23 | Val AUC: 0.73633\n",
      "[Seed 1] Epoch 24 | Val AUC: 0.73924\n",
      "[Seed 1] Epoch 25 | Val AUC: 0.73637\n",
      "[Seed 1] Epoch 26 | Val AUC: 0.73783\n",
      "[Seed 1] Epoch 27 | Val AUC: 0.73890\n",
      "[Seed 1] Epoch 28 | Val AUC: 0.73743\n",
      "[Seed 1] Epoch 29 | Val AUC: 0.73683\n",
      "[Seed 1] Epoch 30 | Val AUC: 0.73389\n",
      "[Seed 2] Epoch 01 | Val AUC: 0.72541\n",
      "[Seed 2] Epoch 02 | Val AUC: 0.72920\n",
      "[Seed 2] Epoch 03 | Val AUC: 0.73024\n",
      "[Seed 2] Epoch 04 | Val AUC: 0.73326\n",
      "[Seed 2] Epoch 05 | Val AUC: 0.73430\n",
      "[Seed 2] Epoch 06 | Val AUC: 0.73571\n",
      "[Seed 2] Epoch 07 | Val AUC: 0.73724\n",
      "[Seed 2] Epoch 08 | Val AUC: 0.73639\n",
      "[Seed 2] Epoch 09 | Val AUC: 0.73689\n",
      "[Seed 2] Epoch 10 | Val AUC: 0.73672\n",
      "[Seed 2] Epoch 11 | Val AUC: 0.73830\n",
      "[Seed 2] Epoch 12 | Val AUC: 0.73911\n",
      "[Seed 2] Epoch 13 | Val AUC: 0.73796\n",
      "[Seed 2] Epoch 14 | Val AUC: 0.73865\n",
      "[Seed 2] Epoch 15 | Val AUC: 0.73773\n",
      "[Seed 2] Epoch 16 | Val AUC: 0.73928\n",
      "[Seed 2] Epoch 17 | Val AUC: 0.73821\n",
      "[Seed 2] Epoch 18 | Val AUC: 0.73874\n",
      "[Seed 2] Epoch 19 | Val AUC: 0.73741\n",
      "[Seed 2] Epoch 20 | Val AUC: 0.73756\n",
      "[Seed 2] Epoch 21 | Val AUC: 0.73852\n",
      "[Seed 2] Epoch 22 | Val AUC: 0.73786\n",
      "[Seed 2] Epoch 23 | Val AUC: 0.73519\n",
      "[Seed 2] Epoch 24 | Val AUC: 0.73677\n",
      "[Seed 2] Epoch 25 | Val AUC: 0.73742\n",
      "[Seed 2] Epoch 26 | Val AUC: 0.73577\n",
      "[Seed 2] Epoch 27 | Val AUC: 0.73726\n",
      "[Seed 2] Epoch 28 | Val AUC: 0.73652\n",
      "[Seed 2] Epoch 29 | Val AUC: 0.73432\n",
      "[Seed 2] Epoch 30 | Val AUC: 0.73591\n",
      "[Seed 3] Epoch 01 | Val AUC: 0.72421\n",
      "[Seed 3] Epoch 02 | Val AUC: 0.73031\n",
      "[Seed 3] Epoch 03 | Val AUC: 0.73380\n",
      "[Seed 3] Epoch 04 | Val AUC: 0.73481\n",
      "[Seed 3] Epoch 05 | Val AUC: 0.73536\n",
      "[Seed 3] Epoch 06 | Val AUC: 0.73568\n",
      "[Seed 3] Epoch 07 | Val AUC: 0.73738\n",
      "[Seed 3] Epoch 08 | Val AUC: 0.73702\n",
      "[Seed 3] Epoch 09 | Val AUC: 0.73716\n",
      "[Seed 3] Epoch 10 | Val AUC: 0.73846\n",
      "[Seed 3] Epoch 11 | Val AUC: 0.73778\n",
      "[Seed 3] Epoch 12 | Val AUC: 0.73838\n",
      "[Seed 3] Epoch 13 | Val AUC: 0.73808\n",
      "[Seed 3] Epoch 14 | Val AUC: 0.73823\n",
      "[Seed 3] Epoch 15 | Val AUC: 0.73808\n",
      "[Seed 3] Epoch 16 | Val AUC: 0.73756\n",
      "[Seed 3] Epoch 17 | Val AUC: 0.73953\n",
      "[Seed 3] Epoch 18 | Val AUC: 0.73827\n",
      "[Seed 3] Epoch 19 | Val AUC: 0.73836\n",
      "[Seed 3] Epoch 20 | Val AUC: 0.73825\n",
      "[Seed 3] Epoch 21 | Val AUC: 0.73913\n",
      "[Seed 3] Epoch 22 | Val AUC: 0.73845\n",
      "[Seed 3] Epoch 23 | Val AUC: 0.73654\n",
      "[Seed 3] Epoch 24 | Val AUC: 0.73795\n",
      "[Seed 3] Epoch 25 | Val AUC: 0.73687\n",
      "[Seed 3] Epoch 26 | Val AUC: 0.73784\n",
      "[Seed 3] Epoch 27 | Val AUC: 0.73713\n",
      "[Seed 3] Epoch 28 | Val AUC: 0.73683\n",
      "[Seed 3] Epoch 29 | Val AUC: 0.73612\n",
      "[Seed 3] Epoch 30 | Val AUC: 0.73831\n",
      "[Seed 4] Epoch 01 | Val AUC: 0.72567\n",
      "[Seed 4] Epoch 02 | Val AUC: 0.73045\n",
      "[Seed 4] Epoch 03 | Val AUC: 0.73312\n",
      "[Seed 4] Epoch 04 | Val AUC: 0.73580\n",
      "[Seed 4] Epoch 05 | Val AUC: 0.73669\n",
      "[Seed 4] Epoch 06 | Val AUC: 0.73653\n",
      "[Seed 4] Epoch 07 | Val AUC: 0.73757\n",
      "[Seed 4] Epoch 08 | Val AUC: 0.73891\n",
      "[Seed 4] Epoch 09 | Val AUC: 0.73918\n",
      "[Seed 4] Epoch 10 | Val AUC: 0.73983\n",
      "[Seed 4] Epoch 11 | Val AUC: 0.74125\n",
      "[Seed 4] Epoch 12 | Val AUC: 0.74001\n",
      "[Seed 4] Epoch 13 | Val AUC: 0.74021\n",
      "[Seed 4] Epoch 14 | Val AUC: 0.74028\n",
      "[Seed 4] Epoch 15 | Val AUC: 0.73866\n",
      "[Seed 4] Epoch 16 | Val AUC: 0.74108\n",
      "[Seed 4] Epoch 17 | Val AUC: 0.73860\n",
      "[Seed 4] Epoch 18 | Val AUC: 0.73892\n",
      "[Seed 4] Epoch 19 | Val AUC: 0.74082\n",
      "[Seed 4] Epoch 20 | Val AUC: 0.73901\n",
      "[Seed 4] Epoch 21 | Val AUC: 0.73919\n",
      "[Seed 4] Epoch 22 | Val AUC: 0.73816\n",
      "[Seed 4] Epoch 23 | Val AUC: 0.73876\n",
      "[Seed 4] Epoch 24 | Val AUC: 0.74047\n",
      "[Seed 4] Epoch 25 | Val AUC: 0.73920\n",
      "[Seed 4] Epoch 26 | Val AUC: 0.73753\n",
      "[Seed 4] Epoch 27 | Val AUC: 0.73722\n",
      "[Seed 4] Epoch 28 | Val AUC: 0.73899\n",
      "[Seed 4] Epoch 29 | Val AUC: 0.73752\n",
      "[Seed 4] Epoch 30 | Val AUC: 0.73865\n"
     ]
    }
   ],
   "source": [
    "# Seed 앙상블\n",
    "'''\n",
    "[Why?]\n",
    "- 같은 구조라도 seed가 다르면 서로 다른 decision boundary 학습\n",
    "- 확률 평균 -> 분산 감소\n",
    "- AUC 상승에 매우 효과적\n",
    "'''\n",
    "\n",
    "SEEDS = [0, 1, 2, 3, 4]\n",
    "test_loader = DataLoader(\n",
    "    TabularDataset(test_df.values),\n",
    "    batch_size=512\n",
    ")\n",
    "\n",
    "all_test_probs = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    model = train_one_seed(seed)\n",
    "    model.eval()\n",
    "\n",
    "    probs =[]\n",
    "    with torch.no_grad():\n",
    "        for xb in test_loader:\n",
    "            probs.extend(torch.sigmoid(model(xb)).cpu().numpy())\n",
    "\n",
    "    all_test_probs.append(np.array(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b06424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗️ submission.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "final_prob = np.mean(all_test_probs, axis=0)\n",
    "\n",
    "submission = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
    "\n",
    "submission['voted'] = final_prob\n",
    "\n",
    "submission.to_csv('submit_260128_hana03.csv', index=False)\n",
    "print('❗️ submission.csv 저장 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98f067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
