{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "목표\n",
        "- CPU 환경에서 가능한 한 **최고 점수**를 노리는 단일 노트북\n",
        "- 최종 제출은 딥러닝 모델(MLP/FT-Transformer) 예측만 사용\n",
        "\n",
        "전략\n",
        "\n",
        "3) 앙상블은 0.5 고정이 아니라 **OOF로 최적 가중치(0~1, 0.01 step)** + rank 평균까지 비교\n",
        "4) 저장은 submission_best.csv 하나만\n",
        "\n",
        "출력\n",
        "- submission_best.csv (index, voted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# CONFIG (CPU용 세팅)\n",
        "# =========================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "EPOCHS = 35        # 50 -> 35 (CPU 현실 타협)\n",
        "PATIENCE = 6       # 8 -> 6\n",
        "DEVICE = \"cpu\"     # ✅ CPU 강제\n",
        "\n",
        "# MLP/FT 학습률\n",
        "LR_MLP = 1e-3\n",
        "LR_FT  = 5e-4\n",
        "\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) 데이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (45532, 79) Test: (11383, 77)\n",
            "pos_ratio: 0.5468242115435298\n"
          ]
        }
      ],
      "source": [
        "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
        "test_raw  = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
        "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
        "\n",
        "print(\"Train:\", train_raw.shape, \"Test:\", test_raw.shape)\n",
        "print(\"pos_ratio:\", float(train_raw[\"voted_bin\"].mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 클리닝\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    for col in ['education', 'engnat', 'hand', 'married', 'urban']:\n",
        "        if col in df.columns:\n",
        "            df.loc[df[col] == 0, col] = np.nan\n",
        "\n",
        "\n",
        "    if 'familysize' in df.columns:\n",
        "        df.loc[df['familysize'] == 0, 'familysize'] = np.nan\n",
        "        df.loc[df['familysize'] > 15, 'familysize'] = np.nan\n",
        "\n",
        "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
        "        if col in df.columns:\n",
        "            df.loc[df[col] == 0, col] = np.nan\n",
        "\n",
        "    for col in [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].clip(lower=0, upper=60000)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "476e0604",
      "metadata": {},
      "source": [
        "\t•\teducation, engnat, hand, married, urban 에서은 실제 값이 아니라 “무응답” -> 그래서 0 → NaN으로 바꿈\n",
        "\n",
        "\t•\t가족 수가 0인 경우: 논리적으로 불가능\n",
        "\t•\t15명 초과: 극단적인 이상치로 판단\n",
        "\t•\t모두 NaN 처리하여 모델 학습 안정화\n",
        "\t\n",
        "\tfor col in tp01 ~ tp10:\t\t\t\t\t\t\t->평균, 차이(tp01 - tp06 등) 계산 시 왜곡 방지를 위해 제거\n",
        "    df.loc[df[col] == 0, col] = np.nan \n",
        "\n",
        "\tdf[col] = df[col].clip(lower=0, upper=60000)   -> 음수 응답 시간 제거, 과도하게 큰 값(60초 초과) 제한 응답 시간 평균·합·분산 피처가 상치 하나 때문에 망가지는 것을 방지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) 피처 엔지니어링\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_features(df):\n",
        "    df = df.copy()\n",
        "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
        "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
        "    df[\"is_teenager\"] = (df[\"age_ord\"] == 1).astype(int)\n",
        "    df[\"is_young\"] = (df[\"age_ord\"] <= 2).astype(int)\n",
        "    df[\"is_old\"] = (df[\"age_ord\"] >= 6).astype(int)\n",
        "    df[\"edu_low\"] = (df[\"education\"] <= 2).astype(float)\n",
        "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float)\n",
        "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float)\n",
        "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float)\n",
        "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float)\n",
        "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float)\n",
        "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(int)\n",
        "\n",
        "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
        "    df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
        "    df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
        "    df[\"qa_range\"] = df[qa_cols].max(axis=1) - df[qa_cols].min(axis=1)\n",
        "    df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / 20\n",
        "    df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / 20\n",
        "    df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(int)\n",
        "\n",
        "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
        "    for col in qe_cols:\n",
        "        df[f\"{col}_log\"] = np.log1p(df[col])\n",
        "    qe_log_cols = [f\"{col}_log\" for col in qe_cols]\n",
        "    df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
        "    df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
        "    df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / 20\n",
        "    df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
        "    df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df[\"qa_all_same\"] == 1)).astype(int)\n",
        "\n",
        "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
        "    df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / 10\n",
        "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
        "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
        "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
        "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
        "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
        "    df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
        "\n",
        "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
        "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
        "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
        "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
        "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
        "    df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(int)\n",
        "\n",
        "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
        "    df[\"young_low_edu\"] = df[\"is_young\"] * df[\"edu_low\"]\n",
        "    df[\"young_single\"] = df[\"is_young\"] * df[\"is_single\"]\n",
        "    df[\"old_married\"] = df[\"is_old\"] * df[\"is_married\"]\n",
        "    df[\"teenager_low_edu\"] = df[\"is_teenager\"] * df[\"edu_low\"]\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5568a71",
      "metadata": {},
      "source": [
        "1️. 인구통계 요약 (age / education / marital)\n",
        "\t•\t연령대를 순서형 숫자(age_ord) 로 변환\n",
        "\t•\t특정 그룹을 나타내는 이진 변수 생성\n",
        "\n",
        "age_ord, is_teenager, is_young, is_old\n",
        "edu_low / edu_high\n",
        "is_single / is_married\n",
        "is_urban, is_english_native, is_male\n",
        "\n",
        "2️. 설문 응답 태도 요약 (Q_A)\n",
        "\n",
        "20개 문항을 그대로 쓰지 않고 응답 스타일을 \n",
        "\n",
        "qa_mean        : 전반적으로 긍정/부정적인지\n",
        "qa_std         : 답변 일관성\n",
        "qa_range       : 답변 폭\n",
        "qa_extreme_ratio : 1·5 극단 선택 비율\n",
        "qa_neutral_ratio : 3(중립) 선택 비율\n",
        "qa_all_same    : 모든 문항을 동일하게 답했는지\n",
        "\n",
        "3️. 응답 시간 요약 (Q_E)\n",
        "\n",
        "qe_log_mean, qe_log_std\n",
        "qe_total_log\n",
        "qe_fast_ratio : 매우 빠른 응답 비율\n",
        "is_careless   : 너무 빠르거나 전부 같은 답변 여부\n",
        "\n",
        "4. 성격(Big5, tp) 요약\n",
        "\n",
        "extraversion, agreeableness, conscientiousness,\n",
        "neuroticism, openness\n",
        "tp_mean\n",
        "tp_missing_ratio\n",
        "\n",
        "5️. 단어 인지 / 응답 신뢰도 (wr / wf)\n",
        "wr_sum          : 실제 단어 인지 수\n",
        "wf_sum          : 가짜 단어 인지 수\n",
        "word_credibility: wr - wf\n",
        "vocab_high      : 어휘 인지 수준이 높은지\n",
        "\n",
        "6. 상호작용 피처 (Interaction)\n",
        "age_edu\n",
        "young_low_edu\n",
        "young_single\n",
        "old_married\n",
        "teenager_low_edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Target Encoding (fold-safe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def target_encode(train_df, val_df, test_df, col, target_col, smoothing=10):\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    agg = train_df.groupby(col)[target_col].agg(['mean', 'count'])\n",
        "    agg['te'] = (agg['count'] * agg['mean'] + smoothing * global_mean) / (agg['count'] + smoothing)\n",
        "    te_map = agg['te'].to_dict()\n",
        "    return (train_df[col].map(te_map).fillna(global_mean).values,\n",
        "            val_df[col].map(te_map).fillna(global_mean).values,\n",
        "            test_df[col].map(te_map).fillna(global_mean).values)\n",
        "\n",
        "def create_target_encodings(train_df, val_df, test_df, target_col=\"voted_bin\"):\n",
        "    te = {'train': {}, 'val': {}, 'test': {}}\n",
        "    for col in ['age_group', 'race', 'religion']:\n",
        "        tr, va, te_ = target_encode(train_df, val_df, test_df, col, target_col, 10)\n",
        "        te['train'][f'{col}_te'] = tr\n",
        "        te['val'][f'{col}_te'] = va\n",
        "        te['test'][f'{col}_te'] = te_\n",
        "    for df in [train_df, val_df, test_df]:\n",
        "        df['age_edu_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str)\n",
        "        df['age_married_cat'] = df['age_group'].astype(str) + '_' + df['married'].astype(str)\n",
        "        df['age_race_cat'] = df['age_group'].astype(str) + '_' + df['race'].astype(str)\n",
        "        df['age_edu_married_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str) + '_' + df['married'].astype(str)\n",
        "    for col, sm in [('age_edu_cat', 5), ('age_married_cat', 5), ('age_race_cat', 5), ('age_edu_married_cat', 3)]:\n",
        "        tr, va, te_ = target_encode(train_df, val_df, test_df, col, target_col, sm)\n",
        "        te['train'][f'{col}_te'] = tr\n",
        "        te['val'][f'{col}_te'] = va\n",
        "        te['test'][f'{col}_te'] = te_\n",
        "    return te\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) 피처 리스트 / Dataset / Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
        "qe_log_cols = [f\"Q{c}E_log\" for c in \"abcdefghijklmnopqrst\"]\n",
        "wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
        "wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
        "tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
        "\n",
        "num_features = (\n",
        "    qa_cols + qe_log_cols + wr_cols + wf_cols + tp_cols +\n",
        "    [\n",
        "        \"age_ord\", \"education\", \"married\", \"urban\", \"engnat\", \"familysize\", \"hand\",\n",
        "        \"is_teenager\", \"is_young\", \"is_old\", \"edu_low\", \"edu_high\",\n",
        "        \"is_single\", \"is_married\", \"is_urban\", \"is_english_native\", \"is_male\",\n",
        "        \"qa_mean\", \"qa_std\", \"qa_range\", \"qa_extreme_ratio\", \"qa_neutral_ratio\", \"qa_all_same\",\n",
        "        \"qe_log_mean\", \"qe_log_std\", \"qe_fast_ratio\", \"qe_total_log\", \"is_careless\",\n",
        "        \"tp_missing_ratio\", \"tp_mean\",\n",
        "        \"extraversion\", \"agreeableness\", \"conscientiousness\", \"neuroticism\", \"openness\",\n",
        "        \"wr_sum\", \"wf_sum\", \"word_credibility\", \"vocab_high\",\n",
        "        \"age_edu\", \"young_low_edu\", \"young_single\", \"old_married\", \"teenager_low_edu\",\n",
        "    ]\n",
        ")\n",
        "te_features = ['age_group_te', 'race_te', 'religion_te',\n",
        "               'age_edu_cat_te', 'age_married_cat_te', 'age_race_cat_te', 'age_edu_married_cat_te']\n",
        "cat_features = ['gender', 'race', 'religion']\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, X_num, X_cat, y=None):\n",
        "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
        "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
        "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "    def __len__(self): return len(self.X_num)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None: return self.X_num[idx], self.X_cat[idx]\n",
        "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_features, cat_dims, embed_dim=8, hidden_dims=(256,128,64), dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(dim + 1, embed_dim) for dim in cat_dims])\n",
        "        input_dim = num_features + len(cat_dims) * embed_dim\n",
        "        layers_=[]; prev=input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers_ += [nn.Linear(prev,h), nn.BatchNorm1d(h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            prev=h\n",
        "        self.mlp = nn.Sequential(*layers_)\n",
        "        self.output = nn.Linear(prev, 1)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "    def forward(self, x_num, x_cat):\n",
        "        cat_emb = torch.cat([emb(x_cat[:,i]) for i,emb in enumerate(self.embeddings)], dim=1)\n",
        "        x = torch.cat([x_num, cat_emb], dim=1)\n",
        "        x = self.mlp(x)\n",
        "        return self.output(x)\n",
        "\n",
        "class NumericalEmbedding(nn.Module):\n",
        "    def __init__(self, num_features, d_token):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(num_features, d_token) * 0.02)\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features, d_token))\n",
        "    def forward(self, x):\n",
        "        return x.unsqueeze(-1) * self.weight + self.bias\n",
        "\n",
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, num_features, cat_dims, d_token=48, n_layers=2, n_heads=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.num_embed = NumericalEmbedding(num_features, d_token)\n",
        "        self.cat_embeds = nn.ModuleList([nn.Embedding(dim + 1, d_token) for dim in cat_dims])\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_token) * 0.02)\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_token, nhead=n_heads, dim_feedforward=d_token*2,\n",
        "            dropout=dropout, activation='gelu', batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
        "        self.head = nn.Sequential(nn.LayerNorm(d_token),\n",
        "                                  nn.Linear(d_token, d_token//2),\n",
        "                                  nn.GELU(),\n",
        "                                  nn.Dropout(dropout),\n",
        "                                  nn.Linear(d_token//2, 1))\n",
        "    def forward(self, x_num, x_cat):\n",
        "        num_tokens = self.num_embed(x_num)\n",
        "        cat_tokens = torch.stack([emb(x_cat[:,i]) for i,emb in enumerate(self.cat_embeds)], dim=1)\n",
        "        tokens = torch.cat([num_tokens, cat_tokens], dim=1)\n",
        "        cls = self.cls_token.expand(tokens.size(0), -1, -1)\n",
        "        tokens = torch.cat([cls, tokens], dim=1)\n",
        "        x = self.transformer(tokens)\n",
        "        return self.head(x[:,0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Train / Predict + 앙상블(best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, train_y, val_y, lr):\n",
        "    model.to(DEVICE)\n",
        "    pos_ratio = float(np.mean(train_y))\n",
        "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=DEVICE)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_auc = -1\n",
        "    best_state = None\n",
        "    no_imp = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for X_num, X_cat, yy in train_loader:\n",
        "            X_num, X_cat, yy = X_num.to(DEVICE), X_cat.to(DEVICE), yy.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X_num, X_cat)\n",
        "            loss = criterion(logits, yy)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for X_num, X_cat, _ in val_loader:\n",
        "                X_num, X_cat = X_num.to(DEVICE), X_cat.to(DEVICE)\n",
        "                preds.append(torch.sigmoid(model(X_num, X_cat)).cpu().numpy())\n",
        "        preds = np.concatenate(preds).ravel()\n",
        "        auc = roc_auc_score(val_y, preds)\n",
        "        scheduler.step(auc)\n",
        "\n",
        "        if auc > best_auc + 1e-5:\n",
        "            best_auc = auc\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            no_imp = 0\n",
        "        else:\n",
        "            no_imp += 1\n",
        "            if no_imp >= PATIENCE:\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def predict(model, loader):\n",
        "    model.eval()\n",
        "    preds=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            X_num, X_cat = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
        "            preds.append(torch.sigmoid(model(X_num, X_cat)).cpu().numpy())\n",
        "    return np.concatenate(preds).ravel()\n",
        "\n",
        "def best_blend_weight(y_true, p_mlp, p_ft):\n",
        "    best_auc=-1; best_w=0.5\n",
        "    for w in np.linspace(0.0, 1.0, 101):\n",
        "        p = w*p_mlp + (1-w)*p_ft\n",
        "        auc = roc_auc_score(y_true, p)\n",
        "        if auc > best_auc:\n",
        "            best_auc, best_w = auc, w\n",
        "    return best_w, best_auc\n",
        "\n",
        "def rank_avg(a, b):\n",
        "    ra = a.argsort().argsort().astype(np.float32)\n",
        "    rb = b.argsort().argsort().astype(np.float32)\n",
        "    r = (ra + rb) / 2.0\n",
        "    r = (r - r.min()) / (r.max() - r.min() + 1e-12)\n",
        "    return r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) MAIN: 5-fold로 MLP+FT 학습 → OOF로 best(prob vs rank) 선택 → submission_best.csv 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1/5\n",
            "  MLP fold AUC: 0.7811104364149108\n",
            "  FTT fold AUC: 0.776782730631759\n",
            "\n",
            "Fold 2/5\n",
            "  MLP fold AUC: 0.7688804649175817\n",
            "  FTT fold AUC: 0.7684411744384857\n",
            "\n",
            "Fold 3/5\n",
            "  MLP fold AUC: 0.763170520180577\n",
            "  FTT fold AUC: 0.7588464132827968\n",
            "\n",
            "Fold 4/5\n",
            "  MLP fold AUC: 0.7655388882397418\n",
            "  FTT fold AUC: 0.7632971735468761\n",
            "\n",
            "Fold 5/5\n",
            "  MLP fold AUC: 0.7709743413249144\n",
            "  FTT fold AUC: 0.7632319614442691\n",
            "\n",
            "OOF MLP: 0.7697211251741358 OOF FTT: 0.7646004090602618\n",
            "OOF prob(best_w mlp): 0.7708552006853077 w: 0.7000000000000001\n",
            "OOF rank: 0.7701868121304895\n",
            "Chosen best: prob\n",
            "submission: (11383, 2) ['index', 'voted']\n",
            "count    11383.000000\n",
            "mean         0.507682\n",
            "std          0.248760\n",
            "min          0.112014\n",
            "25%          0.310229\n",
            "50%          0.421914\n",
            "75%          0.708842\n",
            "max          0.993886\n",
            "Name: voted, dtype: float64\n",
            "Saved: submission_best.csv\n"
          ]
        }
      ],
      "source": [
        "set_seed(SEED)\n",
        "\n",
        "train_clean = clean_data(train_raw)\n",
        "test_clean  = clean_data(test_raw)\n",
        "\n",
        "y_all = train_clean[\"voted_bin\"].values.astype(np.float32)\n",
        "\n",
        "oof_mlp = np.zeros(len(train_clean), dtype=np.float32)\n",
        "oof_ft  = np.zeros(len(train_clean), dtype=np.float32)\n",
        "test_mlp = np.zeros(len(test_clean), dtype=np.float32)\n",
        "test_ft  = np.zeros(len(test_clean), dtype=np.float32)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(train_clean, train_clean[\"voted_bin\"])):\n",
        "    print(f\"\\nFold {fold+1}/{N_FOLDS}\")\n",
        "\n",
        "    tr = train_clean.iloc[tr_idx].copy().reset_index(drop=True)\n",
        "    va = train_clean.iloc[va_idx].copy().reset_index(drop=True)\n",
        "    te = test_clean.copy()\n",
        "\n",
        "    tr_fe = build_features(tr)\n",
        "    va_fe = build_features(va)\n",
        "    te_fe = build_features(te)\n",
        "\n",
        "    te_dict = create_target_encodings(tr_fe, va_fe, te_fe, \"voted_bin\")\n",
        "    all_num = num_features + te_features\n",
        "\n",
        "    X_tr = tr_fe[num_features].copy()\n",
        "    X_va = va_fe[num_features].copy()\n",
        "    X_te = te_fe[num_features].copy()\n",
        "\n",
        "    for te_name in te_features:\n",
        "        X_tr[te_name] = te_dict[\"train\"][te_name]\n",
        "        X_va[te_name] = te_dict[\"val\"][te_name]\n",
        "        X_te[te_name] = te_dict[\"test\"][te_name]\n",
        "\n",
        "    for col in all_num:\n",
        "        med = X_tr[col].median()\n",
        "        if pd.isna(med): med = 0\n",
        "        X_tr[col] = X_tr[col].fillna(med)\n",
        "        X_va[col] = X_va[col].fillna(med)\n",
        "        X_te[col] = X_te[col].fillna(med)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_tr_s = scaler.fit_transform(X_tr.values)\n",
        "    X_va_s = scaler.transform(X_va.values)\n",
        "    X_te_s = scaler.transform(X_te.values)\n",
        "\n",
        "    cat_dims=[]\n",
        "    X_cat_tr=[]; X_cat_va=[]; X_cat_te=[]\n",
        "    for col in cat_features:\n",
        "        le = LabelEncoder()\n",
        "        all_vals = list(set(tr_fe[col].fillna(\"NaN\").astype(str)) |\n",
        "                        set(va_fe[col].fillna(\"NaN\").astype(str)) |\n",
        "                        set(te_fe[col].fillna(\"NaN\").astype(str)))\n",
        "        le.fit(all_vals + [\"UNK\"])\n",
        "        cat_dims.append(len(le.classes_))\n",
        "        X_cat_tr.append(le.transform(tr_fe[col].fillna(\"NaN\").astype(str)))\n",
        "        X_cat_va.append(le.transform(va_fe[col].fillna(\"NaN\").astype(str)))\n",
        "        X_cat_te.append(le.transform(te_fe[col].fillna(\"NaN\").astype(str)))\n",
        "\n",
        "    X_cat_tr = np.stack(X_cat_tr, axis=1)\n",
        "    X_cat_va = np.stack(X_cat_va, axis=1)\n",
        "    X_cat_te = np.stack(X_cat_te, axis=1)\n",
        "\n",
        "    y_tr = tr_fe[\"voted_bin\"].values.astype(np.float32)\n",
        "    y_va = va_fe[\"voted_bin\"].values.astype(np.float32)\n",
        "\n",
        "    train_ds = TabDataset(X_tr_s, X_cat_tr, y_tr)\n",
        "    val_ds   = TabDataset(X_va_s, X_cat_va, y_va)\n",
        "    test_ds  = TabDataset(X_te_s, X_cat_te, None)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # MLP\n",
        "    mlp = MLP(num_features=len(all_num), cat_dims=cat_dims, embed_dim=8, hidden_dims=(256,128,64), dropout=0.3)\n",
        "    mlp = train_model(mlp, train_loader, val_loader, y_tr, y_va, lr=LR_MLP)\n",
        "    pred_va_mlp = predict(mlp, val_loader)\n",
        "    oof_mlp[va_idx] = pred_va_mlp\n",
        "    test_mlp += predict(mlp, test_loader) / N_FOLDS\n",
        "    print(\"  MLP fold AUC:\", roc_auc_score(y_va, pred_va_mlp))\n",
        "\n",
        "    # FTTransformer\n",
        "    ft = FTTransformer(num_features=len(all_num), cat_dims=cat_dims, d_token=48, n_layers=2, n_heads=4, dropout=0.2)\n",
        "    ft = train_model(ft, train_loader, val_loader, y_tr, y_va, lr=LR_FT)\n",
        "    pred_va_ft = predict(ft, val_loader)\n",
        "    oof_ft[va_idx] = pred_va_ft\n",
        "    test_ft += predict(ft, test_loader) / N_FOLDS\n",
        "    print(\"  FTT fold AUC:\", roc_auc_score(y_va, pred_va_ft))\n",
        "\n",
        "# OOF scoring\n",
        "auc_mlp = roc_auc_score(y_all, oof_mlp)\n",
        "auc_ft  = roc_auc_score(y_all, oof_ft)\n",
        "best_w, auc_prob = best_blend_weight(y_all, oof_mlp, oof_ft)\n",
        "oof_prob = best_w*oof_mlp + (1-best_w)*oof_ft\n",
        "test_prob = best_w*test_mlp + (1-best_w)*test_ft\n",
        "\n",
        "oof_rank = rank_avg(oof_mlp, oof_ft)\n",
        "test_rank = rank_avg(test_mlp, test_ft)\n",
        "\n",
        "auc_prob = roc_auc_score(y_all, oof_prob)\n",
        "auc_rank = roc_auc_score(y_all, oof_rank)\n",
        "\n",
        "print(\"\\nOOF MLP:\", auc_mlp, \"OOF FTT:\", auc_ft)\n",
        "print(\"OOF prob(best_w mlp):\", auc_prob, \"w:\", best_w)\n",
        "print(\"OOF rank:\", auc_rank)\n",
        "\n",
        "# choose best\n",
        "if auc_rank > auc_prob:\n",
        "    final_test = test_rank\n",
        "    chosen = \"rank\"\n",
        "else:\n",
        "    final_test = test_prob\n",
        "    chosen = \"prob\"\n",
        "\n",
        "print(\"Chosen best:\", chosen)\n",
        "\n",
        "submission_best = pd.DataFrame({\n",
        "    \"index\": test_raw[\"index\"].values if \"index\" in test_raw.columns else np.arange(len(test_raw)),\n",
        "    \"voted\": final_test\n",
        "})\n",
        "\n",
        "print(\"submission:\", submission_best.shape, submission_best.columns.tolist())\n",
        "print(submission_best[\"voted\"].describe())\n",
        "\n",
        "assert submission_best.shape == (11383, 2)\n",
        "assert submission_best.columns.tolist() == [\"index\", \"voted\"]\n",
        "assert float(submission_best[\"voted\"].min()) >= 0.0 and float(submission_best[\"voted\"].max()) <= 1.0\n",
        "\n",
        "submission_best.to_csv(\"submission_best.csv\", index=False)\n",
        "print(\"Saved: submission_best.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ecebc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 리더 보드 = 0.778854247"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db9cb6e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "voteai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
