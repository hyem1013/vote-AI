{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03_best_score_\n",
        "\n",
        "목표\n",
        "- **최종 제출은 딥러닝 모델만** 사용\n",
        "- 다만, **피처(변수) 중요도 확인/선별**은 LightGBM을 도구로 사용(규칙 허용)\n",
        "- 제출값은 **voted=2 확률**로 통일\n",
        "\n",
        "구성(한 줄)\n",
        "1) 설문 데이터를 요약 피처로 만들고 → 2) LGBM으로 중요한 피처만 고른 뒤 → 3) 그 피처로 딥러닝(MLP) 학습/제출\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) (필요 시) 설치\n",
        "- 이미 설치돼 있으면 건너뛰세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요할 때만 실행하세요.\n",
        "# !pip install --default-timeout=300 lightgbm tensorflow scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) 데이터 로드 (팀 공용 경로)\n",
        "- 프로젝트 루트를 자동으로 찾아서, 어디서 실행해도 동일하게 동작하도록 했습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: (45532, 78) test: (11383, 77) sub: (11383, 2)\n",
            "pos ratio (voted==2): 0.5468242115435298\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    start = start.resolve()\n",
        "    for p in [start] + list(start.parents):\n",
        "        if (p / \"requirements.txt\").exists() or (p / \"README.md\").exists():\n",
        "            return p\n",
        "    raise FileNotFoundError(\"프로젝트 루트를 찾지 못했습니다. (requirements.txt 또는 README.md 위치 확인)\")\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "\n",
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test  = pd.read_csv(DATA_DIR / \"test_x.csv\")\n",
        "sub   = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
        "\n",
        "print(\"train:\", train.shape, \"test:\", test.shape, \"sub:\", sub.shape)\n",
        "\n",
        "# 타깃: voted==2 확률 제출을 위해 y를 voted==2로 고정\n",
        "y = (train[\"voted\"] == 2).astype(\"int32\")\n",
        "X_raw = train.drop(columns=[\"voted\"])\n",
        "\n",
        "print(\"pos ratio (voted==2):\", float(y.mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 컬럼 그룹 자동 탐지\n",
        "- 설문 응답(QA), 응답 시간(QE), 성격(tp), 단어(wr/wf) 그룹을 자동으로 잡습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QA/QE/TP/WR/WF: 20 20 10 13 3\n"
          ]
        }
      ],
      "source": [
        "cols = list(X_raw.columns)\n",
        "q_like = [c for c in cols if c.startswith(\"Q\")]\n",
        "\n",
        "QA_cols = sorted([c for c in q_like if re.fullmatch(r\"Q[a-z]A\", c)])\n",
        "QE_cols = sorted([c for c in q_like if re.fullmatch(r\"Q[a-z]E\", c)])\n",
        "\n",
        "TP_cols = sorted([c for c in cols if re.fullmatch(r\"tp\\d{2}\", c)])\n",
        "WR_cols = sorted([c for c in cols if re.fullmatch(r\"wr_?\\d{2}\", c)])\n",
        "WF_cols = sorted([c for c in cols if re.fullmatch(r\"wf_?\\d{2}\", c)])\n",
        "\n",
        "print(\"QA/QE/TP/WR/WF:\", len(QA_cols), len(QE_cols), len(TP_cols), len(WR_cols), len(WF_cols))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Feature Engineering\n",
        "\n",
        "\n",
        "# Feature\n",
        "- 태도: 평균/흔들림/중립비율/극단비율/무응답비율\n",
        "- 응답태도: 응답시간 합/표준편차/너무 빠름·느림 비율\n",
        "- 성격: Big5 차이(diff)와 강도(|diff|)\n",
        "- 단어: wr합, wf합, (wr-wf)\n",
        "- 인구통계: 나이대/urban은 순서형 숫자로 변환 + 무응답 여부 표시\n",
        "\n",
        "Reverse+Mach는 도움이 될 때가 있고 아닐 때가 있어서 스위치로 둡니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_feat: (45532, 38) T_feat: (11383, 38)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age_group</th>\n",
              "      <th>education</th>\n",
              "      <th>engnat</th>\n",
              "      <th>familysize</th>\n",
              "      <th>gender</th>\n",
              "      <th>hand</th>\n",
              "      <th>married</th>\n",
              "      <th>race</th>\n",
              "      <th>religion</th>\n",
              "      <th>urban</th>\n",
              "      <th>age_group_ord</th>\n",
              "      <th>urban_ord</th>\n",
              "      <th>education_is_missing</th>\n",
              "      <th>urban_is_missing</th>\n",
              "      <th>hand_is_missing</th>\n",
              "      <th>married_is_missing</th>\n",
              "      <th>att_mean</th>\n",
              "      <th>att_std</th>\n",
              "      <th>ratio_neutral</th>\n",
              "      <th>ratio_extreme</th>\n",
              "      <th>ratio_qa_missing</th>\n",
              "      <th>time_sum</th>\n",
              "      <th>time_std</th>\n",
              "      <th>ratio_fast</th>\n",
              "      <th>ratio_slow</th>\n",
              "      <th>Ex_diff</th>\n",
              "      <th>Ex_strength</th>\n",
              "      <th>Ag_diff</th>\n",
              "      <th>Ag_strength</th>\n",
              "      <th>Con_diff</th>\n",
              "      <th>Con_strength</th>\n",
              "      <th>Es_diff</th>\n",
              "      <th>Es_strength</th>\n",
              "      <th>Op_diff</th>\n",
              "      <th>Op_strength</th>\n",
              "      <th>wr_sum</th>\n",
              "      <th>wf_sum</th>\n",
              "      <th>word_credibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.05</td>\n",
              "      <td>1.394538</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17874</td>\n",
              "      <td>323.295058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1.794729</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49565</td>\n",
              "      <td>1264.031057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-1.628942</td>\n",
              "      <td>1.628942</td>\n",
              "      <td>-0.6306</td>\n",
              "      <td>0.6306</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1.641565</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29661</td>\n",
              "      <td>693.931096</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-4.0000</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>0.944513</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72714</td>\n",
              "      <td>5389.724786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.803505</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18487</td>\n",
              "      <td>366.429756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.588953</td>\n",
              "      <td>1.588953</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-4.0000</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>-3.956082</td>\n",
              "      <td>3.956082</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age_group  education  engnat  familysize  gender  hand  married  race  religion  urban  age_group_ord  urban_ord  education_is_missing  urban_is_missing  hand_is_missing  married_is_missing  \\\n",
              "0        0.0          2       1           4       0     1        3     6        10      1             30          1                     0                 0                0                   0   \n",
              "1        0.0          4       2           3       0     1        1     1         7      3             20          3                     0                 0                0                   0   \n",
              "2        0.0          3       1           3       1     1        2     6        10      2             30          2                     0                 0                0                   0   \n",
              "3        0.0          4       2           0       0     1        1     1         7      3             20          3                     0                 0                0                   0   \n",
              "4        0.0          3       1           2       1     1        2     6         0      1             20          1                     0                 0                0                   0   \n",
              "\n",
              "   att_mean   att_std  ratio_neutral  ratio_extreme  ratio_qa_missing  time_sum     time_std  ratio_fast  ratio_slow  Ex_diff  Ex_strength   Ag_diff  Ag_strength  Con_diff  Con_strength  Es_diff  \\\n",
              "0      3.05  1.394538           0.05           0.30               0.0     17874   323.295058         0.0         1.0      1.0          1.0  5.000000     5.000000 -2.000000      2.000000   3.0000   \n",
              "1      3.20  1.794729           0.15           0.75               0.0     49565  1264.031057         0.0         1.0     -1.0          1.0  2.000000     2.000000 -1.628942      1.628942  -0.6306   \n",
              "2      2.80  1.641565           0.05           0.55               0.0     29661   693.931096         0.0         1.0     -2.0          2.0 -1.000000     1.000000 -5.000000      5.000000  -4.0000   \n",
              "3      3.55  0.944513           0.30           0.15               0.0     72714  5389.724786         0.0         1.0     -1.0          1.0 -3.000000     3.000000 -2.000000      2.000000   0.0000   \n",
              "4      2.90  1.803505           0.00           0.70               0.0     18487   366.429756         0.0         1.0     -1.0          1.0  1.588953     1.588953 -5.000000      5.000000  -4.0000   \n",
              "\n",
              "   Es_strength   Op_diff  Op_strength  wr_sum  wf_sum  word_credibility  \n",
              "0       3.0000 -1.000000     1.000000       7       0                 7  \n",
              "1       0.6306 -3.000000     3.000000       8       0                 8  \n",
              "2       4.0000  0.000000     0.000000      10       1                 9  \n",
              "3       0.0000 -2.000000     2.000000       5       0                 5  \n",
              "4       4.0000 -3.956082     3.956082      11       1                10  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "USE_REVERSE_MACH = False  # True/False 둘 다 돌려보고 높은 쪽을 쓰면 됨\n",
        "\n",
        "FLIP_PUBLIC = [\"QeA\",\"QfA\",\"QkA\",\"QqA\",\"QrA\"]\n",
        "FLIP_SECRET = [\"QaA\",\"QdA\",\"QgA\",\"QiA\",\"QnA\"]\n",
        "\n",
        "def age_group_to_ord(v):\n",
        "    # '10s' -> 10, '20s' -> 20 ...\n",
        "    try:\n",
        "        return int(str(v).replace(\"s\",\"\"))\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "def urban_to_ord(v):\n",
        "    # 0은 무응답 취급(-1), 1/2/3은 유지\n",
        "    try:\n",
        "        iv = int(v)\n",
        "        return -1 if iv == 0 else iv\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "def build_features(df: pd.DataFrame, tp_means=None):\n",
        "    df = df.copy()\n",
        "\n",
        "    # index는 제출용이므로 피처에서는 제거\n",
        "    if \"index\" in df.columns:\n",
        "        df = df.drop(columns=[\"index\"])\n",
        "\n",
        "    # QA/QE/TP/WR/WF 숫자화\n",
        "    for c in QA_cols: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    for c in QE_cols: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    for c in TP_cols: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    for c in WR_cols: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    for c in WF_cols: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # (1) 인구통계 순서형 변환 + 무응답 indicator\n",
        "    if \"age_group\" in df.columns:\n",
        "        df[\"age_group_ord\"] = df[\"age_group\"].astype(str).apply(age_group_to_ord)\n",
        "    if \"urban\" in df.columns:\n",
        "        df[\"urban_ord\"] = df[\"urban\"].apply(urban_to_ord)\n",
        "\n",
        "    for c in [\"education\",\"urban\",\"hand\",\"married\"]:\n",
        "        if c in df.columns:\n",
        "            tmp = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "            df[f\"{c}_is_missing\"] = (tmp == 0).astype(\"int32\")\n",
        "\n",
        "    # (2) QA reverse + Mach (옵션)\n",
        "    if USE_REVERSE_MACH:\n",
        "        for c in FLIP_PUBLIC + FLIP_SECRET:\n",
        "            if c in df.columns:\n",
        "                df[c] = 6 - df[c]\n",
        "\n",
        "    qa = df[QA_cols]\n",
        "    df[\"att_mean\"] = qa.mean(axis=1)\n",
        "    df[\"att_std\"] = qa.std(axis=1)\n",
        "    df[\"ratio_neutral\"] = (qa == 3).mean(axis=1)\n",
        "    df[\"ratio_extreme\"] = ((qa == 1) | (qa == 5)).mean(axis=1)\n",
        "    df[\"ratio_qa_missing\"] = qa.isna().mean(axis=1)\n",
        "\n",
        "    if USE_REVERSE_MACH:\n",
        "        df[\"mach_T\"] = df[\"QcA\"] - df[\"QfA\"] + df[\"QoA\"] - df[\"QrA\"] + df[\"QsA\"]\n",
        "        df[\"mach_V\"] = df[\"QbA\"] - df[\"QeA\"] + df[\"QhA\"] + df[\"QjA\"] + df[\"QmA\"] - df[\"QqA\"]\n",
        "        df[\"mach_M\"] = -df[\"QkA\"]\n",
        "        df[\"mach_mean\"] = qa.mean(axis=1)\n",
        "\n",
        "    # (3) QE delay 요약\n",
        "    qe = df[QE_cols].clip(lower=0)\n",
        "    qe_log = np.log1p(qe)\n",
        "    df[\"time_sum\"] = qe.sum(axis=1)\n",
        "    df[\"time_std\"] = qe.std(axis=1)\n",
        "    df[\"ratio_fast\"] = (qe_log < 1.0).mean(axis=1)\n",
        "    df[\"ratio_slow\"] = (qe_log > 4.0).mean(axis=1)\n",
        "\n",
        "    # (4) Big5: tp는 0을 무응답으로 보고 train 평균으로 채움\n",
        "    for c in TP_cols:\n",
        "        df.loc[df[c] == 0, c] = np.nan\n",
        "\n",
        "    if tp_means is None:\n",
        "        tp_means = {c: float(df[c].mean()) for c in TP_cols}\n",
        "    for c in TP_cols:\n",
        "        df[c] = df[c].fillna(tp_means[c])\n",
        "\n",
        "    df[\"Ex_diff\"] = df[\"tp01\"] - df[\"tp06\"]; df[\"Ex_strength\"] = df[\"Ex_diff\"].abs()\n",
        "    df[\"Ag_diff\"] = df[\"tp07\"] - df[\"tp02\"]; df[\"Ag_strength\"] = df[\"Ag_diff\"].abs()\n",
        "    df[\"Con_diff\"] = df[\"tp03\"] - df[\"tp08\"]; df[\"Con_strength\"] = df[\"Con_diff\"].abs()\n",
        "    df[\"Es_diff\"] = df[\"tp09\"] - df[\"tp04\"]; df[\"Es_strength\"] = df[\"Es_diff\"].abs()\n",
        "    df[\"Op_diff\"] = df[\"tp05\"] - df[\"tp10\"]; df[\"Op_strength\"] = df[\"Op_diff\"].abs()\n",
        "\n",
        "    # (5) WR/WF 요약\n",
        "    df[\"wr_sum\"] = df[WR_cols].sum(axis=1) if len(WR_cols) else 0\n",
        "    df[\"wf_sum\"] = df[WF_cols].sum(axis=1) if len(WF_cols) else 0\n",
        "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
        "\n",
        "    # 원본 그룹은 노이즈가 많아서 제거 (요약만 남김)\n",
        "    drop_cols = QA_cols + QE_cols + TP_cols + WR_cols + WF_cols\n",
        "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "    # 남아있는 문자열 범주형을 간단히 숫자코드로 변환\n",
        "    # (최종 모델은 딥러닝이지만 여기선 입력을 깔끔하게 만들기 위한 변환)\n",
        "    for c in [\"gender\",\"race\",\"religion\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
        "\n",
        "    # 최종: 전부 숫자로 만들고 결측은 0\n",
        "    df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "    return df, tp_means\n",
        "\n",
        "X_feat, tp_means = build_features(X_raw, tp_means=None)\n",
        "T_feat, _ = build_features(test, tp_means=tp_means)\n",
        "\n",
        "print(\"X_feat:\", X_feat.shape, \"T_feat:\", T_feat.shape)\n",
        "X_feat.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) LGBM으로 중요 피처 TopK 선택 \n",
        "여기서 중요한 점:\n",
        "- one-hot을 섞지 않고 **지금 만든 numeric 피처만**으로 importance를 뽑는다.\n",
        "그래야 TopK가 정확히 딥러닝 입력으로 이어진다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 19918, number of negative: 16507\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1228\n",
            "[LightGBM] [Info] Number of data points in the train set: 36425, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546822 -> initscore=0.187839\n",
            "[LightGBM] [Info] Start training from score 0.187839\n",
            "Training until validation scores don't improve for 400 rounds\n",
            "Early stopping, best iteration is:\n",
            "[212]\tvalid_0's auc: 0.778883\tvalid_0's binary_logloss: 0.546514\n",
            "[LightGBM] [Info] Number of positive: 19918, number of negative: 16507\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1228\n",
            "[LightGBM] [Info] Number of data points in the train set: 36425, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546822 -> initscore=0.187839\n",
            "[LightGBM] [Info] Start training from score 0.187839\n",
            "Training until validation scores don't improve for 400 rounds\n",
            "Early stopping, best iteration is:\n",
            "[149]\tvalid_0's auc: 0.768089\tvalid_0's binary_logloss: 0.560077\n",
            "[LightGBM] [Info] Number of positive: 19918, number of negative: 16508\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1228\n",
            "[LightGBM] [Info] Number of data points in the train set: 36426, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546807 -> initscore=0.187779\n",
            "[LightGBM] [Info] Start training from score 0.187779\n",
            "Training until validation scores don't improve for 400 rounds\n",
            "Early stopping, best iteration is:\n",
            "[219]\tvalid_0's auc: 0.762084\tvalid_0's binary_logloss: 0.562358\n",
            "[LightGBM] [Info] Number of positive: 19919, number of negative: 16507\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1228\n",
            "[LightGBM] [Info] Number of data points in the train set: 36426, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546835 -> initscore=0.187890\n",
            "[LightGBM] [Info] Start training from score 0.187890\n",
            "Training until validation scores don't improve for 400 rounds\n",
            "Early stopping, best iteration is:\n",
            "[275]\tvalid_0's auc: 0.76029\tvalid_0's binary_logloss: 0.566153\n",
            "[LightGBM] [Info] Number of positive: 19919, number of negative: 16507\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1230\n",
            "[LightGBM] [Info] Number of data points in the train set: 36426, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546835 -> initscore=0.187890\n",
            "[LightGBM] [Info] Start training from score 0.187890\n",
            "Training until validation scores don't improve for 400 rounds\n",
            "Early stopping, best iteration is:\n",
            "[217]\tvalid_0's auc: 0.767459\tvalid_0's binary_logloss: 0.558806\n",
            "LGBM CV AUC mean: 0.7673610283014751 std: 0.0064982959482056644\n",
            "[LightGBM] [Info] Number of positive: 16598, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1225\n",
            "[LightGBM] [Info] Number of data points in the train set: 30354, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546814 -> initscore=0.187807\n",
            "[LightGBM] [Info] Start training from score 0.187807\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1222\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "K 40 quick AUC 0.7546393856225135\n",
            "[LightGBM] [Info] Number of positive: 16598, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1225\n",
            "[LightGBM] [Info] Number of data points in the train set: 30354, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546814 -> initscore=0.187807\n",
            "[LightGBM] [Info] Start training from score 0.187807\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1222\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "K 60 quick AUC 0.7546393856225135\n",
            "[LightGBM] [Info] Number of positive: 16598, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1225\n",
            "[LightGBM] [Info] Number of data points in the train set: 30354, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546814 -> initscore=0.187807\n",
            "[LightGBM] [Info] Start training from score 0.187807\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1222\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "K 80 quick AUC 0.7546393856225135\n",
            "[LightGBM] [Info] Number of positive: 16598, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1225\n",
            "[LightGBM] [Info] Number of data points in the train set: 30354, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546814 -> initscore=0.187807\n",
            "[LightGBM] [Info] Start training from score 0.187807\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1222\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n",
            "K 120 quick AUC 0.7546393856225135\n",
            "[LightGBM] [Info] Number of positive: 16598, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1225\n",
            "[LightGBM] [Info] Number of data points in the train set: 30354, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546814 -> initscore=0.187807\n",
            "[LightGBM] [Info] Start training from score 0.187807\n",
            "[LightGBM] [Info] Number of positive: 16599, number of negative: 13756\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1221\n",
            "[LightGBM] [Info] Number of data points in the train set: 30355, number of used features: 35\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.546829 -> initscore=0.187867\n",
            "[LightGBM] [Info] Start training from score 0.187867\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "\n",
        "X_lgb = X_feat.copy()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "importances = np.zeros(X_lgb.shape[1], dtype=float)\n",
        "auc_list = []\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_lgb, y)):\n",
        "    X_tr, X_va = X_lgb.iloc[tr_idx], X_lgb.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        n_estimators=8000, learning_rate=0.015,\n",
        "        num_leaves=255, subsample=0.8, colsample_bytree=0.8,\n",
        "        reg_lambda=1.0, random_state=42+fold\n",
        "    )\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_va, y_va)],\n",
        "        eval_metric=\"auc\",\n",
        "        callbacks=[early_stopping(400), log_evaluation(0)]\n",
        "    )\n",
        "    pred = model.predict_proba(X_va)[:, 1]\n",
        "    auc_list.append(roc_auc_score(y_va, pred))\n",
        "    importances += model.booster_.feature_importance(importance_type=\"gain\")\n",
        "\n",
        "print(\"LGBM CV AUC mean:\", float(np.mean(auc_list)), \"std:\", float(np.std(auc_list)))\n",
        "\n",
        "imp_rank = pd.Series(importances, index=X_lgb.columns).sort_values(ascending=False)\n",
        "\n",
        "# K는 경험상 40~160 사이가 자주 잘 먹힘\n",
        "K_CANDIDATES = [40, 60, 80, 120, 160]\n",
        "best_k, best_auc = None, -1\n",
        "\n",
        "skf2 = StratifiedKFold(n_splits=3, shuffle=True, random_state=777)\n",
        "for k in K_CANDIDATES:\n",
        "    use = imp_rank.head(k).index.tolist()\n",
        "    auc2 = []\n",
        "    for f, (tr, va) in enumerate(skf2.split(X_lgb[use], y)):\n",
        "        m = LGBMClassifier(n_estimators=3000, learning_rate=0.02, num_leaves=127, random_state=1000+f)\n",
        "        m.fit(X_lgb[use].iloc[tr], y.iloc[tr])\n",
        "        p = m.predict_proba(X_lgb[use].iloc[va])[:, 1]\n",
        "        auc2.append(roc_auc_score(y.iloc[va], p))\n",
        "    mean_auc2 = float(np.mean(auc2))\n",
        "    print(\"K\", k, \"quick AUC\", mean_auc2)\n",
        "    if mean_auc2 > best_auc:\n",
        "        best_auc, best_k = mean_auc2, k\n",
        "\n",
        "TOPK = best_k\n",
        "selected_features = imp_rank.head(TOPK).index.tolist()\n",
        "print(\"\\n Selected TOPK =\", TOPK)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) 최종 딥러닝 모델(MLP) 학습 + 제출 생성\n",
        "여기서부터는 **딥러닝만** 사용함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODE: FAST CFG: {'EPOCHS': 12, 'N_SPLITS': 3, 'SEEDS': [42], 'BATCH': 512}\n",
            "[seed 42] fold 0 AUC=0.764611\n",
            "[seed 42] fold 1 AUC=0.756534\n",
            "[seed 42] fold 2 AUC=0.756867\n",
            "\n",
            "[seed 42] OOF AUC: 0.759281\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Ensemble OOF AUC: 0.7592811938191976\n",
            "submission: (11383, 2) ['index', 'voted']\n",
            "count    11383.000000\n",
            "mean         0.520863\n",
            "std          0.245189\n",
            "min          0.087193\n",
            "25%          0.329722\n",
            "50%          0.431084\n",
            "75%          0.724007\n",
            "max          0.997267\n",
            "Name: voted, dtype: float64\n",
            "Saved: /Users/admin/Downloads/AI 헬스케어 수업/oz코딩 수업/해커톤 (1)/vote-AI/submission_best_score.csv\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "X_sel = X_feat[selected_features].copy()\n",
        "T_sel = T_feat[selected_features].copy()\n",
        "\n",
        "def make_ds(Xdf, yarr=None, batch_size=512, shuffle=False, seed=42):\n",
        "    Xnp = Xdf.values.astype(\"float32\")\n",
        "    if yarr is None:\n",
        "        ds = tf.data.Dataset.from_tensor_slices(Xnp)\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((Xnp, yarr.astype(\"float32\")))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=min(len(Xdf), 10000), seed=seed, reshuffle_each_iteration=True)\n",
        "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def build_mlp(input_dim, lr=1e-3, dropout=0.3):\n",
        "    inp = keras.Input(shape=(input_dim,), dtype=tf.float32)\n",
        "    x = layers.BatchNormalization()(inp)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[keras.metrics.AUC(name=\"auc\")])\n",
        "    return model\n",
        "\n",
        "# FAST / SUBMIT\n",
        "FAST = dict(EPOCHS=12, N_SPLITS=3, SEEDS=[42], BATCH=512)\n",
        "SUBMIT = dict(EPOCHS=25, N_SPLITS=5, SEEDS=[42,202,777], BATCH=256)\n",
        "\n",
        "MODE = \"FAST\"   # 먼저 FAST로 OOF 확인 후 SUBMIT로 바꾸는 것을 권장\n",
        "CFG = FAST if MODE==\"FAST\" else SUBMIT\n",
        "print(\"MODE:\", MODE, \"CFG:\", CFG)\n",
        "\n",
        "EPOCHS = CFG[\"EPOCHS\"]; N_SPLITS = CFG[\"N_SPLITS\"]; SEEDS = CFG[\"SEEDS\"]; BATCH = CFG[\"BATCH\"]\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "oof_by_seed = []\n",
        "for seed in SEEDS:\n",
        "    oof = np.zeros(len(X_sel), dtype=\"float32\")\n",
        "    for fold, (tr, va) in enumerate(skf.split(X_sel, y)):\n",
        "        X_tr = X_sel.iloc[tr].reset_index(drop=True)\n",
        "        y_tr = y.iloc[tr].reset_index(drop=True).values\n",
        "        X_va = X_sel.iloc[va].reset_index(drop=True)\n",
        "        y_va = y.iloc[va].reset_index(drop=True).values\n",
        "\n",
        "        pos = float(y_tr.mean()); neg = 1.0 - pos\n",
        "        class_weight = {0: 1.0, 1: neg/(pos+1e-9)}\n",
        "\n",
        "        tf.keras.utils.set_random_seed(seed + fold)\n",
        "        model = build_mlp(X_tr.shape[1], lr=1e-3, dropout=0.3)\n",
        "\n",
        "        tr_ds = make_ds(X_tr, y_tr, batch_size=BATCH, shuffle=True, seed=seed+fold)\n",
        "        va_ds = make_ds(X_va, y_va, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "        cb = [\n",
        "            keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=3, restore_best_weights=True),\n",
        "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=1, min_lr=1e-5),\n",
        "        ]\n",
        "\n",
        "        model.fit(tr_ds, validation_data=va_ds, epochs=EPOCHS, verbose=0, callbacks=cb, class_weight=class_weight)\n",
        "\n",
        "        pred = model.predict(make_ds(X_va, None, batch_size=BATCH), verbose=0).reshape(-1)\n",
        "        pred = np.nan_to_num(pred, nan=0.5)\n",
        "        oof[va] = pred\n",
        "        print(f\"[seed {seed}] fold {fold} AUC={roc_auc_score(y_va, pred):.6f}\")\n",
        "\n",
        "    auc_seed = roc_auc_score(y, oof)\n",
        "    oof_by_seed.append(oof)\n",
        "    print(f\"\\n[seed {seed}] OOF AUC: {auc_seed:.6f}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "oof_ens = np.mean(np.vstack(oof_by_seed), axis=0)\n",
        "print(\"\\n✅ Ensemble OOF AUC:\", roc_auc_score(y, oof_ens))\n",
        "\n",
        "# ---- Final submission (SUBMIT 모드에서만 권장) ----\n",
        "FINAL_SEEDS = SUBMIT[\"SEEDS\"]\n",
        "EPOCHS_SUB = SUBMIT[\"EPOCHS\"]\n",
        "BATCH_SUB = SUBMIT[\"BATCH\"]\n",
        "\n",
        "def train_full_predict(seed):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    model = build_mlp(X_sel.shape[1], lr=1e-3, dropout=0.3)\n",
        "\n",
        "    pos = float(y.mean()); neg = 1.0 - pos\n",
        "    class_weight = {0: 1.0, 1: neg/(pos+1e-9)}\n",
        "\n",
        "    tr_ds = make_ds(X_sel, y.values, batch_size=BATCH_SUB, shuffle=True, seed=seed)\n",
        "    model.fit(tr_ds, epochs=max(10, EPOCHS_SUB//2), verbose=0, class_weight=class_weight)\n",
        "\n",
        "    pred = model.predict(make_ds(T_sel, None, batch_size=BATCH_SUB), verbose=0).reshape(-1)\n",
        "    return np.nan_to_num(pred, nan=0.5)\n",
        "\n",
        "pred_test = np.mean(np.vstack([train_full_predict(s) for s in FINAL_SEEDS]), axis=0).reshape(-1)\n",
        "\n",
        "submission = sub.copy()\n",
        "submission[\"voted\"] = pred_test\n",
        "\n",
        "print(\"submission:\", submission.shape, submission.columns.tolist())\n",
        "print(submission[\"voted\"].describe())\n",
        "\n",
        "assert submission.shape == (11383, 2)\n",
        "assert submission.columns.tolist() == [\"index\",\"voted\"]\n",
        "assert float(submission[\"voted\"].min()) >= 0.0 and float(submission[\"voted\"].max()) <= 1.0\n",
        "\n",
        "out_path = PROJECT_ROOT / \"submission_best_score.csv\"\n",
        "submission.to_csv(out_path, index=False)\n",
        "print(\"Saved:\", out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b08c52",
      "metadata": {},
      "outputs": [],
      "source": [
        "# OOF AUC: 0.759281 --> SE_REVERSE_MACH = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b90350",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "voteai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
