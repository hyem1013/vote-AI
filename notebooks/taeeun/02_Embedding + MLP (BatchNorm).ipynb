{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering + Seed Ensemble\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) (필요 시) 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요할 때만 실행하세요.\n",
        "# !pip -q install tensorflow scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1)  공용 로더 + 데이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT: /Users/admin/Downloads/AI 헬스케어 수업/oz코딩 수업/해커톤 (1)/vote-AI\n",
            "DATA_DIR: /Users/admin/Downloads/AI 헬스케어 수업/oz코딩 수업/해커톤 (1)/vote-AI/data/raw\n",
            "train: (45532, 78) test: (11383, 77) sub: (11383, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>QaA</th>\n",
              "      <th>QaE</th>\n",
              "      <th>QbA</th>\n",
              "      <th>QbE</th>\n",
              "      <th>QcA</th>\n",
              "      <th>QcE</th>\n",
              "      <th>QdA</th>\n",
              "      <th>QdE</th>\n",
              "      <th>QeA</th>\n",
              "      <th>QeE</th>\n",
              "      <th>QfA</th>\n",
              "      <th>QfE</th>\n",
              "      <th>QgA</th>\n",
              "      <th>QgE</th>\n",
              "      <th>QhA</th>\n",
              "      <th>QhE</th>\n",
              "      <th>QiA</th>\n",
              "      <th>QiE</th>\n",
              "      <th>QjA</th>\n",
              "      <th>QjE</th>\n",
              "      <th>QkA</th>\n",
              "      <th>QkE</th>\n",
              "      <th>QlA</th>\n",
              "      <th>QlE</th>\n",
              "      <th>QmA</th>\n",
              "      <th>QmE</th>\n",
              "      <th>QnA</th>\n",
              "      <th>QnE</th>\n",
              "      <th>QoA</th>\n",
              "      <th>QoE</th>\n",
              "      <th>QpA</th>\n",
              "      <th>QpE</th>\n",
              "      <th>QqA</th>\n",
              "      <th>QqE</th>\n",
              "      <th>QrA</th>\n",
              "      <th>QrE</th>\n",
              "      <th>QsA</th>\n",
              "      <th>QsE</th>\n",
              "      <th>QtA</th>\n",
              "      <th>QtE</th>\n",
              "      <th>age_group</th>\n",
              "      <th>education</th>\n",
              "      <th>engnat</th>\n",
              "      <th>familysize</th>\n",
              "      <th>gender</th>\n",
              "      <th>hand</th>\n",
              "      <th>married</th>\n",
              "      <th>race</th>\n",
              "      <th>religion</th>\n",
              "      <th>tp01</th>\n",
              "      <th>tp02</th>\n",
              "      <th>tp03</th>\n",
              "      <th>tp04</th>\n",
              "      <th>tp05</th>\n",
              "      <th>tp06</th>\n",
              "      <th>tp07</th>\n",
              "      <th>tp08</th>\n",
              "      <th>tp09</th>\n",
              "      <th>tp10</th>\n",
              "      <th>urban</th>\n",
              "      <th>voted</th>\n",
              "      <th>wf_01</th>\n",
              "      <th>wf_02</th>\n",
              "      <th>wf_03</th>\n",
              "      <th>wr_01</th>\n",
              "      <th>wr_02</th>\n",
              "      <th>wr_03</th>\n",
              "      <th>wr_04</th>\n",
              "      <th>wr_05</th>\n",
              "      <th>wr_06</th>\n",
              "      <th>wr_07</th>\n",
              "      <th>wr_08</th>\n",
              "      <th>wr_09</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>wr_11</th>\n",
              "      <th>wr_12</th>\n",
              "      <th>wr_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>363</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>997</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1024</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1577</td>\n",
              "      <td>5.0</td>\n",
              "      <td>539</td>\n",
              "      <td>2.0</td>\n",
              "      <td>586</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1095</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1142</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1287</td>\n",
              "      <td>4.0</td>\n",
              "      <td>883</td>\n",
              "      <td>4.0</td>\n",
              "      <td>851</td>\n",
              "      <td>2.0</td>\n",
              "      <td>851</td>\n",
              "      <td>5.0</td>\n",
              "      <td>816</td>\n",
              "      <td>2.0</td>\n",
              "      <td>579</td>\n",
              "      <td>2.0</td>\n",
              "      <td>924</td>\n",
              "      <td>2.0</td>\n",
              "      <td>366</td>\n",
              "      <td>2.0</td>\n",
              "      <td>876</td>\n",
              "      <td>2.0</td>\n",
              "      <td>633</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1115</td>\n",
              "      <td>30s</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>White</td>\n",
              "      <td>Other</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>647</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3387</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2969</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4320</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2190</td>\n",
              "      <td>1.0</td>\n",
              "      <td>826</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4082</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1867</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1264</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2943</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3927</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4329</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1828</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1214</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2414</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1356</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3039</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1346</td>\n",
              "      <td>20s</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Asian</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1623</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1480</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1021</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3374</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>531</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1016</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2653</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1569</td>\n",
              "      <td>5.0</td>\n",
              "      <td>998</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2547</td>\n",
              "      <td>2.0</td>\n",
              "      <td>918</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2153</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1131</td>\n",
              "      <td>5.0</td>\n",
              "      <td>937</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1170</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1409</td>\n",
              "      <td>30s</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>White</td>\n",
              "      <td>Other</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>504</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2311</td>\n",
              "      <td>4.0</td>\n",
              "      <td>992</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3245</td>\n",
              "      <td>1.0</td>\n",
              "      <td>357</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1519</td>\n",
              "      <td>4.0</td>\n",
              "      <td>159</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2275</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2809</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5614</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3219</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1296</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9046</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1216</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1169</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23868</td>\n",
              "      <td>3.0</td>\n",
              "      <td>581</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8830</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2392</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1312</td>\n",
              "      <td>20s</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Asian</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>927</td>\n",
              "      <td>1.0</td>\n",
              "      <td>707</td>\n",
              "      <td>5.0</td>\n",
              "      <td>556</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1062</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1014</td>\n",
              "      <td>2.0</td>\n",
              "      <td>628</td>\n",
              "      <td>1.0</td>\n",
              "      <td>991</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1259</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1153</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1388</td>\n",
              "      <td>5.0</td>\n",
              "      <td>740</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1181</td>\n",
              "      <td>4.0</td>\n",
              "      <td>547</td>\n",
              "      <td>2.0</td>\n",
              "      <td>575</td>\n",
              "      <td>1.0</td>\n",
              "      <td>754</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1140</td>\n",
              "      <td>5.0</td>\n",
              "      <td>323</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>583</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1889</td>\n",
              "      <td>20s</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>White</td>\n",
              "      <td>Agnostic</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA   QeE  QfA   QfE  QgA   QgE  QhA   QhE  QiA   QiE  QjA   QjE  QkA   QkE  QlA   QlE  QmA   QmE  QnA   QnE  QoA   QoE  \\\n",
              "0      0  3.0   363  4.0  1370  5.0   997  1.0  1024  2.0  1577  5.0   539  2.0   586  4.0  1095  5.0  1142  4.0  1287  4.0   883  4.0   851  2.0   851  5.0   816  2.0   579   \n",
              "1      1  5.0   647  5.0  1313  3.0  3387  5.0  2969  1.0  4320  3.0  2190  1.0   826  1.0  4082  5.0  1867  3.0  1264  5.0  2943  4.0  3927  1.0  4329  5.0  1828  1.0  1214   \n",
              "2      2  4.0  1623  1.0  1480  1.0  1021  4.0  3374  5.0  1333  1.0   531  4.0  1167  1.0  1016  3.0  2653  2.0  1569  5.0   998  5.0  2547  2.0   918  4.0  2153  2.0  1304   \n",
              "3      3  3.0   504  3.0  2311  4.0   992  3.0  3245  1.0   357  2.0  1519  4.0   159  3.0  2275  5.0  2809  4.0  5614  3.0  3219  4.0  1296  4.0  9046  4.0  1216  4.0  1169   \n",
              "4      4  1.0   927  1.0   707  5.0   556  2.0  1062  1.0  1014  2.0   628  1.0   991  1.0  1259  5.0  1153  5.0  1388  5.0   740  5.0  1181  4.0   547  2.0   575  1.0   754   \n",
              "\n",
              "   QpA    QpE  QqA   QqE  QrA   QrE  QsA   QsE  QtA   QtE age_group  education  engnat  familysize  gender  hand  married   race  religion  tp01  tp02  tp03  tp04  tp05  tp06  \\\n",
              "0  2.0    924  2.0   366  2.0   876  2.0   633  1.0  1115       30s          2       1           4  Female     1        3  White     Other     2     2     2     1     2     1   \n",
              "1  5.0   2414  5.0  1356  1.0  3039  4.0  4304  1.0  1346       20s          4       2           3  Female     1        1  Asian     Hindu     1     1     0     0     1     2   \n",
              "2  1.0   1131  5.0   937  4.0  1327  1.0  1170  1.0  1409       30s          3       1           3    Male     1        2  White     Other     2     3     1     5     3     4   \n",
              "3  4.0  23868  3.0   581  4.0  8830  4.0  2392  5.0  1312       20s          4       2           0  Female     1        1  Asian     Hindu     2     4     1     1     1     3   \n",
              "4  4.0   1140  5.0   323  5.0  1070  1.0   583  2.0  1889       20s          3       1           2    Male     1        2  White  Agnostic     1     1     1     6     0     2   \n",
              "\n",
              "   tp07  tp08  tp09  tp10  urban  voted  wf_01  wf_02  wf_03  wr_01  wr_02  wr_03  wr_04  wr_05  wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
              "0     7     4     4     3      1      2      0      0      0      0      1      0      0      1      0      1      1      0      1      0      1      1  \n",
              "1     3     4     0     4      3      2      0      0      0      0      1      0      1      1      0      1      1      0      1      0      1      1  \n",
              "2     2     6     1     3      2      1      0      0      1      1      1      0      1      1      0      1      1      1      1      0      1      1  \n",
              "3     1     3     1     3      3      1      0      0      0      0      1      0      0      0      0      0      1      0      1      0      1      1  \n",
              "4     0     6     2     6      1      1      0      1      0      1      1      0      1      1      1      1      1      0      1      1      1      1  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_columns', 220)\n",
        "pd.set_option('display.width', 180)\n",
        "\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    start = start.resolve()\n",
        "    for p in [start] + list(start.parents):\n",
        "        if (p / \"requirements.txt\").exists() or (p / \"README.md\").exists():\n",
        "            return p\n",
        "    raise FileNotFoundError(\"프로젝트 루트를 찾지 못했습니다. vote-AI 루트에 requirements.txt 또는 README.md가 있는지 확인하세요.\")\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
        "\n",
        "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
        "test  = pd.read_csv(DATA_DIR / \"test_x.csv\")\n",
        "sub   = pd.read_csv(DATA_DIR / \"sample_submission.csv\")\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"train:\", train.shape, \"test:\", test.shape, \"sub:\", sub.shape)\n",
        "train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 스키마 검증\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train(no voted) cols: 77\n",
            "test cols          : 77\n",
            "same columns set   : True\n",
            "same column order  : True\n"
          ]
        }
      ],
      "source": [
        "train_cols = [c for c in train.columns if c != 'voted']\n",
        "test_cols  = list(test.columns)\n",
        "\n",
        "print('train(no voted) cols:', len(train_cols))\n",
        "print('test cols          :', len(test_cols))\n",
        "print('same columns set   :', set(train_cols) == set(test_cols))\n",
        "print('same column order  :', train_cols == test_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) 타깃(y) 인코딩\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw voted unique: [np.int64(1), np.int64(2)]\n",
            "y counts (1=Yes):\n",
            "voted\n",
            "0    24898\n",
            "1    20634\n",
            "Name: count, dtype: int64\n",
            "positive ratio: 0.45317578845647016\n"
          ]
        }
      ],
      "source": [
        "y = (train['voted'] == 1).astype('int32')\n",
        "X = train.drop(columns=['voted'])\n",
        "\n",
        "print(\"raw voted unique:\", sorted(train['voted'].unique()))\n",
        "print(\"y counts (1=Yes):\")\n",
        "print(y.value_counts())\n",
        "print(\"positive ratio:\", float(y.mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) 그룹 컬럼 탐지\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q_A: 20 ['QaA', 'QbA', 'QcA', 'QdA', 'QeA', 'QfA', 'QgA', 'QhA', 'QiA', 'QjA'] ...\n",
            "Q_E: 20 ['QaE', 'QbE', 'QcE', 'QdE', 'QeE', 'QfE', 'QgE', 'QhE', 'QiE', 'QjE'] ...\n",
            "TP : 10 ['tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10']\n",
            "WR : 13 ['wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05'] ...\n",
            "WF : 3 ['wf_01', 'wf_02', 'wf_03'] \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cols = list(X.columns)\n",
        "\n",
        "# Q 계열: QaA/QaE 형태로 20개씩 존재\n",
        "q_like = [c for c in cols if re.match(r\"^Q\", c)]\n",
        "\n",
        "QA_cols = sorted([c for c in q_like if re.fullmatch(r\"Q[a-z]A\", c)])\n",
        "QE_cols = sorted([c for c in q_like if re.fullmatch(r\"Q[a-z]E\", c)])\n",
        "\n",
        "TP_cols = sorted([c for c in cols if re.fullmatch(r\"tp\\d{2}\", c)])\n",
        "WR_cols = sorted([c for c in cols if re.fullmatch(r\"wr_?\\d{2}\", c)])\n",
        "WF_cols = sorted([c for c in cols if re.fullmatch(r\"wf_?\\d{2}\", c)])\n",
        "\n",
        "print(\"Q_A:\", len(QA_cols), QA_cols[:10], \"...\" if len(QA_cols)>10 else \"\")\n",
        "print(\"Q_E:\", len(QE_cols), QE_cols[:10], \"...\" if len(QE_cols)>10 else \"\")\n",
        "print(\"TP :\", len(TP_cols), TP_cols)\n",
        "print(\"WR :\", len(WR_cols), WR_cols[:5],  \"...\" if len(WR_cols)>5 else \"\")\n",
        "print(\"WF :\", len(WF_cols), WF_cols[:5],  \"...\" if len(WF_cols)>5 else \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) 문자열 섞임 자동 탐지(예: '30s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object cols: ['age_group', 'gender', 'race', 'religion']\n",
            "mixed  cols: []\n",
            "\n",
            "#cat_base: 4  #num_base: 73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/wb/_9w5mhfj4kl4vxshnbz2n7p80000gn/T/ipykernel_70811/1041077928.py:21: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
            "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
            "  object_cols = X.select_dtypes(include='object').columns.tolist()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def find_mixed_type_columns(df: pd.DataFrame, numeric_cols: list[str]):\n",
        "    mixed_cols = []\n",
        "    examples = {}\n",
        "\n",
        "    for c in numeric_cols:\n",
        "        s = df[c]\n",
        "        coerced = pd.to_numeric(s, errors='coerce')\n",
        "\n",
        "        if coerced.isna().sum() > s.isna().sum():\n",
        "            mixed_cols.append(c)\n",
        "            mask = coerced.isna() & s.notna()\n",
        "            examples[c] = s.loc[mask].astype(str).head(5).tolist()\n",
        "\n",
        "    return mixed_cols, examples\n",
        "\n",
        "\n",
        "# 1️ dtype 기준 1차 분류\n",
        "object_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "numeric_cols = [c for c in X.columns if c not in object_cols]\n",
        "\n",
        "# 2️ 숫자 컬럼에 문자열 섞임 점검\n",
        "mixed_cols, mixed_examples = find_mixed_type_columns(X, numeric_cols)\n",
        "\n",
        "# 3️ 섞임이 있으면 범주형으로 승격\n",
        "cat_cols_base = sorted(set(object_cols + mixed_cols))\n",
        "num_cols_base = [c for c in X.columns if c not in cat_cols_base]\n",
        "\n",
        "# 4️ 확인 출력\n",
        "print(\"object cols:\", object_cols)\n",
        "print(\"mixed  cols:\", mixed_cols)\n",
        "if mixed_cols:\n",
        "    print(\"mixed examples:\")\n",
        "    for k, v in list(mixed_examples.items())[:5]:\n",
        "        print(\" -\", k, \":\", v)\n",
        "\n",
        "print(\"\\n#cat_base:\", len(cat_cols_base), \" #num_base:\", len(num_cols_base))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) 파생변수 생성(누수 없는 row-wise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After FE shapes: (45532, 102) (11383, 102)\n",
            "float64    63\n",
            "int64      35\n",
            "str         4\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "ZERO_AS_MISSING = ['education', 'engnat', 'hand', 'urban']\n",
        "\n",
        "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # 0=무응답 처리 -> 결측\n",
        "    for c in ZERO_AS_MISSING:\n",
        "        if c in df.columns:\n",
        "            df.loc[df[c] == 0, c] = np.nan\n",
        "\n",
        "    # 범주형 통일  = 범주형(문자열)은 딥러닝에서 StringLookup → Embedding으로 처리할 거라 타입을 문자열로 통일합니다.\n",
        "    for c in cat_cols_base:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str)\n",
        "\n",
        "    # 수치형 강제 변환 \t=\t딥러닝 입력에서 “숫자여야 하는데 문자열이 섞인 사고”를 원천 차단합니다.\n",
        "    for c in num_cols_base:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "    # Q_E: log1p + 요약\n",
        "    if len(QE_cols) > 0:\n",
        "        qe = df[QE_cols].copy()\n",
        "        qe = np.log1p(qe.clip(lower=0))\n",
        "\n",
        "        df[\"qe_sum\"]    = qe.sum(axis=1)\n",
        "        df[\"qe_mean\"]   = qe.mean(axis=1)\n",
        "        df[\"qe_std\"]    = qe.std(axis=1)\n",
        "        df[\"qe_max\"]    = qe.max(axis=1)\n",
        "        df[\"qe_min\"]    = qe.min(axis=1)\n",
        "        df[\"qe_median\"] = qe.median(axis=1)\n",
        "\n",
        "        df[\"qe_fast_ratio\"] = (qe < 1.0).mean(axis=1)\n",
        "        df[\"qe_slow_ratio\"] = (qe > 4.0).mean(axis=1)\n",
        "\n",
        "        df[QE_cols] = qe\n",
        "\n",
        "    # Q_A: 요약 + 스타일\n",
        "    if len(QA_cols) > 0:\n",
        "        qa = df[QA_cols].copy().apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "        df[\"qa_mean\"] = qa.mean(axis=1)\n",
        "        df[\"qa_std\"]  = qa.std(axis=1)\n",
        "        df[\"qa_min\"]  = qa.min(axis=1)\n",
        "        df[\"qa_max\"]  = qa.max(axis=1)\n",
        "\n",
        "        df[\"qa_extreme_ratio\"] = ((qa == 1) | (qa == 5)).mean(axis=1)\n",
        "        df[\"qa_neutral_ratio\"] = (qa == 3).mean(axis=1)\n",
        "\n",
        "    # TP: 요약 + 간단 차이\n",
        "    if len(TP_cols) > 0:\n",
        "        tp = df[TP_cols].copy().apply(pd.to_numeric, errors='coerce')\n",
        "        df[\"tp_mean\"] = tp.mean(axis=1)\n",
        "        df[\"tp_std\"]  = tp.std(axis=1)\n",
        "\n",
        "        if \"tp01\" in df.columns and \"tp06\" in df.columns:\n",
        "            df[\"tp_extro_minus_intro\"] = pd.to_numeric(df[\"tp01\"], errors='coerce') - pd.to_numeric(df[\"tp06\"], errors='coerce')\n",
        "        if \"tp09\" in df.columns and \"tp04\" in df.columns:\n",
        "            df[\"tp_stable_minus_anx\"]  = pd.to_numeric(df[\"tp09\"], errors='coerce') - pd.to_numeric(df[\"tp04\"], errors='coerce')\n",
        "\n",
        "    # WR/WF: 요약\n",
        "    if len(WR_cols) > 0:\n",
        "        wr = df[WR_cols].copy().apply(pd.to_numeric, errors='coerce')\n",
        "        df[\"wr_yes_count\"] = wr.sum(axis=1)\n",
        "        df[\"wr_yes_ratio\"] = wr.mean(axis=1)\n",
        "\n",
        "    if len(WF_cols) > 0:\n",
        "        wf = df[WF_cols].copy().apply(pd.to_numeric, errors='coerce')\n",
        "        df[\"wf_yes_count\"] = wf.sum(axis=1)\n",
        "        df[\"wf_yes_ratio\"] = wf.mean(axis=1)\n",
        "\n",
        "    if (\"wr_yes_count\" in df.columns) and (\"wf_yes_count\" in df.columns):\n",
        "        df[\"wr_minus_wf\"] = df[\"wr_yes_count\"] - df[\"wf_yes_count\"]\n",
        "\n",
        "    # 결측 인디케이터 + NaN → 0\n",
        "    numeric_cols_now = [c for c in df.columns if df[c].dtype != 'object']\n",
        "    df[\"num_missing_count\"] = df[numeric_cols_now].isna().sum(axis=1)\n",
        "    df[\"num_missing_ratio\"] = df[numeric_cols_now].isna().mean(axis=1)\n",
        "    df[numeric_cols_now] = df[numeric_cols_now].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "X_fe = add_features(X)\n",
        "T_fe = add_features(test)\n",
        "\n",
        "print(\"After FE shapes:\", X_fe.shape, T_fe.shape)\n",
        "print(X_fe.dtypes.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) 최종 입력 컬럼 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#cat_cols: 4  #num_cols: 98\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/wb/_9w5mhfj4kl4vxshnbz2n7p80000gn/T/ipykernel_70811/100249664.py:1: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
            "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
            "  cat_cols = X_fe.select_dtypes(include='object').columns.tolist()\n"
          ]
        }
      ],
      "source": [
        "cat_cols = X_fe.select_dtypes(include='object').columns.tolist()\n",
        "num_cols = [c for c in X_fe.columns if c not in cat_cols]\n",
        "\n",
        "print(\"#cat_cols:\", len(cat_cols), \" #num_cols:\", len(num_cols))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) 모델: Embedding + MLP (BatchNorm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model_from_fold_train(\n",
        "    X_fold_train: pd.DataFrame,\n",
        "    cat_cols: list[str],\n",
        "    num_cols: list[str],\n",
        "    *,\n",
        "    emb_dim=24,\n",
        "    hidden1=512,\n",
        "    hidden2=256,\n",
        "    hidden3=128,\n",
        "    dropout=0.25,\n",
        "    lr=1e-3,\n",
        "):\n",
        "    inputs = {}\n",
        "    encoded = []\n",
        "\n",
        "    for c in cat_cols:\n",
        "        inp = keras.Input(shape=(1,), name=c, dtype=tf.string)\n",
        "        lookup = layers.StringLookup(output_mode='int')\n",
        "        lookup.adapt(X_fold_train[c].astype(str).values)  # fold-train only\n",
        "\n",
        "        vocab_size = lookup.vocabulary_size()\n",
        "        dim = min(emb_dim, max(2, int(np.ceil(vocab_size**0.25) * 2)))\n",
        "\n",
        "        x = lookup(inp)\n",
        "        x = layers.Embedding(vocab_size, dim)(x)\n",
        "        x = layers.Reshape((dim,))(x)\n",
        "\n",
        "        inputs[c] = inp\n",
        "        encoded.append(x)\n",
        "\n",
        "    if len(num_cols) > 0:\n",
        "        num_inp = keras.Input(shape=(len(num_cols),), name=\"num\", dtype=tf.float32)\n",
        "        norm = layers.Normalization()\n",
        "        norm.adapt(X_fold_train[num_cols].values.astype('float32'))  # fold-train only\n",
        "        x_num = norm(num_inp)\n",
        "\n",
        "        inputs[\"num\"] = num_inp\n",
        "        encoded.append(x_num)\n",
        "\n",
        "    x = layers.Concatenate()(encoded) if len(encoded) > 1 else encoded[0]\n",
        "\n",
        "    x = layers.Dense(hidden1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(hidden2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(hidden3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    out = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[keras.metrics.AUC(name='auc')],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8-1) tf.data 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def df_to_dataset(df: pd.DataFrame, y=None, cat_cols=None, num_cols=None, batch_size=512, shuffle=False, seed=42):\n",
        "    cat_cols = cat_cols or []\n",
        "    num_cols = num_cols or []\n",
        "\n",
        "    features = {}\n",
        "    for c in cat_cols:\n",
        "        features[c] = df[c].astype(str).values\n",
        "    if len(num_cols) > 0:\n",
        "        features[\"num\"] = df[num_cols].values.astype('float32')\n",
        "\n",
        "    if y is None:\n",
        "        ds = tf.data.Dataset.from_tensor_slices(features)\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((features, y.values.astype('float32')))\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=min(len(df), 10000), seed=seed, reshuffle_each_iteration=True)\n",
        "\n",
        "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) 5-Fold CV + Seed 앙상블\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[seed 41] fold 0 AUC=0.772476\n",
            "[seed 41] fold 1 AUC=0.762707\n",
            "[seed 41] fold 2 AUC=0.750513\n",
            "[seed 41] fold 3 AUC=0.753663\n",
            "[seed 41] fold 4 AUC=0.761588\n",
            "\n",
            "[seed 41] OOF AUC: 0.7600277397751615\n",
            "------------------------------------------------------------\n",
            "[seed 42] fold 0 AUC=0.770866\n",
            "[seed 42] fold 1 AUC=0.761768\n",
            "[seed 42] fold 2 AUC=0.748859\n",
            "[seed 42] fold 3 AUC=0.753030\n",
            "[seed 42] fold 4 AUC=0.759847\n",
            "\n",
            "[seed 42] OOF AUC: 0.7586434605307519\n",
            "------------------------------------------------------------\n",
            "[seed 43] fold 0 AUC=0.773247\n",
            "[seed 43] fold 1 AUC=0.760214\n",
            "[seed 43] fold 2 AUC=0.751659\n",
            "[seed 43] fold 3 AUC=0.752975\n",
            "[seed 43] fold 4 AUC=0.761520\n",
            "\n",
            "[seed 43] OOF AUC: 0.7595963596998678\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Ensemble OOF AUC: 0.7620204138419305\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 25\n",
        "BATCH  = 512\n",
        "SEEDS = [41, 42, 43]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_seed_list = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    oof = np.zeros(len(X_fe), dtype='float32')\n",
        "    scores = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_fe, y)):\n",
        "        X_tr = X_fe.iloc[tr_idx].reset_index(drop=True)\n",
        "        y_tr = y.iloc[tr_idx].reset_index(drop=True)\n",
        "        X_va = X_fe.iloc[va_idx].reset_index(drop=True)\n",
        "        y_va = y.iloc[va_idx].reset_index(drop=True)\n",
        "\n",
        "        tf.keras.utils.set_random_seed(seed + fold)\n",
        "\n",
        "        model = build_model_from_fold_train(X_tr, cat_cols=cat_cols, num_cols=num_cols, lr=1e-3, dropout=0.25)\n",
        "\n",
        "        tr_ds = df_to_dataset(X_tr, y_tr, cat_cols, num_cols, batch_size=BATCH, shuffle=True, seed=seed+fold)\n",
        "        va_ds = df_to_dataset(X_va, y_va, cat_cols, num_cols, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "        callbacks = [\n",
        "            keras.callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=4, restore_best_weights=True),\n",
        "            keras.callbacks.ReduceLROnPlateau(monitor='val_auc', mode='max', factor=0.5, patience=2, min_lr=1e-5),\n",
        "        ]\n",
        "\n",
        "        model.fit(tr_ds, validation_data=va_ds, epochs=EPOCHS, verbose=0, callbacks=callbacks)\n",
        "\n",
        "        pred_va = model.predict(df_to_dataset(X_va, None, cat_cols, num_cols, batch_size=BATCH), verbose=0).reshape(-1)\n",
        "        pred_va = np.nan_to_num(pred_va, nan=0.5)\n",
        "\n",
        "        auc = roc_auc_score(y_va, pred_va)\n",
        "        oof[va_idx] = pred_va\n",
        "        scores.append(auc)\n",
        "\n",
        "        print(f\"[seed {seed}] fold {fold} AUC={auc:.6f}\")\n",
        "\n",
        "    oof_seed_list.append(oof)\n",
        "    print(f\"\\n[seed {seed}] OOF AUC:\", roc_auc_score(y, oof))\n",
        "    print(\"-\"*60)\n",
        "\n",
        "oof_ens = np.mean(np.vstack(oof_seed_list), axis=0)\n",
        "print(\"\\n✅ Ensemble OOF AUC:\", roc_auc_score(y, oof_ens))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) 전체 학습 → test 예측 → 제출 파일 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01651e28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/admin/Downloads/AI 헬스케어 수업/oz코딩 수업/해커톤 (1)/vote-AI/submission_FINAL.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>voted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.343607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.096420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.571807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.755422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.297271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      voted\n",
              "0  0.343607\n",
              "1  0.096420\n",
              "2  0.571807\n",
              "3  0.755422\n",
              "4  0.297271"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ===============================\n",
        "# 최종 제출 파일 생성 (형식 보정)\n",
        "# ===============================\n",
        "\n",
        "# pred_test는 이미 올바른 Yes 확률\n",
        "assert pred_test.ndim == 1\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"voted\": pred_test\n",
        "})\n",
        "\n",
        "# 절대 index 저장하지 말 것\n",
        "out_path = PROJECT_ROOT / \"submission_FINAL.csv\"\n",
        "submission.to_csv(out_path, index=False)\n",
        "\n",
        "print(\"Saved:\", out_path)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69177f2e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "voteai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
