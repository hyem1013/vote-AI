
1/29 실험 요약 (Feature 중심 정리)

1. 실험 목적
	•	설문 데이터를 이용해 “투표함(voted=2)”일 확률을 예측
	•	최종 제출 모델은 딥러닝 모델만 사용
	•	다만, 어떤 변수가 중요한지 판단하기 위해 LightGBM을 보조 도구로 사용
	•	목표는 모델 복잡도보다 설문 응답을 잘 요약하는 피처 설계

⸻

2. 전체 접근 방식 요약

설문 문항(Q_A, Q_E, tp, wr/wf)을 그대로 넣는 대신,
**“이 사람이 어떤 방식으로 설문에 응답했는가”**를 요약하는 가상변수를 만들고
이를 딥러닝 모델이 학습하도록 구성했다.

실험을 진행하면서 느낀 점은,
	•	모델 구조를 바꾸는 것보다
	•	피처를 어떻게 요약하느냐가 성능에 훨씬 큰 영향을 줬다는 것이다.

⸻

3. 시도한 주요 피처 설계

3.1 설문 응답 태도 요약 (Q_A 기반)

개별 문항 점수보다 답변 습관과 태도를 보고자 했다.

사용한 피처
	•	긍정 성향 문항 평균
	•	부정 성향 문항 평균
(역문항은 방향을 맞추기 위해 6 - 값으로 변환)
	•	전체 문항 중 중립(3번) 선택 비율
	•	전체 문항 중 극단값(1 또는 5) 선택 비율
	•	전체 문항 중 무응답 비율

간단한 코드 예시

qa = df[QA_cols]

pos_mean = qa[pos_cols].mean(axis=1)
neg_mean = (6 - qa[neg_cols]).mean(axis=1)

neutral_ratio = (qa == 3).mean(axis=1)
extreme_ratio = ((qa == 1) | (qa == 5)).mean(axis=1)
missing_ratio = qa.isna().mean(axis=1)

의도
	•	설문 “내용” 자체보다
얼마나 극단적인지 / 중립적인지 / 성실한지를 반영하려는 목적

➡️ 성능에 가장 꾸준히 긍정적인 영향을 준 핵심 피처 그룹

⸻

3.2 응답 시간 요약 (Q_E 기반)

응답 시간을 통해
대충 찍은 응답인지, 생각하고 답한 응답인지를 구분하고자 했다.

사용한 피처
	•	전체 문항 응답 시간 합
	•	평균 응답 시간
	•	응답 시간의 분산
	•	매우 빠르게 답한 문항 비율
	•	매우 느리게 답한 문항 비율

간단한 코드 예시

qe = df[QE_cols].clip(lower=0)

delay_sum = qe.sum(axis=1)
delay_mean = qe.mean(axis=1)
delay_std = qe.std(axis=1)

fast_ratio = (qe < 1.0).mean(axis=1)
slow_ratio = (qe > 4.0).mean(axis=1)

의도
	•	응답 성실도 / 집중도 차이를 반영하기 위한 피처

➡️ Q_A 태도 피처와 결합했을 때 성능 상승에 도움

⸻

3.3 성격 요약 (tp 문항)

tp01~tp10을 그대로 쓰는 대신,
성향의 방향 + 강도로 요약했다.

방식
	•	서로 반대되는 문항 간 차이로 성향 방향 계산
	•	해당 차이의 절댓값으로 성향 강도 계산

예시

extroversion = tp01 - tp06
extro_strength = abs(extroversion)

의도
	•	“외향적인지 내향적인지”뿐 아니라
성향이 얼마나 뚜렷한 사람인지까지 표현

➡️ 단독 효과는 크지 않았지만, 다른 피처와 결합 시 안정성에 기여

⸻

3.4 단어 인지(wr / wf) 요약

wr/wf 원본을 그대로 쓰기보다 신뢰도 지표로 요약

사용한 피처
	•	실제 단어 개수 (wr_sum)
	•	가짜 단어 개수 (wf_sum)
	•	차이 값 (wr_sum - wf_sum)

의도
	•	응답자가 정보를 얼마나 구분해서 판단하는지에 대한 간접 지표

➡️ 일부 모델에서는 효과 있었으나, 항상 일관되지는 않음

⸻

3.5 무응답 indicator

education / urban / hand / married 에서
0 = 무응답으로 처리된 값들에 대해 indicator 생성

df["education_is_missing"] = (df["education"] == 0).astype(int)

➡️ 보조적인 피처로는 도움, 단독 효과는 크지 않음

⸻

4. 사용한 모델과 실험 흐름

4.1 기본 모델: Embedding + MLP
	•	범주형 변수 → Embedding
	•	수치형 변수 → 정규화 후 MLP
	•	BatchNorm + Dropout 사용
	•	seed 변경 후 앙상블

➡️ 가장 안정적이고, 실험 기준점으로 사용한 모델

⸻

4.2 LightGBM은 “피처 선별 도구”로만 사용
	•	최종 제출에는 사용하지 않음
	•	목적:
많이 만든 피처 중 실제로 의미 있는 것만 추리기

사용 방식
	1.	모든 피처로 LightGBM 학습
	2.	feature importance 기준 상위 피처 선택
	3.	선택된 피처만 딥러닝 모델에 투입

➡️ 잡음 피처를 줄였을 때 딥러닝 성능이 개선되는 경우가 있었음

⸻

5. 점수가 떨어졌던 시도들에 대한 정리

실험 과정에서 다음과 같은 경우 점수가 오히려 하락했다.
	•	원본 문항(Q_A, Q_E, tp)을 과도하게 많이 사용했을 때
	•	비슷한 의미의 요약 피처를 너무 많이 중복 생성했을 때
	•	LightGBM으로 뽑은 피처 수를 너무 줄였을 때
	•	FT-Transformer 등 복잡한 모델을 쓰되 피처 정리가 부족했을 때

➡️ 모델 복잡도 ↑ = 성능 ↑ 가 아님을 확인

6.	성능이 실제로 개선됐던 시도 (TOP 3)

6.1 설문 응답 태도 요약(Q_A)을 평균·비율로 단순화한 경우

가장 안정적으로 성능이 올라간 시도였다.
개별 문항을 모두 넣는 대신, 응답 “스타일”만 요약해서 사용했다.

핵심 아이디어
	•	질문 하나하나의 의미보다
	•	이 사람이 전반적으로 어떻게 답하는지가 더 중요하다고 판단

간단한 코드 예시

qa = df[QA_cols]

pos_mean = qa[pos_cols].mean(axis=1)
neg_mean = (6 - qa[neg_cols]).mean(axis=1)

neutral_ratio = (qa == 3).mean(axis=1)
extreme_ratio = ((qa == 1) | (qa == 5)).mean(axis=1)

결과
	•	거의 모든 딥러닝 모델에서 성능이 안정적으로 상승
	•	이번 실험 전체에서 가장 중요한 피처 그룹이라고 판단

⸻

6.2 응답 시간(Q_E)을 합·평균·비율로 요약한 경우

응답 시간을 그대로 쓰는 것보다
“얼마나 성실하게 응답했는지”를 요약하는 방식이 효과적이었다.

간단한 코드 예시

qe = df[QE_cols].clip(lower=0)

delay_sum = qe.sum(axis=1)
delay_mean = qe.mean(axis=1)
delay_std = qe.std(axis=1)

fast_ratio = (qe < 1.0).mean(axis=1)
slow_ratio = (qe > 4.0).mean(axis=1)

결과
	•	Q_A 태도 피처와 함께 사용했을 때 성능 상승
	•	단독보다는 “보조 피처”로 역할이 명확했음

⸻

6.3 LightGBM으로 피처를 걸러낸 뒤 딥러닝에 투입한 경우

모든 피처를 딥러닝에 넣기보다
중요한 것만 남기는 과정이 필요하다고 판단했다.

사용 방식 요약
	1.	모든 피처로 LightGBM 학습
	2.	feature importance 상위 피처 선택
	3.	선택된 피처만 딥러닝 모델에 사용

개념 코드 예시

lgbm.fit(X, y)
important_features = top_k_features(lgbm)
X_selected = X[important_features]

결과
	•	잡음 피처를 줄였을 때 딥러닝 성능이 소폭 개선
	•	특히 피처 수가 많아졌을 때 효과가 있었음

⸻
	7.	성능이 오히려 떨어졌던 시도 (TOP 3)

7.1 원본 설문 문항(Q_A, Q_E, tp)을 그대로 많이 사용한 경우

“정보를 최대한 많이 주면 좋지 않을까?”라는 생각으로
원본 문항을 거의 그대로 넣어본 적이 있었다.

결과
	•	오히려 성능 하락
	•	모델이 중요한 신호를 못 잡고 노이즈에 흔들리는 느낌

판단
	•	이 대회에서는 원본 문항 자체가 아니라
요약된 응답 태도가 더 중요하다고 결론

⸻

7.2 의미가 겹치는 요약 피처를 과도하게 만든 경우

비슷한 개념의 평균, 비율, 합계 피처를 너무 많이 만들었을 때
오히려 성능이 떨어지는 경우가 있었다.

예시
	•	긍정 평균, 긍정 합, 긍정 중앙값을 동시에 사용
	•	응답 시간 평균, 로그 평균, 정규화 평균을 동시에 사용

결과
	•	피처 수만 늘고 성능은 개선되지 않음

판단
	•	“다양함”보다 “대표성 있는 요약”이 더 중요

⸻

7.3 모델 구조를 과도하게 복잡하게 만든 경우

FT-Transformer 등 복잡한 구조를 도입했지만
피처 정리가 충분하지 않은 상태에서는 성능이 오히려 하락했다.

--------------------------------------------------------------------------------------
<1/28일>
실험 정리 (간단 요약)

1. 전체 흐름
	•	설문 데이터라서 문항 하나하나를 그대로 쓰기보다는
	•	응답 성향, 태도, 일관성 같은 걸 요약한 가상변수를 만들었음
	•	모델은 MLP 계열 딥러닝과 FT-Transformer를 시도함
	•	목표는 voted == 2 일 확률을 예측하는 것

2. 가상변수(Feature Engineering) 정리

Q_A (태도 관련 문항)
	•	긍정 문항, 부정 문항이 섞여 있어서
→ 부정 문항은 6 - 값으로 뒤집어서 통일
	•	그 다음,
	•	긍정 문항 평균 → pos_att
	•	부정 문항 평균 → neg_att

👉 개인이 전반적으로 긍정적인지 / 부정적인지를 평균값으로 표현

응답 스타일 관련 비율 변수
•	neutral_ratio
	•	Q_A 문항 중에서 값이 3(중립)인 문항 개수
	•	전체 Q_A 문항 개수로 나눈 비율
	•	→ 중립적으로 답하는 성향

•	confident_ratio
	•	Q_A 문항 중에서 1 또는 5(극단값)로 답한 개수
	•	전체 문항 수로 나눈 비율
	•	→ 확신 강하게 답하는 성향

•	qa_missing_ratio
	•	Q_A 문항 중 무응답(NaN) 개수
	•	전체 문항 수로 나눈 비율
	•	→ 설문에 성실하지 않은 성향

👉 전부 “문항 개수 대비 비율”로 계산함


⸻

성격(Big5, TIPI)
•	각 성향마다 두 문항이 있음
	•	예를 들어 외향성:
	•	Ex = tp01 - tp06
	•	→ 성향의 방향
	•	Ex_strength = |tp01 - tp06|
	•	→ 성향의 강도

👉 다섯 성향 모두 같은 방식으로 처리

⸻

단어 인지 관련 (WR / WF)
•	wr_sum
	•	실제 단어에서 Yes 선택한 개수의 합

•	wf_sum
	•	가짜 단어에서 Yes 선택한 개수의 합
•	word_credibility = wr_sum - wf_sum

👉 설문을 얼마나 신뢰할 수 있는지 보는 지표로 사용

⸻

인구통계 관련 처리
•	age_group, urban 등은 순서형 변수로 변환

•	education, married, hand 같은 항목은
	•	값이 0이면 무응답으로 보고
	•	is_missing 같은 indicator 변수 추가

👉 무응답 자체도 정보라고 판단

⸻

3. 사용한 모델

(1) Embedding + MLP
	•	범주형 변수는 Embedding
	•	수치형 변수는 그대로 입력
	•	BatchNorm + Dropout 사용
	•	AdamW optimizer
	•	클래스 불균형 때문에 class_weight 적용

👉 가장 기본적인 딥러닝 베이스라인

⸻

(2) FT-Transformer
	•	탭형 데이터용 Transformer 구조
	•	변수 간 상호작용을 더 잘 학습하려는 목적
	•	5-fold 교차검증
	•	EarlyStopping 사용
	•	seed 여러 개로 앙상블도 시도

👉 MLP보다 복잡하지만 표현력은 더 좋을 수 있다고 판단

⸻

4. 라벨과 제출 방식
	•	원래 voted 값:
	•	1 = Yes
	•	2 = No
	•	내부 학습에서는
	•	voted == 2 → 1
	•	voted == 1 → 0
	•	제출할 때는
	•	voted가 2일 확률만 제출

⸻

5. 현재 상태 정리
	•	가상변수는 1등 코드에서 사용한 아이디어들을 참고해서 구성
	•	모델은 MLP → FT-Transformer 순으로 확장
	•	현재 점수는 약 0.75 ~ 0.76대
	•	더 올리기 위해:
	•	feature 단순화
	•	학습 시간 줄이고 seed 앙상블 확대 고려 중