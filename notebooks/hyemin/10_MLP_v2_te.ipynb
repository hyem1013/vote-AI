{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10_MLP_v2_te ìš”ì•½\n",
    "\n",
    "- ëª¨ë¸: SimpleMLPWithEmbedding + Target Encoding\n",
    "- í”¼ì²˜: Q_A/Q_E log/WR/WF + demo flags + QA/QE ì§‘ê³„ + TP Big5 + vocab + interaction\n",
    "- í•™ìŠµ/í‰ê°€: KFold 5, seed=42\n",
    "- ì œì¶œíŒŒì¼: submission_10_MLP_v2_te.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae3bff",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3ff998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG - CPU ìµœì í™”\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588eda3",
   "metadata": {},
   "source": [
    "## 2. ì„¤ì •ê°’ ë° ì‹œë“œ ê³ ì •\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72c9026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ Device: cpu\n",
      "ğŸ“Š Config: 5-Fold, 50 epochs, batch=512\n",
      "\n",
      "============================================================\n",
      "ğŸ“‚ 1. ë°ì´í„° ë¡œë”©\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 512  # í° ë°°ì¹˜ = ë¹ ë¥¸ í•™ìŠµ\n",
    "EPOCHS = 50\n",
    "PATIENCE = 8\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ Device: {DEVICE}\")\n",
    "print(f\"ğŸ“Š Config: {N_FOLDS}-Fold, {EPOCHS} epochs, batch={BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. ë°ì´í„° ë¡œë”©\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‚ 1. ë°ì´í„° ë¡œë”©\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41b955",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d5caae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (45532, 78), Test: (11383, 77)\n",
      "íƒ€ê²Ÿ ë¶„í¬: íˆ¬í‘œì•ˆí•¨=54.7%\n",
      "\n",
      "============================================================\n",
      "ğŸ”§ 2. ì´ìƒì¹˜/ë¬´ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ”¨ 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜ ì •ì˜\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test_raw = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "# íƒ€ê²Ÿ ìƒì„±\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "print(f\"íƒ€ê²Ÿ ë¶„í¬: íˆ¬í‘œì•ˆí•¨={train_raw['voted_bin'].mean():.1%}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. ì´ìƒì¹˜/ë¬´ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”§ 2. ì´ìƒì¹˜/ë¬´ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "def clean_data(df, is_train=True):\n",
    "    \"\"\"\n",
    "    ì´ìƒì¹˜ì™€ ë¬´ì‘ë‹µì„ ì²´ê³„ì ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # 2-1. ë¬´ì‘ë‹µ ì²˜ë¦¬ (0 â†’ NaN)\n",
    "    # -----------------------------------------\n",
    "    zero_to_nan_cols = ['education', 'engnat', 'hand', 'married', 'urban']\n",
    "    for col in zero_to_nan_cols:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # 2-2. familysize ì²˜ë¦¬\n",
    "    # -----------------------------------------\n",
    "    if 'familysize' in df.columns:\n",
    "        # 0, ê·¹ë‹¨ê°’ â†’ NaN\n",
    "        df.loc[df['familysize'] == 0, 'familysize'] = np.nan\n",
    "        df.loc[df['familysize'] > 15, 'familysize'] = np.nan\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # 2-3. TP ì„±ê²© ì²˜ë¦¬ (0 â†’ NaN)\n",
    "    # -----------------------------------------\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    for col in tp_cols:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # 2-4. Q_E ì‘ë‹µì‹œê°„ í´ë¦¬í•‘ (100ms ~ 60ì´ˆ)\n",
    "    # -----------------------------------------\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    for col in qe_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].clip(lower=100, upper=60000)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¨ 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜ ì •ì˜\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a93ce",
   "metadata": {},
   "source": [
    "## 4. í”¼ì²˜ ìƒì„± í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca13839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¯ 4. Target Encoding í•¨ìˆ˜ ì •ì˜\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ 5. í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜\n",
      "============================================================\n",
      "ìˆ˜ì¹˜í˜• í”¼ì²˜: 113\n",
      "Target Encoding: 7\n",
      "ë²”ì£¼í˜• í”¼ì²˜: 3\n",
      "ì´: 123\n",
      "\n",
      "============================================================\n",
      "ğŸ—ï¸ 6. Dataset & Model ì •ì˜\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ 8. í•™ìŠµ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 1/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5021, val_auc=0.77789, best=0.77789\n",
      "    Early stopping at epoch 18\n",
      "  âœ… Fold 1 AUC: 0.77789\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 2/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5017, val_auc=0.76792, best=0.76792\n",
      "    Epoch 20: loss=0.4833, val_auc=0.76505, best=0.76864\n",
      "    Early stopping at epoch 21\n",
      "  âœ… Fold 2 AUC: 0.76864\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 3/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.4978, val_auc=0.76092, best=0.76239\n",
      "    Early stopping at epoch 16\n",
      "  âœ… Fold 3 AUC: 0.76239\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 4/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5008, val_auc=0.75953, best=0.75953\n",
      "    Epoch 20: loss=0.4802, val_auc=0.75986, best=0.76111\n",
      "    Early stopping at epoch 23\n",
      "  âœ… Fold 4 AUC: 0.76111\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 5/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.4983, val_auc=0.76847, best=0.76847\n",
      "    Early stopping at epoch 19\n",
      "  âœ… Fold 5 AUC: 0.76861\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ìµœì¢… ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ† OOF AUC: 0.76740\n",
      "ğŸ“Š Fold AUCs: ['0.77789', '0.76864', '0.76239', '0.76111', '0.76861']\n",
      "ğŸ“Š Mean Â± Std: 0.76773 Â± 0.00595\n",
      "\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: submission_final(ì œì¶œ).csv\n",
      "   ì˜ˆì¸¡ ë²”ìœ„: [0.0893, 0.9987]\n",
      "   ì˜ˆì¸¡ í‰ê· : 0.5086\n"
     ]
    }
   ],
   "source": [
    "def build_features(df, is_train=True):\n",
    "    \"\"\"\n",
    "    ì²´ê³„ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-1. ì¸êµ¬í†µê³„ í”¼ì²˜\n",
    "    # ===========================================\n",
    "    \n",
    "    # age_group â†’ ordinal\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    \n",
    "    # ì—°ë ¹ëŒ€ í”Œë˜ê·¸\n",
    "    df[\"is_teenager\"] = (df[\"age_ord\"] == 1).astype(int)\n",
    "    df[\"is_young\"] = (df[\"age_ord\"] <= 2).astype(int)  # 10s, 20s\n",
    "    df[\"is_middle\"] = ((df[\"age_ord\"] >= 3) & (df[\"age_ord\"] <= 5)).astype(int)  # 30s-50s\n",
    "    df[\"is_old\"] = (df[\"age_ord\"] >= 6).astype(int)  # 60s+\n",
    "    \n",
    "    # education í”Œë˜ê·¸\n",
    "    df[\"edu_low\"] = (df[\"education\"] <= 2).astype(float)\n",
    "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float)\n",
    "    \n",
    "    # married í”Œë˜ê·¸\n",
    "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float)\n",
    "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float)\n",
    "    \n",
    "    # urban í”Œë˜ê·¸\n",
    "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float)\n",
    "    df[\"is_rural\"] = (df[\"urban\"] == 1).astype(float)\n",
    "    \n",
    "    # engnat í”Œë˜ê·¸\n",
    "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float)\n",
    "    \n",
    "    # gender ì´ì§„í™”\n",
    "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(int)\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-2. Q_A íƒœë„ í”¼ì²˜ (ì›ë³¸ 20ê°œ + ì§‘ê³„)\n",
    "    # ===========================================\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    \n",
    "    # Q_A ì§‘ê³„ í†µê³„\n",
    "    df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
    "    df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
    "    df[\"qa_min\"] = df[qa_cols].min(axis=1)\n",
    "    df[\"qa_max\"] = df[qa_cols].max(axis=1)\n",
    "    df[\"qa_range\"] = df[\"qa_max\"] - df[\"qa_min\"]\n",
    "    \n",
    "    # ê·¹ë‹¨ ì‘ë‹µ ë¹„ìœ¨ (1 ë˜ëŠ” 5)\n",
    "    df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / 20\n",
    "    # ì¤‘ë¦½ ì‘ë‹µ ë¹„ìœ¨ (3)\n",
    "    df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / 20\n",
    "    # ë¶€ì • ì‘ë‹µ ë¹„ìœ¨ (1, 2)\n",
    "    df[\"qa_negative_ratio\"] = ((df[qa_cols] <= 2)).sum(axis=1) / 20\n",
    "    # ê¸ì • ì‘ë‹µ ë¹„ìœ¨ (4, 5)\n",
    "    df[\"qa_positive_ratio\"] = ((df[qa_cols] >= 4)).sum(axis=1) / 20\n",
    "    \n",
    "    # ì„±ì˜ì—†ëŠ” ì‘ë‹µ í”Œë˜ê·¸ (ëª¨ë“  ë‹µ ë™ì¼)\n",
    "    df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(int)\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-3. Q_E ì‘ë‹µì‹œê°„ í”¼ì²˜ (ë¡œê·¸ ë³€í™˜ + ì§‘ê³„)\n",
    "    # ===========================================\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    \n",
    "    # ë¡œê·¸ ë³€í™˜\n",
    "    for col in qe_cols:\n",
    "        df[f\"{col}_log\"] = np.log1p(df[col])\n",
    "    \n",
    "    qe_log_cols = [f\"{col}_log\" for col in qe_cols]\n",
    "    \n",
    "    # Q_E ì§‘ê³„ í†µê³„\n",
    "    df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
    "    df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
    "    df[\"qe_log_min\"] = df[qe_log_cols].min(axis=1)\n",
    "    df[\"qe_log_max\"] = df[qe_log_cols].max(axis=1)\n",
    "    \n",
    "    # ë¹ ë¥¸/ëŠë¦° ì‘ë‹µ ë¹„ìœ¨\n",
    "    df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / 20\n",
    "    df[\"qe_slow_ratio\"] = (df[qe_cols] > 10000).sum(axis=1) / 20\n",
    "    \n",
    "    # ì´ ì‘ë‹µì‹œê°„\n",
    "    df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
    "    \n",
    "    # ì„±ì˜ì—†ëŠ” ì‘ë‹µì í”Œë˜ê·¸\n",
    "    df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df[\"qa_all_same\"] == 1)).astype(int)\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-4. TP ì„±ê²© í”¼ì²˜ (Big5)\n",
    "    # ===========================================\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    \n",
    "    # TP ë¬´ì‘ë‹µ ë¹„ìœ¨ (0ì´ì—ˆë˜ ê²ƒë“¤ â†’ NaN ì²˜ë¦¬ë¨)\n",
    "    df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / 10\n",
    "    \n",
    "    # Big5 ê³„ì‚° (NaN í¬í•¨ ìƒíƒœë¡œ)\n",
    "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "    \n",
    "    # TP í‰ê·  (ìœ íš¨ê°’ë§Œ)\n",
    "    df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
    "    df[\"tp_std\"] = df[tp_cols].std(axis=1)\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-5. WR/WF ë‹¨ì–´ì¸ì§€ í”¼ì²˜\n",
    "    # ===========================================\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    \n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "    \n",
    "    # ì–´íœ˜ë ¥ ìˆ˜ì¤€\n",
    "    df[\"vocab_low\"] = (df[\"wr_sum\"] <= 7).astype(int)\n",
    "    df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(int)\n",
    "    \n",
    "    # ===========================================\n",
    "    # 3-6. Interaction í”¼ì²˜ (í•µì‹¬!)\n",
    "    # ===========================================\n",
    "    \n",
    "    # ì—°ë ¹ Ã— í•™ë ¥\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
    "    \n",
    "    # ì Šì€ + ì €í•™ë ¥ (ê°€ì¥ íˆ¬í‘œ ì•ˆí•˜ëŠ” ê·¸ë£¹)\n",
    "    df[\"young_low_edu\"] = df[\"is_young\"] * df[\"edu_low\"]\n",
    "    \n",
    "    # ì Šì€ + ë¯¸í˜¼\n",
    "    df[\"young_single\"] = df[\"is_young\"] * df[\"is_single\"]\n",
    "    \n",
    "    # ë‚˜ì´ë“  + ê¸°í˜¼ (ê°€ì¥ íˆ¬í‘œ ë§ì´ í•˜ëŠ” ê·¸ë£¹)\n",
    "    df[\"old_married\"] = df[\"is_old\"] * df[\"is_married\"]\n",
    "    \n",
    "    # ë‚˜ì´ë“  + ê³ í•™ë ¥\n",
    "    df[\"old_high_edu\"] = df[\"is_old\"] * df[\"edu_high\"]\n",
    "    \n",
    "    # 10ëŒ€ + ì €í•™ë ¥ (ê·¹ë‹¨ì  ë¯¸íˆ¬í‘œ ê·¸ë£¹)\n",
    "    df[\"teenager_low_edu\"] = df[\"is_teenager\"] * df[\"edu_low\"]\n",
    "    \n",
    "    # ì–´íœ˜ë ¥ Ã— í•™ë ¥\n",
    "    df[\"vocab_edu\"] = df[\"wr_sum\"] * df[\"education\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Target Encoding í•¨ìˆ˜ (CV leak ë°©ì§€)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ 4. Target Encoding í•¨ìˆ˜ ì •ì˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "def target_encode(train_df, val_df, test_df, col, target_col, smoothing=10):\n",
    "    \"\"\"\n",
    "    Smoothed Target Encoding (CV leak ë°©ì§€)\n",
    "    train_dfë¡œë§Œ ì¸ì½”ë”© ë§µ ìƒì„± â†’ val, testì— ì ìš©\n",
    "    \"\"\"\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n",
    "    agg = train_df.groupby(col)[target_col].agg(['mean', 'count'])\n",
    "    \n",
    "    # Smoothing ì ìš©\n",
    "    agg['te'] = (agg['count'] * agg['mean'] + smoothing * global_mean) / (agg['count'] + smoothing)\n",
    "    te_map = agg['te'].to_dict()\n",
    "    \n",
    "    # ì ìš©\n",
    "    train_te = train_df[col].map(te_map).fillna(global_mean)\n",
    "    val_te = val_df[col].map(te_map).fillna(global_mean)\n",
    "    test_te = test_df[col].map(te_map).fillna(global_mean)\n",
    "    \n",
    "    return train_te.values, val_te.values, test_te.values\n",
    "\n",
    "\n",
    "def create_all_target_encodings(train_df, val_df, test_df, target_col=\"voted_bin\"):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  Target Encoding í”¼ì²˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    te_dict = {'train': {}, 'val': {}, 'test': {}}\n",
    "    \n",
    "    # ë‹¨ì¼ ì»¬ëŸ¼ TE\n",
    "    single_cols = ['age_group', 'race', 'religion']\n",
    "    for col in single_cols:\n",
    "        tr, va, te = target_encode(train_df, val_df, test_df, col, target_col, smoothing=10)\n",
    "        te_dict['train'][f'{col}_te'] = tr\n",
    "        te_dict['val'][f'{col}_te'] = va\n",
    "        te_dict['test'][f'{col}_te'] = te\n",
    "    \n",
    "    # ë³µí•© ì»¬ëŸ¼ TE (ë¬¸ìì—´ ê²°í•©)\n",
    "    # age Ã— education\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['age_edu_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str)\n",
    "    tr, va, te = target_encode(train_df, val_df, test_df, 'age_edu_cat', target_col, smoothing=5)\n",
    "    te_dict['train']['age_edu_te'] = tr\n",
    "    te_dict['val']['age_edu_te'] = va\n",
    "    te_dict['test']['age_edu_te'] = te\n",
    "    \n",
    "    # age Ã— married\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['age_married_cat'] = df['age_group'].astype(str) + '_' + df['married'].astype(str)\n",
    "    tr, va, te = target_encode(train_df, val_df, test_df, 'age_married_cat', target_col, smoothing=5)\n",
    "    te_dict['train']['age_married_te'] = tr\n",
    "    te_dict['val']['age_married_te'] = va\n",
    "    te_dict['test']['age_married_te'] = te\n",
    "    \n",
    "    # age Ã— race\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['age_race_cat'] = df['age_group'].astype(str) + '_' + df['race'].astype(str)\n",
    "    tr, va, te = target_encode(train_df, val_df, test_df, 'age_race_cat', target_col, smoothing=5)\n",
    "    te_dict['train']['age_race_te'] = tr\n",
    "    te_dict['val']['age_race_te'] = va\n",
    "    te_dict['test']['age_race_te'] = te\n",
    "    \n",
    "    # age Ã— education Ã— married (ê°€ì¥ ê°•ë ¥!)\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['age_edu_married_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str) + '_' + df['married'].astype(str)\n",
    "    tr, va, te = target_encode(train_df, val_df, test_df, 'age_edu_married_cat', target_col, smoothing=3)\n",
    "    te_dict['train']['age_edu_married_te'] = tr\n",
    "    te_dict['val']['age_edu_married_te'] = va\n",
    "    te_dict['test']['age_edu_married_te'] = te\n",
    "    \n",
    "    return te_dict\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ 5. í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ì›ë³¸ Q_A 20ê°œ\n",
    "qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "\n",
    "# Q_E ë¡œê·¸ 20ê°œ\n",
    "qe_log_cols = [f\"Q{c}E_log\" for c in \"abcdefghijklmnopqrst\"]\n",
    "\n",
    "# ì›ë³¸ WR 13ê°œ\n",
    "wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "\n",
    "# ì›ë³¸ WF 3ê°œ\n",
    "wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• í”¼ì²˜\n",
    "num_features = (\n",
    "    qa_cols +  # 20\n",
    "    qe_log_cols +  # 20\n",
    "    wr_cols +  # 13\n",
    "    wf_cols +  # 3\n",
    "    [\n",
    "        # ì¸êµ¬í†µê³„\n",
    "        \"age_ord\", \"education\", \"married\", \"urban\", \"engnat\", \"familysize\", \"hand\",\n",
    "        \"is_teenager\", \"is_young\", \"is_middle\", \"is_old\",\n",
    "        \"edu_low\", \"edu_high\", \"is_single\", \"is_married\",\n",
    "        \"is_urban\", \"is_rural\", \"is_english_native\", \"is_male\",\n",
    "        \n",
    "        # Q_A ì§‘ê³„\n",
    "        \"qa_mean\", \"qa_std\", \"qa_min\", \"qa_max\", \"qa_range\",\n",
    "        \"qa_extreme_ratio\", \"qa_neutral_ratio\", \"qa_negative_ratio\", \"qa_positive_ratio\",\n",
    "        \"qa_all_same\",\n",
    "        \n",
    "        # Q_E ì§‘ê³„\n",
    "        \"qe_log_mean\", \"qe_log_std\", \"qe_log_min\", \"qe_log_max\",\n",
    "        \"qe_fast_ratio\", \"qe_slow_ratio\", \"qe_total_log\",\n",
    "        \"is_careless\",\n",
    "        \n",
    "        # TP Big5\n",
    "        \"tp_missing_ratio\", \"tp_mean\", \"tp_std\",\n",
    "        \"extraversion\", \"agreeableness\", \"conscientiousness\", \"neuroticism\", \"openness\",\n",
    "        \n",
    "        # WR/WF ì§‘ê³„\n",
    "        \"wr_sum\", \"wf_sum\", \"word_credibility\", \"vocab_low\", \"vocab_high\",\n",
    "        \n",
    "        # Interaction\n",
    "        \"age_edu\", \"young_low_edu\", \"young_single\", \"old_married\", \"old_high_edu\",\n",
    "        \"teenager_low_edu\", \"vocab_edu\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Target Encoding í”¼ì²˜ (ë™ì  ì¶”ê°€)\n",
    "te_features = [\n",
    "    'age_group_te', 'race_te', 'religion_te',\n",
    "    'age_edu_te', 'age_married_te', 'age_race_te', 'age_edu_married_te'\n",
    "]\n",
    "\n",
    "# ë²”ì£¼í˜• í”¼ì²˜ (ì„ë² ë”©ìš©)\n",
    "cat_features = ['gender', 'race', 'religion']\n",
    "\n",
    "print(f\"ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(num_features)}\")\n",
    "print(f\"Target Encoding: {len(te_features)}\")\n",
    "print(f\"ë²”ì£¼í˜• í”¼ì²˜: {len(cat_features)}\")\n",
    "print(f\"ì´: {len(num_features) + len(te_features) + len(cat_features)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Dataset & Model\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ—ï¸ 6. Dataset & Model ì •ì˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class SimpleMLPWithEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì ì¸ MLP (CPU ìµœì í™”)\n",
    "    - ë²”ì£¼í˜• ì„ë² ë”©\n",
    "    - Residual Connection\n",
    "    - BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, cat_dims, embed_dim=8, hidden_dims=[256, 128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ë²”ì£¼í˜• ì„ë² ë”©\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim + 1, embed_dim) for dim in cat_dims\n",
    "        ])\n",
    "        \n",
    "        # ì…ë ¥ ì°¨ì› ê³„ì‚°\n",
    "        total_embed_dim = len(cat_dims) * embed_dim\n",
    "        input_dim = num_features + total_embed_dim\n",
    "        \n",
    "        # MLP ë ˆì´ì–´\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.output = nn.Linear(hidden_dims[-1], 1)\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, x_num, x_cat):\n",
    "        # ë²”ì£¼í˜• ì„ë² ë”©\n",
    "        cat_embeds = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        cat_embeds = torch.cat(cat_embeds, dim=1)\n",
    "        \n",
    "        # ê²°í•©\n",
    "        x = torch.cat([x_num, cat_embeds], dim=1)\n",
    "        \n",
    "        # MLP\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. í•™ìŠµ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def train_fold(model, train_loader, val_loader, val_y, device, epochs=EPOCHS, patience=PATIENCE):\n",
    "    model.to(device)\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
    "    pos_ratio = val_y.mean()\n",
    "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for X_num, X_cat, y in train_loader:\n",
    "            X_num, X_cat, y = X_num.to(device), X_cat.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(X_num, X_cat)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_num, X_cat, _ in val_loader:\n",
    "                X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "                out = torch.sigmoid(model(X_num, X_cat))\n",
    "                val_preds.append(out.cpu().numpy())\n",
    "        \n",
    "        val_preds = np.concatenate(val_preds).ravel()\n",
    "        val_auc = roc_auc_score(val_y, val_preds)\n",
    "        \n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        if val_auc > best_auc + 1e-5:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"    Epoch {epoch+1}: loss={train_loss/len(train_loader):.4f}, val_auc={val_auc:.5f}, best={best_auc:.5f}\")\n",
    "        \n",
    "        if no_improve >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_auc\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if len(batch) == 2:\n",
    "                X_num, X_cat = batch\n",
    "            else:\n",
    "                X_num, X_cat, _ = batch\n",
    "            X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "            out = torch.sigmoid(model(X_num, X_cat))\n",
    "            preds.append(out.cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ë©”ì¸ í•™ìŠµ ë£¨í”„\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš€ 8. í•™ìŠµ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„° ì •ë¦¬\n",
    "    train_clean = clean_data(train_raw, is_train=True)\n",
    "    test_clean = clean_data(test_raw, is_train=False)\n",
    "    \n",
    "    # OOF ë° Test ì˜ˆì¸¡ ì €ì¥\n",
    "    oof_preds = np.zeros(len(train_clean))\n",
    "    test_preds = np.zeros(len(test_clean))\n",
    "    fold_aucs = []\n",
    "    \n",
    "    # K-Fold\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_clean, train_clean[\"voted_bin\"])):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“‚ Fold {fold + 1}/{N_FOLDS}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ë°ì´í„° ë¶„í• \n",
    "        train_fold_df = train_clean.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        val_fold_df = train_clean.iloc[val_idx].copy().reset_index(drop=True)\n",
    "        test_fold_df = test_clean.copy()\n",
    "        \n",
    "        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "        train_fe = build_features(train_fold_df, is_train=True)\n",
    "        val_fe = build_features(val_fold_df, is_train=True)\n",
    "        test_fe = build_features(test_fold_df, is_train=False)\n",
    "        \n",
    "        # Target Encoding (foldë³„ë¡œ ìƒˆë¡œ ê³„ì‚°!)\n",
    "        te_dict = create_all_target_encodings(train_fe, val_fe, test_fe, \"voted_bin\")\n",
    "        \n",
    "        # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¤€ë¹„\n",
    "        all_num_features = num_features + te_features\n",
    "        \n",
    "        X_train = train_fe[num_features].copy()\n",
    "        X_val = val_fe[num_features].copy()\n",
    "        X_test = test_fe[num_features].copy()\n",
    "        \n",
    "        # Target Encoding ì¶”ê°€\n",
    "        for te_name in te_features:\n",
    "            X_train[te_name] = te_dict['train'][te_name]\n",
    "            X_val[te_name] = te_dict['val'][te_name]\n",
    "            X_test[te_name] = te_dict['test'][te_name]\n",
    "        \n",
    "        # NaN ì²˜ë¦¬ (train ì¤‘ì•™ê°’ìœ¼ë¡œ)\n",
    "        for col in all_num_features:\n",
    "            median_val = X_train[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                median_val = 0\n",
    "            X_train[col] = X_train[col].fillna(median_val)\n",
    "            X_val[col] = X_val[col].fillna(median_val)\n",
    "            X_test[col] = X_test[col].fillna(median_val)\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "        X_val_scaled = scaler.transform(X_val.values)\n",
    "        X_test_scaled = scaler.transform(X_test.values)\n",
    "        \n",
    "        # ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "        cat_dims = []\n",
    "        X_cat_train_list = []\n",
    "        X_cat_val_list = []\n",
    "        X_cat_test_list = []\n",
    "        \n",
    "        for col in cat_features:\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            train_col = train_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            val_col = val_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            test_col = test_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            \n",
    "            all_values = list(set(train_col.unique()) | set(val_col.unique()) | set(test_col.unique()))\n",
    "            if \"__UNK__\" not in all_values:\n",
    "                all_values.append(\"__UNK__\")\n",
    "            \n",
    "            le.fit(all_values)\n",
    "            cat_dims.append(len(le.classes_))\n",
    "            \n",
    "            X_cat_train_list.append(le.transform(train_col))\n",
    "            X_cat_val_list.append(le.transform(val_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "            X_cat_test_list.append(le.transform(test_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "        \n",
    "        X_cat_train = np.stack(X_cat_train_list, axis=1)\n",
    "        X_cat_val = np.stack(X_cat_val_list, axis=1)\n",
    "        X_cat_test = np.stack(X_cat_test_list, axis=1)\n",
    "        \n",
    "        y_train = train_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_val = val_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "        \n",
    "        # DataLoader\n",
    "        train_ds = TabDataset(X_train_scaled, X_cat_train, y_train)\n",
    "        val_ds = TabDataset(X_val_scaled, X_cat_val, y_val)\n",
    "        test_ds = TabDataset(X_test_scaled, X_cat_test)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        # ëª¨ë¸\n",
    "        model = SimpleMLPWithEmbedding(\n",
    "            num_features=len(all_num_features),\n",
    "            cat_dims=cat_dims,\n",
    "            embed_dim=8,\n",
    "            hidden_dims=[256, 128, 64],\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"    ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        # í•™ìŠµ\n",
    "        model, fold_auc = train_fold(model, train_loader, val_loader, y_val, DEVICE)\n",
    "        fold_aucs.append(fold_auc)\n",
    "        \n",
    "        # OOF ì˜ˆì¸¡\n",
    "        oof_preds[val_idx] = predict(model, val_loader, DEVICE)\n",
    "        \n",
    "        # Test ì˜ˆì¸¡ (í‰ê· )\n",
    "        test_preds += predict(model, test_loader, DEVICE) / N_FOLDS\n",
    "        \n",
    "        print(f\"  âœ… Fold {fold + 1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼\n",
    "    final_oof_auc = roc_auc_score(train_clean[\"voted_bin\"], oof_preds)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ ìµœì¢… ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ† OOF AUC: {final_oof_auc:.5f}\")\n",
    "    print(f\"ğŸ“Š Fold AUCs: {[f'{x:.5f}' for x in fold_aucs]}\")\n",
    "    print(f\"ğŸ“Š Mean Â± Std: {np.mean(fold_aucs):.5f} Â± {np.std(fold_aucs):.5f}\")\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else range(len(test_raw)),\n",
    "        \"voted\": test_preds\n",
    "    })\n",
    "    sub.to_csv(\"submission_10_MLP_v2_te.csv\", index=False)\n",
    "    print(f\"\\nğŸ’¾ ì €ì¥ ì™„ë£Œ: submission_10_MLP_v2_te.csv\")\n",
    "    print(f\"   ì˜ˆì¸¡ ë²”ìœ„: [{test_preds.min():.4f}, {test_preds.max():.4f}]\")\n",
    "    print(f\"   ì˜ˆì¸¡ í‰ê· : {test_preds.mean():.4f}\")\n",
    "    \n",
    "    return final_oof_auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_auc = main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2194a",
   "metadata": {},
   "source": [
    "## 5. Dataset & ëª¨ë¸ ì •ì˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06adb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class SimpleMLPWithEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì ì¸ MLP (CPU ìµœì í™”)\n",
    "    - ë²”ì£¼í˜• ì„ë² ë”©\n",
    "    - Residual Connection\n",
    "    - BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, cat_dims, embed_dim=8, hidden_dims=[256, 128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ë²”ì£¼í˜• ì„ë² ë”©\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim + 1, embed_dim) for dim in cat_dims\n",
    "        ])\n",
    "        \n",
    "        # ì…ë ¥ ì°¨ì› ê³„ì‚°\n",
    "        total_embed_dim = len(cat_dims) * embed_dim\n",
    "        input_dim = num_features + total_embed_dim\n",
    "        \n",
    "        # MLP ë ˆì´ì–´\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        # ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.output = nn.Linear(hidden_dims[-1], 1)\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, x_num, x_cat):\n",
    "        # ë²”ì£¼í˜• ì„ë² ë”©\n",
    "        cat_embeds = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        cat_embeds = torch.cat(cat_embeds, dim=1)\n",
    "        \n",
    "        # ê²°í•©\n",
    "        x = torch.cat([x_num, cat_embeds], dim=1)\n",
    "        \n",
    "        # MLP\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. í•™ìŠµ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749576a",
   "metadata": {},
   "source": [
    "## 6. í•™ìŠµ/í‰ê°€ í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c58b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(model, train_loader, val_loader, val_y, device, epochs=EPOCHS, patience=PATIENCE):\n",
    "    model.to(device)\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
    "    pos_ratio = val_y.mean()\n",
    "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for X_num, X_cat, y in train_loader:\n",
    "            X_num, X_cat, y = X_num.to(device), X_cat.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(X_num, X_cat)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_num, X_cat, _ in val_loader:\n",
    "                X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "                out = torch.sigmoid(model(X_num, X_cat))\n",
    "                val_preds.append(out.cpu().numpy())\n",
    "        \n",
    "        val_preds = np.concatenate(val_preds).ravel()\n",
    "        val_auc = roc_auc_score(val_y, val_preds)\n",
    "        \n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        if val_auc > best_auc + 1e-5:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"    Epoch {epoch+1}: loss={train_loss/len(train_loader):.4f}, val_auc={val_auc:.5f}, best={best_auc:.5f}\")\n",
    "        \n",
    "        if no_improve >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_auc\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if len(batch) == 2:\n",
    "                X_num, X_cat = batch\n",
    "            else:\n",
    "                X_num, X_cat, _ = batch\n",
    "            X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "            out = torch.sigmoid(model(X_num, X_cat))\n",
    "            preds.append(out.cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ë©”ì¸ í•™ìŠµ ë£¨í”„\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš€ 8. í•™ìŠµ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„° ì •ë¦¬\n",
    "    train_clean = clean_data(train_raw, is_train=True)\n",
    "    test_clean = clean_data(test_raw, is_train=False)\n",
    "    \n",
    "    # OOF ë° Test ì˜ˆì¸¡ ì €ì¥\n",
    "    oof_preds = np.zeros(len(train_clean))\n",
    "    test_preds = np.zeros(len(test_clean))\n",
    "    fold_aucs = []\n",
    "    \n",
    "    # K-Fold\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_clean, train_clean[\"voted_bin\"])):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“‚ Fold {fold + 1}/{N_FOLDS}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ë°ì´í„° ë¶„í• \n",
    "        train_fold_df = train_clean.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        val_fold_df = train_clean.iloc[val_idx].copy().reset_index(drop=True)\n",
    "        test_fold_df = test_clean.copy()\n",
    "        \n",
    "        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "        train_fe = build_features(train_fold_df, is_train=True)\n",
    "        val_fe = build_features(val_fold_df, is_train=True)\n",
    "        test_fe = build_features(test_fold_df, is_train=False)\n",
    "        \n",
    "        # Target Encoding (foldë³„ë¡œ ìƒˆë¡œ ê³„ì‚°!)\n",
    "        te_dict = create_all_target_encodings(train_fe, val_fe, test_fe, \"voted_bin\")\n",
    "        \n",
    "        # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¤€ë¹„\n",
    "        all_num_features = num_features + te_features\n",
    "        \n",
    "        X_train = train_fe[num_features].copy()\n",
    "        X_val = val_fe[num_features].copy()\n",
    "        X_test = test_fe[num_features].copy()\n",
    "        \n",
    "        # Target Encoding ì¶”ê°€\n",
    "        for te_name in te_features:\n",
    "            X_train[te_name] = te_dict['train'][te_name]\n",
    "            X_val[te_name] = te_dict['val'][te_name]\n",
    "            X_test[te_name] = te_dict['test'][te_name]\n",
    "        \n",
    "        # NaN ì²˜ë¦¬ (train ì¤‘ì•™ê°’ìœ¼ë¡œ)\n",
    "        for col in all_num_features:\n",
    "            median_val = X_train[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                median_val = 0\n",
    "            X_train[col] = X_train[col].fillna(median_val)\n",
    "            X_val[col] = X_val[col].fillna(median_val)\n",
    "            X_test[col] = X_test[col].fillna(median_val)\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "        X_val_scaled = scaler.transform(X_val.values)\n",
    "        X_test_scaled = scaler.transform(X_test.values)\n",
    "        \n",
    "        # ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "        cat_dims = []\n",
    "        X_cat_train_list = []\n",
    "        X_cat_val_list = []\n",
    "        X_cat_test_list = []\n",
    "        \n",
    "        for col in cat_features:\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            train_col = train_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            val_col = val_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            test_col = test_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            \n",
    "            all_values = list(set(train_col.unique()) | set(val_col.unique()) | set(test_col.unique()))\n",
    "            if \"__UNK__\" not in all_values:\n",
    "                all_values.append(\"__UNK__\")\n",
    "            \n",
    "            le.fit(all_values)\n",
    "            cat_dims.append(len(le.classes_))\n",
    "            \n",
    "            X_cat_train_list.append(le.transform(train_col))\n",
    "            X_cat_val_list.append(le.transform(val_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "            X_cat_test_list.append(le.transform(test_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "        \n",
    "        X_cat_train = np.stack(X_cat_train_list, axis=1)\n",
    "        X_cat_val = np.stack(X_cat_val_list, axis=1)\n",
    "        X_cat_test = np.stack(X_cat_test_list, axis=1)\n",
    "        \n",
    "        y_train = train_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_val = val_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "        \n",
    "        # DataLoader\n",
    "        train_ds = TabDataset(X_train_scaled, X_cat_train, y_train)\n",
    "        val_ds = TabDataset(X_val_scaled, X_cat_val, y_val)\n",
    "        test_ds = TabDataset(X_test_scaled, X_cat_test)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        # ëª¨ë¸\n",
    "        model = SimpleMLPWithEmbedding(\n",
    "            num_features=len(all_num_features),\n",
    "            cat_dims=cat_dims,\n",
    "            embed_dim=8,\n",
    "            hidden_dims=[256, 128, 64],\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"    ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        # í•™ìŠµ\n",
    "        model, fold_auc = train_fold(model, train_loader, val_loader, y_val, DEVICE)\n",
    "        fold_aucs.append(fold_auc)\n",
    "        \n",
    "        # OOF ì˜ˆì¸¡\n",
    "        oof_preds[val_idx] = predict(model, val_loader, DEVICE)\n",
    "        \n",
    "        # Test ì˜ˆì¸¡ (í‰ê· )\n",
    "        test_preds += predict(model, test_loader, DEVICE) / N_FOLDS\n",
    "        \n",
    "        print(f\"  âœ… Fold {fold + 1} AUC: {fold_auc:.5f}\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼\n",
    "    final_oof_auc = roc_auc_score(train_clean[\"voted_bin\"], oof_preds)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ ìµœì¢… ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ† OOF AUC: {final_oof_auc:.5f}\")\n",
    "    print(f\"ğŸ“Š Fold AUCs: {[f'{x:.5f}' for x in fold_aucs]}\")\n",
    "    print(f\"ğŸ“Š Mean Â± Std: {np.mean(fold_aucs):.5f} Â± {np.std(fold_aucs):.5f}\")\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else range(len(test_raw)),\n",
    "        \"voted\": test_preds\n",
    "    })\n",
    "    sub.to_csv(\"submission_10_MLP_v2_te.csv\", index=False)\n",
    "    print(f\"\\nğŸ’¾ ì €ì¥ ì™„ë£Œ: submission_10_MLP_v2_te.csv\")\n",
    "    print(f\"   ì˜ˆì¸¡ ë²”ìœ„: [{test_preds.min():.4f}, {test_preds.max():.4f}]\")\n",
    "    print(f\"   ì˜ˆì¸¡ í‰ê· : {test_preds.mean():.4f}\")\n",
    "    \n",
    "    return final_oof_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeb2c8",
   "metadata": {},
   "source": [
    "## 7. ì‹¤í–‰ ë° ì œì¶œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fedb746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ 8. í•™ìŠµ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 1/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5021, val_auc=0.77789, best=0.77789\n",
      "    Early stopping at epoch 18\n",
      "  âœ… Fold 1 AUC: 0.77789\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 2/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5017, val_auc=0.76792, best=0.76792\n",
      "    Epoch 20: loss=0.4833, val_auc=0.76505, best=0.76864\n",
      "    Early stopping at epoch 21\n",
      "  âœ… Fold 2 AUC: 0.76864\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 3/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.4978, val_auc=0.76092, best=0.76239\n",
      "    Early stopping at epoch 16\n",
      "  âœ… Fold 3 AUC: 0.76239\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 4/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.5008, val_auc=0.75953, best=0.75953\n",
      "    Epoch 20: loss=0.4802, val_auc=0.75986, best=0.76111\n",
      "    Early stopping at epoch 23\n",
      "  âœ… Fold 4 AUC: 0.76111\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ Fold 5/5\n",
      "==================================================\n",
      "    ëª¨ë¸ íŒŒë¼ë¯¸í„°: 79,449\n",
      "    Epoch 10: loss=0.4983, val_auc=0.76847, best=0.76847\n",
      "    Early stopping at epoch 19\n",
      "  âœ… Fold 5 AUC: 0.76861\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ìµœì¢… ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ† OOF AUC: 0.76740\n",
      "ğŸ“Š Fold AUCs: ['0.77789', '0.76864', '0.76239', '0.76111', '0.76861']\n",
      "ğŸ“Š Mean Â± Std: 0.76773 Â± 0.00595\n",
      "\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: submission_final(ì œì¶œ).csv\n",
      "   ì˜ˆì¸¡ ë²”ìœ„: [0.0893, 0.9987]\n",
      "   ì˜ˆì¸¡ í‰ê· : 0.5086\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    final_auc = main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}