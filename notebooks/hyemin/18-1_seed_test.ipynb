{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0e36e5",
   "metadata": {},
   "source": [
    "Ìï¥Ïª§ÌÜ§ Ï†úÏ∂ú Ïó∞ÏäµÏö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e8961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Device: cpu\n",
      "Train: (45532, 79), Test: (11383, 77)\n",
      "\n",
      "================================================================================\n",
      "üå± SEED RUN: 42\n",
      "================================================================================\n",
      "[Seed 42][Fold 1] AUC=0.78299 | n_feat=117\n",
      "[Seed 42][Fold 2] AUC=0.76903 | n_feat=117\n",
      "[Seed 42][Fold 3] AUC=0.76187 | n_feat=117\n",
      "[Seed 42][Fold 4] AUC=0.76182 | n_feat=117\n",
      "[Seed 42][Fold 5] AUC=0.76909 | n_feat=117\n",
      "‚úÖ SEED 42 OOF AUC: 0.76882 | fold mean: 0.76896\n",
      "\n",
      "================================================================================\n",
      "üå± SEED RUN: 202\n",
      "================================================================================\n",
      "[Seed 202][Fold 1] AUC=0.76867 | n_feat=117\n",
      "[Seed 202][Fold 2] AUC=0.77597 | n_feat=117\n",
      "[Seed 202][Fold 3] AUC=0.76949 | n_feat=117\n",
      "[Seed 202][Fold 4] AUC=0.76065 | n_feat=117\n",
      "[Seed 202][Fold 5] AUC=0.77171 | n_feat=117\n",
      "‚úÖ SEED 202 OOF AUC: 0.76907 | fold mean: 0.76930\n",
      "\n",
      "================================================================================\n",
      "üå± SEED RUN: 777\n",
      "================================================================================\n",
      "[Seed 777][Fold 1] AUC=0.76767 | n_feat=117\n",
      "[Seed 777][Fold 2] AUC=0.77591 | n_feat=117\n",
      "[Seed 777][Fold 3] AUC=0.76289 | n_feat=117\n",
      "[Seed 777][Fold 4] AUC=0.76551 | n_feat=117\n",
      "[Seed 777][Fold 5] AUC=0.77357 | n_feat=117\n",
      "‚úÖ SEED 777 OOF AUC: 0.76875 | fold mean: 0.76911\n",
      "\n",
      "================================================================================\n",
      "üèÅ SEED ENSEMBLE SUMMARY\n",
      "================================================================================\n",
      "Seed 42: OOF AUC = 0.76882\n",
      "Seed 202: OOF AUC = 0.76907\n",
      "Seed 777: OOF AUC = 0.76875\n",
      "‚úÖ Ensemble OOF AUC = 0.77048\n",
      "üíæ Saved: submission_seed_ens_3.csv\n",
      "   pred range: [0.1007, 0.9985]\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../../data/raw/train.csv\"\n",
    "TEST_PATH  = \"../../data/raw/test_x.csv\"\n",
    "\n",
    "N_FOLDS = 5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "EPOCHS = 80\n",
    "PATIENCE = 10\n",
    "\n",
    "# ‚úÖ Ïó¨Í∏∞ seedÎßå Î∞îÍøîÏÑú ÏïôÏÉÅÎ∏î\n",
    "SEEDS = [42, 202, 777]  # ÏõêÌïòÎ©¥ [42, 202, 777, 1024, 2026]ÍπåÏßÄ ÎäòÎ†§ÎèÑ Îê®\n",
    "\n",
    "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Load\n",
    "# ============================================================\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Preprocess\n",
    "# ============================================================\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in [\"education\", \"engnat\", \"hand\", \"married\", \"urban\"]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    if \"familysize\" in df.columns:\n",
    "        df.loc[df[\"familysize\"] == 0, \"familysize\"] = np.nan\n",
    "        df.loc[df[\"familysize\"] > 15, \"familysize\"] = np.nan\n",
    "\n",
    "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    for col in [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].clip(lower=100, upper=60000)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Feature Engineering (ÎÑà ÏΩîÎìú Í∑∏ÎåÄÎ°ú)\n",
    "# ============================================================\n",
    "def build_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "\n",
    "    df[\"is_teenager\"] = (df[\"age_ord\"] == 1).astype(float)\n",
    "    df[\"is_young\"] = (df[\"age_ord\"] <= 2).astype(float)\n",
    "    df[\"is_old\"] = (df[\"age_ord\"] >= 6).astype(float)\n",
    "\n",
    "    df[\"edu_low\"] = (df[\"education\"] <= 2).astype(float)\n",
    "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float)\n",
    "\n",
    "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float)\n",
    "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float)\n",
    "\n",
    "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float)\n",
    "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float)\n",
    "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(float)\n",
    "\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
    "    df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
    "    df[\"qa_range\"] = df[qa_cols].max(axis=1) - df[qa_cols].min(axis=1)\n",
    "    df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / len(qa_cols)\n",
    "    df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / len(qa_cols)\n",
    "    df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(float)\n",
    "\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    for c in qe_cols:\n",
    "        df[f\"{c}_log\"] = np.log1p(df[c])\n",
    "\n",
    "    qe_log_cols = [f\"{c}_log\" for c in qe_cols]\n",
    "    df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
    "    df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
    "    df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / len(qe_cols)\n",
    "    df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
    "    df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df[\"qa_all_same\"] == 1)).astype(float)\n",
    "\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / len(tp_cols)\n",
    "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "    df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
    "\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "    df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(float)\n",
    "\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
    "    df[\"young_low_edu\"] = df[\"is_young\"] * df[\"edu_low\"]\n",
    "    df[\"young_single\"] = df[\"is_young\"] * df[\"is_single\"]\n",
    "    df[\"old_married\"] = df[\"is_old\"] * df[\"is_married\"]\n",
    "    df[\"teenager_low_edu\"] = df[\"is_teenager\"] * df[\"edu_low\"]\n",
    "\n",
    "    df[\"age_edu_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"education\"].astype(str)\n",
    "    df[\"age_married_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"married\"].astype(str)\n",
    "    df[\"age_race_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"race\"].astype(str)\n",
    "    df[\"age_edu_married_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"education\"].astype(str) + \"_\" + df[\"married\"].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TE (fold only)\n",
    "# ============================================================\n",
    "def target_encode(train_df, val_df, test_df, col, target_col=\"voted_bin\", smoothing=10):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    agg = train_df.groupby(col)[target_col].agg([\"mean\", \"count\"])\n",
    "    te = (agg[\"count\"] * agg[\"mean\"] + smoothing * global_mean) / (agg[\"count\"] + smoothing)\n",
    "    te_map = te.to_dict()\n",
    "\n",
    "    return (\n",
    "        train_df[col].map(te_map).fillna(global_mean).values,\n",
    "        val_df[col].map(te_map).fillna(global_mean).values,\n",
    "        test_df[col].map(te_map).fillna(global_mean).values,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_te(train_df, val_df, test_df):\n",
    "    out = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "    single_cols = [(\"age_group\", 10), (\"race\", 10), (\"religion\", 10)]\n",
    "    combo_cols  = [(\"age_edu_cat\", 5), (\"age_married_cat\", 5), (\"age_race_cat\", 5), (\"age_edu_married_cat\", 3)]\n",
    "\n",
    "    for c, sm in single_cols + combo_cols:\n",
    "        tr, va, ts = target_encode(train_df, val_df, test_df, c, \"voted_bin\", sm)\n",
    "        out[\"train\"][f\"{c}_te\"] = tr\n",
    "        out[\"val\"][f\"{c}_te\"] = va\n",
    "        out[\"test\"][f\"{c}_te\"] = ts\n",
    "    return out\n",
    "\n",
    "\n",
    "QA_RAW = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "QE_RAW = [f\"Q{c}E_log\" for c in \"abcdefghijklmnopqrst\"]\n",
    "TP_RAW = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "WR_RAW = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "WF_RAW = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "RAW_FEATURES = QA_RAW + QE_RAW + TP_RAW + WR_RAW + WF_RAW + [\"education\", \"married\", \"urban\", \"engnat\", \"familysize\", \"hand\", \"age_ord\"]\n",
    "\n",
    "SUMMARY_FEATURES = [\n",
    "    \"is_teenager\", \"is_young\", \"is_old\", \"edu_low\", \"edu_high\",\n",
    "    \"is_single\", \"is_married\", \"is_urban\", \"is_english_native\", \"is_male\",\n",
    "    \"qa_mean\", \"qa_std\", \"qa_range\", \"qa_extreme_ratio\", \"qa_neutral_ratio\", \"qa_all_same\",\n",
    "    \"qe_log_mean\", \"qe_log_std\", \"qe_fast_ratio\", \"qe_total_log\", \"is_careless\",\n",
    "    \"tp_missing_ratio\", \"tp_mean\",\n",
    "    \"extraversion\", \"agreeableness\", \"conscientiousness\", \"neuroticism\", \"openness\",\n",
    "    \"wr_sum\", \"wf_sum\", \"word_credibility\", \"vocab_high\",\n",
    "    \"age_edu\", \"young_low_edu\", \"young_single\", \"old_married\", \"teenager_low_edu\",\n",
    "]\n",
    "\n",
    "TE_FEATURES = [\n",
    "    \"age_group_te\", \"race_te\", \"religion_te\",\n",
    "    \"age_edu_cat_te\", \"age_married_cat_te\", \"age_race_cat_te\", \"age_edu_married_cat_te\",\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset / Model\n",
    "# ============================================================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None: return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev, h), nn.BatchNorm1d(h), nn.SiLU(), nn.Dropout(dropout)]\n",
    "            prev = h\n",
    "        layers += [nn.Linear(prev, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "\n",
    "def train_one_fold(model, tr_loader, va_loader, y_va, lr, weight_decay, device):\n",
    "    model.to(device)\n",
    "    pos_ratio = float(np.mean(y_va))\n",
    "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "    best_auc, best_state, no_imp = -1, None, 0\n",
    "    for _ in range(EPOCHS):\n",
    "        model.train()\n",
    "        for x, y in tr_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for x, _y in va_loader:\n",
    "                x = x.to(device)\n",
    "                preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "        preds = np.concatenate(preds).ravel()\n",
    "        auc = roc_auc_score(y_va, preds)\n",
    "        sched.step(auc)\n",
    "\n",
    "        if auc > best_auc + 1e-5:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "        if no_imp >= PATIENCE:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return best_auc\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            if isinstance(x, (tuple, list)):\n",
    "                x = x[0]\n",
    "            x = x.to(device)\n",
    "            preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "\n",
    "def make_X(train_df, val_df, test_df, use_raw, use_summary, use_te):\n",
    "    cols = []\n",
    "    if use_raw:\n",
    "        cols += RAW_FEATURES\n",
    "    if use_summary:\n",
    "        cols += SUMMARY_FEATURES\n",
    "    if use_te:\n",
    "        te = make_te(train_df, val_df, test_df)\n",
    "        for te_name in TE_FEATURES:\n",
    "            train_df[te_name] = te[\"train\"][te_name]\n",
    "            val_df[te_name]   = te[\"val\"][te_name]\n",
    "            test_df[te_name]  = te[\"test\"][te_name]\n",
    "        cols += TE_FEATURES\n",
    "\n",
    "    X_tr = train_df[cols].copy()\n",
    "    X_va = val_df[cols].copy()\n",
    "    X_ts = test_df[cols].copy()\n",
    "\n",
    "    for c in cols:\n",
    "        med = X_tr[c].median()\n",
    "        if pd.isna(med): med = 0.0\n",
    "        X_tr[c] = X_tr[c].fillna(med)\n",
    "        X_va[c] = X_va[c].fillna(med)\n",
    "        X_ts[c] = X_ts[c].fillna(med)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr.values)\n",
    "    X_va = scaler.transform(X_va.values)\n",
    "    X_ts = scaler.transform(X_ts.values)\n",
    "\n",
    "    return X_tr, X_va, X_ts, len(cols)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ‚úÖ BEST PARAMS (ÎÑàÍ∞Ä Ï§Ä Í∑∏ÎåÄÎ°ú)\n",
    "# ============================================================\n",
    "BEST = {\n",
    "  \"use_te\": True,\n",
    "  \"use_summary\": True,\n",
    "  \"use_raw\": True,\n",
    "  \"n_layers\": 3,\n",
    "  \"hidden_base\": 256,\n",
    "  \"shrink\": 0.8212081026195875,\n",
    "  \"dropout\": 0.400484176222794,\n",
    "  \"lr\": 0.0014692944373311206,\n",
    "  \"weight_decay\": 0.001847088696674732,\n",
    "  \"batch_size\": 512\n",
    "}\n",
    "\n",
    "\n",
    "def hidden_dims_from(best):\n",
    "    n_layers = int(best[\"n_layers\"])\n",
    "    base = int(best[\"hidden_base\"])\n",
    "    shrink = float(best[\"shrink\"])\n",
    "    dims = []\n",
    "    cur = base\n",
    "    for _ in range(n_layers):\n",
    "        dims.append(int(cur))\n",
    "        cur = max(32, cur * shrink)\n",
    "    return dims\n",
    "\n",
    "\n",
    "def run_one_seed(seed, train_all, test_all, best):\n",
    "    set_seed(seed)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üå± SEED RUN: {seed}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    use_raw = bool(best[\"use_raw\"])\n",
    "    use_summary = bool(best[\"use_summary\"])\n",
    "    use_te = bool(best[\"use_te\"])\n",
    "\n",
    "    hidden_dims = hidden_dims_from(best)\n",
    "    dropout = float(best[\"dropout\"])\n",
    "    lr = float(best[\"lr\"])\n",
    "    wd = float(best[\"weight_decay\"])\n",
    "    bs = int(best[\"batch_size\"])\n",
    "\n",
    "    y = train_all[\"voted_bin\"].values.astype(np.float32)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)  # ‚úÖ seed Î∞òÏòÅ\n",
    "\n",
    "    oof = np.zeros(len(train_all), dtype=np.float32)\n",
    "    test_pred = np.zeros(len(test_all), dtype=np.float32)\n",
    "    fold_aucs = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(train_all, y), 1):\n",
    "        tr_df = train_all.iloc[tr_idx].copy().reset_index(drop=True)\n",
    "        va_df = train_all.iloc[va_idx].copy().reset_index(drop=True)\n",
    "        ts_df = test_all.copy()\n",
    "\n",
    "        X_tr, X_va, X_ts, n_feat = make_X(tr_df, va_df, ts_df, use_raw, use_summary, use_te)\n",
    "\n",
    "        y_tr = tr_df[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_va = va_df[\"voted_bin\"].values.astype(np.float32)\n",
    "\n",
    "        tr_ds = TabDataset(X_tr, y_tr)\n",
    "        va_ds = TabDataset(X_va, y_va)\n",
    "        ts_ds = TabDataset(X_ts)\n",
    "\n",
    "        tr_loader = DataLoader(tr_ds, batch_size=bs, shuffle=True, drop_last=True)\n",
    "        va_loader = DataLoader(va_ds, batch_size=bs, shuffle=False)\n",
    "        ts_loader = DataLoader(ts_ds, batch_size=bs, shuffle=False)\n",
    "\n",
    "        model = MLP(input_dim=n_feat, hidden_dims=hidden_dims, dropout=dropout)\n",
    "        auc = train_one_fold(model, tr_loader, va_loader, y_va, lr, wd, DEVICE)\n",
    "        fold_aucs.append(auc)\n",
    "\n",
    "        oof[va_idx] = predict(model, va_loader, DEVICE)\n",
    "        test_pred += predict(model, ts_loader, DEVICE) / N_FOLDS\n",
    "\n",
    "        print(f\"[Seed {seed}][Fold {fold}] AUC={auc:.5f} | n_feat={n_feat}\")\n",
    "\n",
    "    oof_auc = roc_auc_score(train_all[\"voted_bin\"], oof)\n",
    "    print(f\"‚úÖ SEED {seed} OOF AUC: {oof_auc:.5f} | fold mean: {np.mean(fold_aucs):.5f}\")\n",
    "\n",
    "    return oof_auc, oof, test_pred\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_clean = clean_data(train_raw)\n",
    "    test_clean  = clean_data(test_raw)\n",
    "\n",
    "    train_fe = build_features(train_clean)\n",
    "    test_fe  = build_features(test_clean)\n",
    "\n",
    "    all_oof = []\n",
    "    all_test = []\n",
    "    seed_scores = []\n",
    "\n",
    "    for s in SEEDS:\n",
    "        oof_auc, oof, test_pred = run_one_seed(s, train_fe, test_fe, BEST)\n",
    "        seed_scores.append((s, oof_auc))\n",
    "        all_oof.append(oof)\n",
    "        all_test.append(test_pred)\n",
    "\n",
    "        # Ï§ëÍ∞Ñ Ï†ÄÏû•(ÌòπÏãú Ï§ëÎã® ÎåÄÎπÑ)\n",
    "        np.save(f\"oof_seed{s}.npy\", oof)\n",
    "        np.save(f\"test_seed{s}.npy\", test_pred)\n",
    "\n",
    "    oof_ens = np.mean(all_oof, axis=0)\n",
    "    test_ens = np.mean(all_test, axis=0)\n",
    "    oof_auc_ens = roc_auc_score(train_fe[\"voted_bin\"], oof_ens)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÅ SEED ENSEMBLE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    for s, sc in seed_scores:\n",
    "        print(f\"Seed {s}: OOF AUC = {sc:.5f}\")\n",
    "    print(f\"‚úÖ Ensemble OOF AUC = {oof_auc_ens:.5f}\")\n",
    "\n",
    "    # submission\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else np.arange(len(test_raw)),\n",
    "        \"voted\": test_ens\n",
    "    })\n",
    "    out = f\"submission_seed_ens_{len(SEEDS)}.csv\"\n",
    "    sub.to_csv(out, index=False)\n",
    "    print(f\"üíæ Saved: {out}\")\n",
    "    print(f\"   pred range: [{test_ens.min():.4f}, {test_ens.max():.4f}]\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
