{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18_v5_empty ÏöîÏïΩ\n",
    "\n",
    "ÏßÄÌîºÌã∞Í∞Ä Ï§Ä ÏΩîÎìú. MLP ÌäπÌôî + Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94560ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Device: cpu\n",
      "üìÇ Train path: ../../data/raw/train.csv\n",
      "üìÇ Test  path: ../../data/raw/test_x.csv\n",
      "Train: (45532, 79), Test: (11383, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:43:44,527]\u001b[0m A new study created in memory with name: MLP_TE\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ OPTUNA START | trials=50 | timeout=None\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:44:37,886]\u001b[0m Trial 0 finished with value: 0.7590648796261102 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': False, 'n_layers': 2, 'hidden_base': 256, 'shrink': 0.5561753482887408, 'dropout': 0.4879639408647978, 'lr': 0.0019057174434080474, 'weight_decay': 5.474303040596577e-06, 'batch_size': 768}. Best is trial 0 with value: 0.7590648796261102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 000] AUC=0.75906 | raw=False sum=False te=True | feat=7 | layers=2 base=256 drop=0.49 lr=1.9e-03 wd=5.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:46:17,288]\u001b[0m Trial 1 finished with value: 0.767002972396001 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 2, 'hidden_base': 320, 'shrink': 0.7042703315240835, 'dropout': 0.336965827544817, 'lr': 0.00022680881003614686, 'weight_decay': 0.00012957079329680438, 'batch_size': 768}. Best is trial 1 with value: 0.767002972396001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 001] AUC=0.76700 | raw=True sum=True te=True | feat=117 | layers=2 base=320 drop=0.34 lr=2.3e-04 wd=1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:49:03,602]\u001b[0m Trial 2 finished with value: 0.7668141277305279 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 4, 'hidden_base': 384, 'shrink': 0.6276339944800051, 'dropout': 0.36500891374159283, 'lr': 0.00046519031844824204, 'weight_decay': 6.43190424662412e-05, 'batch_size': 768}. Best is trial 1 with value: 0.767002972396001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 002] AUC=0.76681 | raw=False sum=True te=True | feat=44 | layers=4 base=384 drop=0.37 lr=4.7e-04 wd=6.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:50:51,087]\u001b[0m Trial 3 finished with value: 0.7588779492432515 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': False, 'n_layers': 4, 'hidden_base': 384, 'shrink': 0.6314047095321688, 'dropout': 0.43149500366077176, 'lr': 0.0005255384124729445, 'weight_decay': 9.480764410116972e-06, 'batch_size': 768}. Best is trial 1 with value: 0.767002972396001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 003] AUC=0.75888 | raw=False sum=False te=True | feat=7 | layers=4 base=384 drop=0.43 lr=5.3e-04 wd=9.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:52:01,602]\u001b[0m Trial 4 finished with value: 0.7593676005384697 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': False, 'n_layers': 2, 'hidden_base': 128, 'shrink': 0.6575397185632817, 'dropout': 0.1463476238100519, 'lr': 0.002070705754931531, 'weight_decay': 0.00014698843461707762, 'batch_size': 256}. Best is trial 1 with value: 0.767002972396001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 004] AUC=0.75937 | raw=False sum=False te=True | feat=7 | layers=2 base=128 drop=0.15 lr=2.1e-03 wd=1.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:53:08,143]\u001b[0m Trial 5 finished with value: 0.7670133000050324 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 3, 'hidden_base': 384, 'shrink': 0.6981386789093172, 'dropout': 0.3090931317527976, 'lr': 0.0006365862447793237, 'weight_decay': 1.2257033861197374e-06, 'batch_size': 768}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 005] AUC=0.76701 | raw=True sum=False te=True | feat=80 | layers=3 base=384 drop=0.31 lr=6.4e-04 wd=1.2e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:54:11,480]\u001b[0m Trial 6 finished with value: 0.7589523299478351 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': False, 'n_layers': 3, 'hidden_base': 128, 'shrink': 0.8289092957027719, 'dropout': 0.4232481518257668, 'lr': 0.0011116565139318074, 'weight_decay': 0.0010719490427623113, 'batch_size': 768}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 006] AUC=0.75895 | raw=False sum=False te=True | feat=7 | layers=3 base=128 drop=0.42 lr=1.1e-03 wd=1.1e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:55:11,465]\u001b[0m Trial 7 finished with value: 0.7594688255530617 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': False, 'n_layers': 2, 'hidden_base': 320, 'shrink': 0.7032241907732697, 'dropout': 0.2669644012595116, 'lr': 0.0003649631783860978, 'weight_decay': 2.610877024242294e-06, 'batch_size': 512}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 007] AUC=0.75947 | raw=False sum=False te=True | feat=7 | layers=2 base=320 drop=0.27 lr=3.6e-04 wd=2.6e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:58:26,148]\u001b[0m Trial 8 finished with value: 0.7669002963784569 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 4, 'hidden_base': 192, 'shrink': 0.732869300193969, 'dropout': 0.30107160929154464, 'lr': 0.0002299183875519423, 'weight_decay': 9.308668046700128e-06, 'batch_size': 256}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 008] AUC=0.76690 | raw=True sum=False te=True | feat=80 | layers=4 base=192 drop=0.30 lr=2.3e-04 wd=9.3e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 14:59:09,150]\u001b[0m Trial 9 finished with value: 0.7645687002430146 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 4, 'hidden_base': 192, 'shrink': 0.7107324052224275, 'dropout': 0.13611590802176332, 'lr': 0.001920533820156232, 'weight_decay': 1.304341108466943e-05, 'batch_size': 768}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 009] AUC=0.76457 | raw=True sum=False te=True | feat=80 | layers=4 base=192 drop=0.14 lr=1.9e-03 wd=1.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:00:18,533]\u001b[0m Trial 10 finished with value: 0.7667011862858781 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 384, 'shrink': 0.7840821151029765, 'dropout': 0.22022592921973835, 'lr': 0.0008922000418351299, 'weight_decay': 1.0909934245539654e-06, 'batch_size': 512}. Best is trial 5 with value: 0.7670133000050324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 010] AUC=0.76670 | raw=True sum=True te=True | feat=117 | layers=3 base=384 drop=0.22 lr=8.9e-04 wd=1.1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:02:41,919]\u001b[0m Trial 11 finished with value: 0.7681226104407495 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 320, 'shrink': 0.755380450350449, 'dropout': 0.32737746462228084, 'lr': 0.00022604474759663955, 'weight_decay': 0.000309569322223745, 'batch_size': 768}. Best is trial 11 with value: 0.7681226104407495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 011] AUC=0.76812 | raw=True sum=True te=True | feat=117 | layers=3 base=320 drop=0.33 lr=2.3e-04 wd=3.1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:03:45,999]\u001b[0m Trial 12 finished with value: 0.766844601085314 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 320, 'shrink': 0.7640509895401062, 'dropout': 0.23462599072562113, 'lr': 0.0006865330630573106, 'weight_decay': 0.0007572493473526734, 'batch_size': 768}. Best is trial 11 with value: 0.7681226104407495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 012] AUC=0.76684 | raw=True sum=True te=True | feat=117 | layers=3 base=320 drop=0.23 lr=6.9e-04 wd=7.6e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:05:57,037]\u001b[0m Trial 13 finished with value: 0.768284046696638 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8353074784977317, 'dropout': 0.36766107960985267, 'lr': 0.0003398153769540061, 'weight_decay': 0.0028140894692944935, 'batch_size': 768}. Best is trial 13 with value: 0.768284046696638.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 013] AUC=0.76828 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.37 lr=3.4e-04 wd=2.8e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:08:27,896]\u001b[0m Trial 14 finished with value: 0.768654493304817 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8498071917482436, 'dropout': 0.3864234146727824, 'lr': 0.0003166989912534049, 'weight_decay': 0.002863312070574435, 'batch_size': 512}. Best is trial 14 with value: 0.768654493304817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 014] AUC=0.76865 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.39 lr=3.2e-04 wd=2.9e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:11:21,362]\u001b[0m Trial 15 finished with value: 0.7689775284825174 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8421348999410402, 'dropout': 0.39309087497171896, 'lr': 0.0003383296038615095, 'weight_decay': 0.002968877977814702, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 015] AUC=0.76898 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.39 lr=3.4e-04 wd=3.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:14:11,185]\u001b[0m Trial 16 finished with value: 0.7686199046361946 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8021611575184936, 'dropout': 0.4369506342433637, 'lr': 0.00033164718827404297, 'weight_decay': 0.0027069736751105643, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 016] AUC=0.76862 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.44 lr=3.3e-04 wd=2.7e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:16:21,231]\u001b[0m Trial 17 finished with value: 0.7689387176103165 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8401474517664183, 'dropout': 0.4989356820471556, 'lr': 0.0011744976734331992, 'weight_decay': 0.001263926798263844, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 017] AUC=0.76894 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.50 lr=1.2e-03 wd=1.3e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:18:39,466]\u001b[0m Trial 18 finished with value: 0.7688802941513074 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8050809601442778, 'dropout': 0.48874145838076666, 'lr': 0.001237722663618603, 'weight_decay': 0.0006861065342436687, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 018] AUC=0.76888 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.49 lr=1.2e-03 wd=6.9e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:20:33,852]\u001b[0m Trial 19 finished with value: 0.7687721882332067 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8126723150666904, 'dropout': 0.4983661689356219, 'lr': 0.0014795899959405522, 'weight_decay': 2.8442806533073437e-05, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 019] AUC=0.76877 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.50 lr=1.5e-03 wd=2.8e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:22:24,768]\u001b[0m Trial 20 finished with value: 0.7687750441106057 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.7794009226085834, 'dropout': 0.4614035607563235, 'lr': 0.002562660490023338, 'weight_decay': 0.0002984367275869683, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 020] AUC=0.76878 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.46 lr=2.6e-03 wd=3.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:24:20,752]\u001b[0m Trial 21 finished with value: 0.768959914570636 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8010323455842263, 'dropout': 0.39976911833787687, 'lr': 0.0011200454896944615, 'weight_decay': 0.0009692988204514945, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 021] AUC=0.76896 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.40 lr=1.1e-03 wd=9.7e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:26:34,752]\u001b[0m Trial 22 finished with value: 0.7683173373039505 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8478436350839929, 'dropout': 0.38934787174411306, 'lr': 0.0008591289432423338, 'weight_decay': 0.0013563553608019559, 'batch_size': 512}. Best is trial 15 with value: 0.7689775284825174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 022] AUC=0.76832 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.39 lr=8.6e-04 wd=1.4e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:28:25,893]\u001b[0m Trial 23 finished with value: 0.7690038116715596 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8165528419389355, 'dropout': 0.4117086462003842, 'lr': 0.0014032470140046105, 'weight_decay': 0.0004013819285642947, 'batch_size': 512}. Best is trial 23 with value: 0.7690038116715596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 023] AUC=0.76900 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.41 lr=1.4e-03 wd=4.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:30:09,691]\u001b[0m Trial 24 finished with value: 0.7686563875325909 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8112485118087688, 'dropout': 0.40612220516437303, 'lr': 0.0015069405320109965, 'weight_decay': 0.0003817253635174364, 'batch_size': 512}. Best is trial 23 with value: 0.7690038116715596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 024] AUC=0.76866 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.41 lr=1.5e-03 wd=3.8e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:31:48,273]\u001b[0m Trial 25 finished with value: 0.7687239036802068 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 128, 'shrink': 0.7797093698344238, 'dropout': 0.3476222367766634, 'lr': 0.0009930125801002913, 'weight_decay': 0.0004670325362269362, 'batch_size': 256}. Best is trial 23 with value: 0.7690038116715596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 025] AUC=0.76872 | raw=True sum=True te=True | feat=117 | layers=3 base=128 drop=0.35 lr=9.9e-04 wd=4.7e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:34:29,354]\u001b[0m Trial 26 finished with value: 0.7682714171298273 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 192, 'shrink': 0.749552388827784, 'dropout': 0.44814546092344437, 'lr': 0.0005884241029478547, 'weight_decay': 0.00015019029373019527, 'batch_size': 512}. Best is trial 23 with value: 0.7690038116715596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 026] AUC=0.76827 | raw=True sum=True te=True | feat=117 | layers=4 base=192 drop=0.45 lr=5.9e-04 wd=1.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:36:08,840]\u001b[0m Trial 27 finished with value: 0.7692024957969453 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8212081026195875, 'dropout': 0.400484176222794, 'lr': 0.0014692944373311206, 'weight_decay': 0.001847088696674732, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 027] AUC=0.76920 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.40 lr=1.5e-03 wd=1.8e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:37:26,704]\u001b[0m Trial 28 finished with value: 0.7678352608865049 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8238753925513683, 'dropout': 0.2672685456719082, 'lr': 0.0029024115487398814, 'weight_decay': 0.0016269072872528345, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 028] AUC=0.76784 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.27 lr=2.9e-03 wd=1.6e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:39:23,857]\u001b[0m Trial 29 finished with value: 0.7675568386262954 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 2, 'hidden_base': 256, 'shrink': 0.5869454911528061, 'dropout': 0.4622696833523103, 'lr': 0.0016242512266738756, 'weight_decay': 0.0016750792642157856, 'batch_size': 256}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 029] AUC=0.76756 | raw=False sum=True te=True | feat=44 | layers=2 base=256 drop=0.46 lr=1.6e-03 wd=1.7e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:40:28,085]\u001b[0m Trial 30 finished with value: 0.7677954226883845 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 2, 'hidden_base': 256, 'shrink': 0.7326957421370993, 'dropout': 0.36674711342346433, 'lr': 0.0022048949547795018, 'weight_decay': 0.000515025883613981, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 030] AUC=0.76780 | raw=True sum=True te=True | feat=117 | layers=2 base=256 drop=0.37 lr=2.2e-03 wd=5.2e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:42:10,895]\u001b[0m Trial 31 finished with value: 0.7689319133278163 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.7878205506992024, 'dropout': 0.4094688908975259, 'lr': 0.0014195303392724584, 'weight_decay': 0.0009183808347592663, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 031] AUC=0.76893 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.41 lr=1.4e-03 wd=9.2e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:43:51,083]\u001b[0m Trial 32 finished with value: 0.7690837448929781 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8208575600659658, 'dropout': 0.3975333121241607, 'lr': 0.0016938460587575148, 'weight_decay': 0.00023785471561921196, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 032] AUC=0.76908 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.40 lr=1.7e-03 wd=2.4e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:45:30,234]\u001b[0m Trial 33 finished with value: 0.7682732016448577 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8175348374784472, 'dropout': 0.343097251844308, 'lr': 0.00166154659549143, 'weight_decay': 7.432542655039172e-05, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 033] AUC=0.76827 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.34 lr=1.7e-03 wd=7.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:48:33,077]\u001b[0m Trial 34 finished with value: 0.7679630812134234 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8312378204880314, 'dropout': 0.46275774971952266, 'lr': 0.0004292717856614143, 'weight_decay': 0.00020980275610499568, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 034] AUC=0.76796 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.46 lr=4.3e-04 wd=2.1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:49:58,394]\u001b[0m Trial 35 finished with value: 0.7673732331831629 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 3, 'hidden_base': 128, 'shrink': 0.5508003883831845, 'dropout': 0.37766717433327407, 'lr': 0.0022957759875348468, 'weight_decay': 3.544897992004013e-05, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 035] AUC=0.76737 | raw=False sum=True te=True | feat=44 | layers=3 base=128 drop=0.38 lr=2.3e-03 wd=3.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:51:24,670]\u001b[0m Trial 36 finished with value: 0.7681751707151605 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 2, 'hidden_base': 384, 'shrink': 0.6780073687171781, 'dropout': 0.423385357798295, 'lr': 0.001747529447600665, 'weight_decay': 0.00010194089903724452, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 036] AUC=0.76818 | raw=True sum=True te=True | feat=117 | layers=2 base=384 drop=0.42 lr=1.7e-03 wd=1.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:54:00,957]\u001b[0m Trial 37 finished with value: 0.7677214781326368 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.7654255396502773, 'dropout': 0.3349871310568924, 'lr': 0.0007428481715553115, 'weight_decay': 0.00024328927995580135, 'batch_size': 256}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 037] AUC=0.76772 | raw=False sum=True te=True | feat=44 | layers=3 base=256 drop=0.33 lr=7.4e-04 wd=2.4e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:55:48,652]\u001b[0m Trial 38 finished with value: 0.7670691540684158 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 3, 'hidden_base': 192, 'shrink': 0.795706416877307, 'dropout': 0.41334899623165544, 'lr': 0.0013610467954839243, 'weight_decay': 0.000565426696849088, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 038] AUC=0.76707 | raw=True sum=False te=True | feat=80 | layers=3 base=192 drop=0.41 lr=1.4e-03 wd=5.7e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:58:09,749]\u001b[0m Trial 39 finished with value: 0.7673562442385589 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 3, 'hidden_base': 320, 'shrink': 0.5791227315633932, 'dropout': 0.31736459433708775, 'lr': 0.00028332726400310735, 'weight_decay': 0.0019039245485677181, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 039] AUC=0.76736 | raw=False sum=True te=True | feat=44 | layers=3 base=320 drop=0.32 lr=2.8e-04 wd=1.9e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 15:59:15,475]\u001b[0m Trial 40 finished with value: 0.7631800675274248 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 2, 'hidden_base': 128, 'shrink': 0.8209865180875415, 'dropout': 0.11066014789029541, 'lr': 0.0004688212665958192, 'weight_decay': 0.00010873766484227687, 'batch_size': 256}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 040] AUC=0.76318 | raw=True sum=False te=True | feat=80 | layers=2 base=128 drop=0.11 lr=4.7e-04 wd=1.1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:01:43,087]\u001b[0m Trial 41 finished with value: 0.7685328421980122 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.8293414886412718, 'dropout': 0.3935939587280551, 'lr': 0.001061518130575912, 'weight_decay': 0.0009201558248174479, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 041] AUC=0.76853 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.39 lr=1.1e-03 wd=9.2e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:03:26,914]\u001b[0m Trial 42 finished with value: 0.7688373516978179 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.7992453979687377, 'dropout': 0.43865210727384457, 'lr': 0.001858553590117446, 'weight_decay': 0.0021322501734196376, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 042] AUC=0.76884 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.44 lr=1.9e-03 wd=2.1e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:05:22,413]\u001b[0m Trial 43 finished with value: 0.7683779535405069 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.6398744963738558, 'dropout': 0.3572741878389514, 'lr': 0.00127392297938178, 'weight_decay': 0.0011685290401070607, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 043] AUC=0.76838 | raw=True sum=True te=True | feat=117 | layers=4 base=256 drop=0.36 lr=1.3e-03 wd=1.2e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:07:34,531]\u001b[0m Trial 44 finished with value: 0.7683788530585599 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 384, 'shrink': 0.836449401675178, 'dropout': 0.40064838977515466, 'lr': 0.000936672617143422, 'weight_decay': 0.00017679632596510826, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 044] AUC=0.76838 | raw=True sum=True te=True | feat=117 | layers=3 base=384 drop=0.40 lr=9.4e-04 wd=1.8e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:10:00,854]\u001b[0m Trial 45 finished with value: 0.7668621708685619 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 4, 'hidden_base': 256, 'shrink': 0.7403368895182234, 'dropout': 0.2871714631374699, 'lr': 0.0008009608157340018, 'weight_decay': 0.0007147388203982892, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 045] AUC=0.76686 | raw=True sum=False te=True | feat=80 | layers=4 base=256 drop=0.29 lr=8.0e-04 wd=7.1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:12:42,863]\u001b[0m Trial 46 finished with value: 0.7685974434635587 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.7737885624464201, 'dropout': 0.4711662960421699, 'lr': 0.0010740591113376032, 'weight_decay': 0.002057690776554118, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 046] AUC=0.76860 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.47 lr=1.1e-03 wd=2.1e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:15:13,979]\u001b[0m Trial 47 finished with value: 0.7672503333927604 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': False, 'n_layers': 4, 'hidden_base': 320, 'shrink': 0.7925112007934656, 'dropout': 0.42314799119964586, 'lr': 0.001303594211118718, 'weight_decay': 0.000382664699392619, 'batch_size': 768}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 047] AUC=0.76725 | raw=False sum=True te=True | feat=44 | layers=4 base=320 drop=0.42 lr=1.3e-03 wd=3.8e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:16:36,505]\u001b[0m Trial 48 finished with value: 0.7674712415498529 and parameters: {'use_te': True, 'use_summary': False, 'use_raw': True, 'n_layers': 3, 'hidden_base': 192, 'shrink': 0.717267986566778, 'dropout': 0.3767220330048511, 'lr': 0.002078654917538259, 'weight_decay': 3.4473085526509026e-06, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 048] AUC=0.76747 | raw=True sum=False te=True | feat=80 | layers=3 base=192 drop=0.38 lr=2.1e-03 wd=3.4e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 16:18:55,063]\u001b[0m Trial 49 finished with value: 0.7659989530261372 and parameters: {'use_te': True, 'use_summary': True, 'use_raw': True, 'n_layers': 3, 'hidden_base': 256, 'shrink': 0.8458404250813222, 'dropout': 0.19235459996755194, 'lr': 0.00027467204985373025, 'weight_decay': 0.0009231193194598854, 'batch_size': 512}. Best is trial 27 with value: 0.7692024957969453.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 049] AUC=0.76600 | raw=True sum=True te=True | feat=117 | layers=3 base=256 drop=0.19 lr=2.7e-04 wd=9.2e-04\n",
      "\n",
      "================================================================================\n",
      "üèÅ OPTUNA DONE\n",
      "================================================================================\n",
      "Best AUC: 0.7692024957969453\n",
      "Best params:\n",
      " {\n",
      "  \"use_te\": true,\n",
      "  \"use_summary\": true,\n",
      "  \"use_raw\": true,\n",
      "  \"n_layers\": 3,\n",
      "  \"hidden_base\": 256,\n",
      "  \"shrink\": 0.8212081026195875,\n",
      "  \"dropout\": 0.400484176222794,\n",
      "  \"lr\": 0.0014692944373311206,\n",
      "  \"weight_decay\": 0.001847088696674732,\n",
      "  \"batch_size\": 512\n",
      "}\n",
      "[BEST][Fold 1] AUC=0.78046 | n_feat=117\n",
      "[BEST][Fold 2] AUC=0.76859 | n_feat=117\n",
      "[BEST][Fold 3] AUC=0.76236 | n_feat=117\n",
      "[BEST][Fold 4] AUC=0.76231 | n_feat=117\n",
      "[BEST][Fold 5] AUC=0.76968 | n_feat=117\n",
      "\n",
      "‚úÖ BEST OOF AUC: 0.76833 | fold mean: 0.76868\n",
      "\n",
      "üíæ Saved: submission_mlp_optuna_te1_sum1_raw1_auc0.76833_0130_162044.csv\n",
      "üíæ Saved: submission_mlp_optuna_te1_sum1_raw1_auc0.76833_0130_162044_params.json\n",
      "   pred range: [0.0935, 0.9987]\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "TRAIN_PATH = \"../../data/raw/train.csv\"\n",
    "TEST_PATH  = \"../../data/raw/test_x.csv\"\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Optuna\n",
    "N_TRIALS = 50                 # ÏãúÍ∞Ñ ÎêòÎ©¥ 200~500ÍπåÏßÄ ÎäòÎ†§ÎèÑ Îê®\n",
    "TIMEOUT_SEC = None            # Ïòà: 60*60*3 (3ÏãúÍ∞Ñ) Îì±\n",
    "OPTUNA_STUDY_NAME = \"MLP_TE\"\n",
    "OPTUNA_STORAGE = None         # \"sqlite:///optuna_mlp.db\" Î°ú ÌïòÎ©¥ Ï§ëÎã®/Ïû¨Í∞ú Í∞ÄÎä•\n",
    "\n",
    "# Train\n",
    "EPOCHS = 80\n",
    "PATIENCE = 10\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n",
    "print(f\"üìÇ Train path: {TRAIN_PATH}\")\n",
    "print(f\"üìÇ Test  path: {TEST_PATH}\")\n",
    "\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Data Load\n",
    "# ============================================================\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Preprocess (ÎÑàÍ∞Ä Ïì∞Îçò Î∞©Ïãù Ïú†ÏßÄ)\n",
    "# ============================================================\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Î¨¥ÏùëÎãµ (0 ‚Üí NaN)\n",
    "    for col in [\"education\", \"engnat\", \"hand\", \"married\", \"urban\"]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # familysize\n",
    "    if \"familysize\" in df.columns:\n",
    "        df.loc[df[\"familysize\"] == 0, \"familysize\"] = np.nan\n",
    "        df.loc[df[\"familysize\"] > 15, \"familysize\"] = np.nan\n",
    "\n",
    "    # TP 0 ‚Üí NaN\n",
    "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # Q_E clipping\n",
    "    for col in [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].clip(lower=100, upper=60000)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Feature Engineering\n",
    "# - RAW:   ÏõêÎ≥∏ Î¨∏Ìï≠Îì§(qa/qe/tp/wr/wf)\n",
    "# - SUM:   ÏöîÏïΩÌÜµÍ≥Ñ + Í∞ÑÎã® interaction\n",
    "# - TE:    target encoding (CV ÎÇ¥Î∂ÄÏóêÏÑúÎßå ÏÉùÏÑ±)\n",
    "# ============================================================\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # demographic\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "\n",
    "    df[\"is_teenager\"] = (df[\"age_ord\"] == 1).astype(float)\n",
    "    df[\"is_young\"] = (df[\"age_ord\"] <= 2).astype(float)\n",
    "    df[\"is_old\"] = (df[\"age_ord\"] >= 6).astype(float)\n",
    "\n",
    "    df[\"edu_low\"] = (df[\"education\"] <= 2).astype(float)\n",
    "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float)\n",
    "\n",
    "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float)\n",
    "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float)\n",
    "\n",
    "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float)\n",
    "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float)\n",
    "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(float)\n",
    "\n",
    "    # Q_A summary\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
    "    df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
    "    df[\"qa_range\"] = df[qa_cols].max(axis=1) - df[qa_cols].min(axis=1)\n",
    "    df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / len(qa_cols)\n",
    "    df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / len(qa_cols)\n",
    "    df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(float)\n",
    "\n",
    "    # Q_E log + summary\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    for c in qe_cols:\n",
    "        df[f\"{c}_log\"] = np.log1p(df[c])\n",
    "\n",
    "    qe_log_cols = [f\"{c}_log\" for c in qe_cols]\n",
    "    df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
    "    df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
    "    df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / len(qe_cols)\n",
    "    df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
    "    df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df[\"qa_all_same\"] == 1)).astype(float)\n",
    "\n",
    "    # TP summary (Big5 style)\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / len(tp_cols)\n",
    "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "    df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
    "\n",
    "    # WR/WF\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "    df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(float)\n",
    "\n",
    "    # interaction\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
    "    df[\"young_low_edu\"] = df[\"is_young\"] * df[\"edu_low\"]\n",
    "    df[\"young_single\"] = df[\"is_young\"] * df[\"is_single\"]\n",
    "    df[\"old_married\"] = df[\"is_old\"] * df[\"is_married\"]\n",
    "    df[\"teenager_low_edu\"] = df[\"is_teenager\"] * df[\"edu_low\"]\n",
    "\n",
    "    # for TE combos\n",
    "    df[\"age_edu_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"education\"].astype(str)\n",
    "    df[\"age_married_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"married\"].astype(str)\n",
    "    df[\"age_race_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"race\"].astype(str)\n",
    "    df[\"age_edu_married_cat\"] = df[\"age_group\"].astype(str) + \"_\" + df[\"education\"].astype(str) + \"_\" + df[\"married\"].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Target Encoding (fold ÎÇ¥Î∂ÄÏóêÏÑúÎßå)\n",
    "# ============================================================\n",
    "def target_encode(train_df, val_df, test_df, col, target_col=\"voted_bin\", smoothing=10):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    agg = train_df.groupby(col)[target_col].agg([\"mean\", \"count\"])\n",
    "    te = (agg[\"count\"] * agg[\"mean\"] + smoothing * global_mean) / (agg[\"count\"] + smoothing)\n",
    "    te_map = te.to_dict()\n",
    "\n",
    "    return (\n",
    "        train_df[col].map(te_map).fillna(global_mean).values,\n",
    "        val_df[col].map(te_map).fillna(global_mean).values,\n",
    "        test_df[col].map(te_map).fillna(global_mean).values,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_te(train_df, val_df, test_df):\n",
    "    out = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "\n",
    "    single_cols = [(\"age_group\", 10), (\"race\", 10), (\"religion\", 10)]\n",
    "    combo_cols  = [(\"age_edu_cat\", 5), (\"age_married_cat\", 5), (\"age_race_cat\", 5), (\"age_edu_married_cat\", 3)]\n",
    "\n",
    "    for c, sm in single_cols + combo_cols:\n",
    "        tr, va, ts = target_encode(train_df, val_df, test_df, c, \"voted_bin\", sm)\n",
    "        out[\"train\"][f\"{c}_te\"] = tr\n",
    "        out[\"val\"][f\"{c}_te\"] = va\n",
    "        out[\"test\"][f\"{c}_te\"] = ts\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Feature Groups (ÎÑàÍ∞Ä ÏõêÌïú ‚ÄúÏ†ïÎ¶¨‚Äù Í∑∏ÎåÄÎ°ú ÏΩîÎìúÏóê Î∞òÏòÅ)\n",
    "# ============================================================\n",
    "QA_RAW = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "QE_RAW = [f\"Q{c}E_log\" for c in \"abcdefghijklmnopqrst\"]  # log ÏÇ¨Ïö©\n",
    "TP_RAW = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "WR_RAW = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "WF_RAW = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "RAW_FEATURES = QA_RAW + QE_RAW + TP_RAW + WR_RAW + WF_RAW + [\"education\", \"married\", \"urban\", \"engnat\", \"familysize\", \"hand\", \"age_ord\"]\n",
    "\n",
    "SUMMARY_FEATURES = [\n",
    "    \"is_teenager\", \"is_young\", \"is_old\", \"edu_low\", \"edu_high\",\n",
    "    \"is_single\", \"is_married\", \"is_urban\", \"is_english_native\", \"is_male\",\n",
    "    \"qa_mean\", \"qa_std\", \"qa_range\", \"qa_extreme_ratio\", \"qa_neutral_ratio\", \"qa_all_same\",\n",
    "    \"qe_log_mean\", \"qe_log_std\", \"qe_fast_ratio\", \"qe_total_log\", \"is_careless\",\n",
    "    \"tp_missing_ratio\", \"tp_mean\",\n",
    "    \"extraversion\", \"agreeableness\", \"conscientiousness\", \"neuroticism\", \"openness\",\n",
    "    \"wr_sum\", \"wf_sum\", \"word_credibility\", \"vocab_high\",\n",
    "    \"age_edu\", \"young_low_edu\", \"young_single\", \"old_married\", \"teenager_low_edu\",\n",
    "]\n",
    "\n",
    "TE_FEATURES = [\n",
    "    \"age_group_te\", \"race_te\", \"religion_te\",\n",
    "    \"age_edu_cat_te\", \"age_married_cat_te\", \"age_race_cat_te\", \"age_edu_married_cat_te\",\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MLP Model (OptunaÎ°ú Íµ¨Ï°∞ ÌäúÎãù)\n",
    "# ============================================================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [\n",
    "                nn.Linear(prev, h),\n",
    "                nn.BatchNorm1d(h),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(dropout),\n",
    "            ]\n",
    "            prev = h\n",
    "        layers += [nn.Linear(prev, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        # init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train / Eval\n",
    "# ============================================================\n",
    "def train_one_fold(model, tr_loader, va_loader, y_va, lr, weight_decay, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # imbalance ÎåÄÏùë(ÎÑàÍ∞Ä Ïì∞Îçò Î∞©Ïãù Ïú†ÏßÄ)\n",
    "    pos_ratio = float(np.mean(y_va))\n",
    "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "    best_auc, best_state, no_imp = -1, None, 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for x, y in tr_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for x, _y in va_loader:\n",
    "                x = x.to(device)\n",
    "                preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "        preds = np.concatenate(preds).ravel()\n",
    "        auc = roc_auc_score(y_va, preds)\n",
    "        sched.step(auc)\n",
    "\n",
    "        if auc > best_auc + 1e-5:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "\n",
    "        if no_imp >= PATIENCE:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return best_auc\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            if isinstance(x, (tuple, list)):\n",
    "                x = x[0]\n",
    "            x = x.to(device)\n",
    "            preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build fold matrices (feature modeÎ°ú RAW/SUM/TE ÏÑ†ÌÉù)\n",
    "# ============================================================\n",
    "def make_X(train_df, val_df, test_df, use_raw, use_summary, use_te):\n",
    "    cols = []\n",
    "\n",
    "    # RAWÎäî ÎπÑÏö© ÎåÄÎπÑ Ïù¥ÎìùÏù¥ ÏºÄÏù¥Ïä§ Îî∞Îùº Í∞àÎ†§ÏÑú ‚ÄúÏòµÏÖò‚ÄùÏúºÎ°ú Îë†\n",
    "    if use_raw:\n",
    "        cols += RAW_FEATURES\n",
    "\n",
    "    if use_summary:\n",
    "        cols += SUMMARY_FEATURES\n",
    "\n",
    "    # TEÎäî fold ÎÇ¥Î∂ÄÏóêÏÑú ÏÉùÏÑ±Ìï¥ÏÑú Î∂ôÏûÑ\n",
    "    if use_te:\n",
    "        te = make_te(train_df, val_df, test_df)\n",
    "        for te_name in TE_FEATURES:\n",
    "            train_df[te_name] = te[\"train\"][te_name]\n",
    "            val_df[te_name]   = te[\"val\"][te_name]\n",
    "            test_df[te_name]  = te[\"test\"][te_name]\n",
    "        cols += TE_FEATURES\n",
    "\n",
    "    X_tr = train_df[cols].copy()\n",
    "    X_va = val_df[cols].copy()\n",
    "    X_ts = test_df[cols].copy()\n",
    "\n",
    "    # NaN -> train median\n",
    "    for c in cols:\n",
    "        med = X_tr[c].median()\n",
    "        if pd.isna(med):\n",
    "            med = 0.0\n",
    "        X_tr[c] = X_tr[c].fillna(med)\n",
    "        X_va[c] = X_va[c].fillna(med)\n",
    "        X_ts[c] = X_ts[c].fillna(med)\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr.values)\n",
    "    X_va = scaler.transform(X_va.values)\n",
    "    X_ts = scaler.transform(X_ts.values)\n",
    "\n",
    "    return X_tr, X_va, X_ts, len(cols)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Optuna Objective (MLP only)\n",
    "# ============================================================\n",
    "def objective(trial: optuna.Trial, train_all: pd.DataFrame, test_all: pd.DataFrame):\n",
    "    # feature modeÎèÑ Í∞ôÏù¥ ÌÉêÏÉâ Í∞ÄÎä• (ÎÑàÍ∞Ä ÏõêÌïú ‚ÄúÎ≠êÍ∞Ä ÎßûÎäîÏßÄ ÌÖåÏä§Ìä∏‚ÄùÎ•º ÏûêÎèôÌôî)\n",
    "    use_te = trial.suggest_categorical(\"use_te\", [True])  # TEÎäî Í≥†Ï†ï Ï∂îÏ≤ú\n",
    "    use_summary = trial.suggest_categorical(\"use_summary\", [True, False])\n",
    "    use_raw = trial.suggest_categorical(\"use_raw\", [False, True])  # rawÎäî ÏºÄÏù¥Ïä§Ïóê Îî∞Îùº Îã¨ÎùºÏÑú ÌÉêÏÉâ\n",
    "\n",
    "    # model params\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
    "    base = trial.suggest_categorical(\"hidden_base\", [128, 192, 256, 320, 384])\n",
    "    shrink = trial.suggest_float(\"shrink\", 0.55, 0.85)\n",
    "    hidden_dims = []\n",
    "    cur = base\n",
    "    for _ in range(n_layers):\n",
    "        hidden_dims.append(int(cur))\n",
    "        cur = max(32, cur * shrink)\n",
    "\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 2e-4, 3e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 3e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 768])\n",
    "\n",
    "    # CV\n",
    "    y = train_all[\"voted_bin\"].values.astype(np.float32)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    fold_aucs = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(train_all, y), 1):\n",
    "        tr_df = train_all.iloc[tr_idx].copy().reset_index(drop=True)\n",
    "        va_df = train_all.iloc[va_idx].copy().reset_index(drop=True)\n",
    "        ts_df = test_all.copy()\n",
    "\n",
    "        X_tr, X_va, _, n_feat = make_X(tr_df, va_df, ts_df, use_raw, use_summary, use_te)\n",
    "\n",
    "        y_tr = tr_df[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_va = va_df[\"voted_bin\"].values.astype(np.float32)\n",
    "\n",
    "        tr_ds = TabDataset(X_tr, y_tr)\n",
    "        va_ds = TabDataset(X_va, y_va)\n",
    "\n",
    "        tr_loader = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        va_loader = DataLoader(va_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = MLP(input_dim=n_feat, hidden_dims=hidden_dims, dropout=dropout)\n",
    "        auc = train_one_fold(model, tr_loader, va_loader, y_va, lr, weight_decay, DEVICE)\n",
    "\n",
    "        fold_aucs.append(auc)\n",
    "        trial.report(float(np.mean(fold_aucs)), step=fold)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    mean_auc = float(np.mean(fold_aucs))\n",
    "\n",
    "    # ÎÑàÍ∞Ä ÏõêÌïú ‚Äúprint ÎπÑÍµê‚Äù\n",
    "    print(f\"[Trial {trial.number:03d}] AUC={mean_auc:.5f} | raw={use_raw} sum={use_summary} te={use_te} | feat={n_feat} | layers={n_layers} base={base} drop={dropout:.2f} lr={lr:.1e} wd={weight_decay:.1e}\")\n",
    "    return mean_auc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train best and make submissions\n",
    "# ============================================================\n",
    "def train_and_predict_best(best_params, train_all, test_all):\n",
    "    use_raw = best_params[\"use_raw\"]\n",
    "    use_summary = best_params[\"use_summary\"]\n",
    "    use_te = best_params[\"use_te\"]\n",
    "\n",
    "    # hidden dims Î≥µÏõê\n",
    "    n_layers = int(best_params[\"n_layers\"])\n",
    "    base = int(best_params[\"hidden_base\"])\n",
    "    shrink = float(best_params[\"shrink\"])\n",
    "    hidden_dims = []\n",
    "    cur = base\n",
    "    for _ in range(n_layers):\n",
    "        hidden_dims.append(int(cur))\n",
    "        cur = max(32, cur * shrink)\n",
    "\n",
    "    dropout = float(best_params[\"dropout\"])\n",
    "    lr = float(best_params[\"lr\"])\n",
    "    weight_decay = float(best_params[\"weight_decay\"])\n",
    "    batch_size = int(best_params[\"batch_size\"])\n",
    "\n",
    "    y = train_all[\"voted_bin\"].values.astype(np.float32)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    oof = np.zeros(len(train_all), dtype=np.float32)\n",
    "    test_pred = np.zeros(len(test_all), dtype=np.float32)\n",
    "\n",
    "    fold_aucs = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(train_all, y), 1):\n",
    "        tr_df = train_all.iloc[tr_idx].copy().reset_index(drop=True)\n",
    "        va_df = train_all.iloc[va_idx].copy().reset_index(drop=True)\n",
    "        ts_df = test_all.copy()\n",
    "\n",
    "        X_tr, X_va, X_ts, n_feat = make_X(tr_df, va_df, ts_df, use_raw, use_summary, use_te)\n",
    "\n",
    "        y_tr = tr_df[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_va = va_df[\"voted_bin\"].values.astype(np.float32)\n",
    "\n",
    "        tr_ds = TabDataset(X_tr, y_tr)\n",
    "        va_ds = TabDataset(X_va, y_va)\n",
    "        ts_ds = TabDataset(X_ts)\n",
    "\n",
    "        tr_loader = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        va_loader = DataLoader(va_ds, batch_size=batch_size, shuffle=False)\n",
    "        ts_loader = DataLoader(ts_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = MLP(input_dim=n_feat, hidden_dims=hidden_dims, dropout=dropout)\n",
    "        auc = train_one_fold(model, tr_loader, va_loader, y_va, lr, weight_decay, DEVICE)\n",
    "        fold_aucs.append(auc)\n",
    "\n",
    "        oof[va_idx] = predict(model, va_loader, DEVICE)\n",
    "        test_pred += predict(model, ts_loader, DEVICE) / N_FOLDS\n",
    "\n",
    "        print(f\"[BEST][Fold {fold}] AUC={auc:.5f} | n_feat={n_feat}\")\n",
    "\n",
    "    oof_auc = roc_auc_score(train_all[\"voted_bin\"], oof)\n",
    "    print(f\"\\n‚úÖ BEST OOF AUC: {oof_auc:.5f} | fold mean: {np.mean(fold_aucs):.5f}\")\n",
    "\n",
    "    return oof_auc, test_pred, fold_aucs\n",
    "\n",
    "\n",
    "def auto_name(prefix, oof_auc, params):\n",
    "    t = time.strftime(\"%m%d_%H%M%S\")\n",
    "    mode = f\"te{int(params['use_te'])}_sum{int(params['use_summary'])}_raw{int(params['use_raw'])}\"\n",
    "    return f\"{prefix}_{mode}_auc{oof_auc:.5f}_{t}\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    train_clean = clean_data(train_raw)\n",
    "    test_clean  = clean_data(test_raw)\n",
    "\n",
    "    train_fe = build_features(train_clean)\n",
    "    test_fe  = build_features(test_clean)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "    pruner  = optuna.pruners.MedianPruner(n_warmup_steps=2)\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        study_name=OPTUNA_STUDY_NAME,\n",
    "        storage=OPTUNA_STORAGE,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üöÄ OPTUNA START | trials={N_TRIALS} | timeout={TIMEOUT_SEC}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    study.optimize(lambda tr: objective(tr, train_fe, test_fe), n_trials=N_TRIALS, timeout=TIMEOUT_SEC)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÅ OPTUNA DONE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Best AUC:\", study.best_value)\n",
    "    print(\"Best params:\\n\", json.dumps(study.best_params, indent=2))\n",
    "\n",
    "    # train best and predict\n",
    "    best_auc, test_pred, fold_aucs = train_and_predict_best(study.best_params, train_fe, test_fe)\n",
    "\n",
    "    # submission auto naming\n",
    "    base = auto_name(\"submission_mlp_optuna\", best_auc, study.best_params)\n",
    "\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else np.arange(len(test_raw)),\n",
    "        \"voted\": test_pred\n",
    "    })\n",
    "    sub_path = f\"{base}.csv\"\n",
    "    sub.to_csv(sub_path, index=False)\n",
    "\n",
    "    # save params too\n",
    "    with open(f\"{base}_params.json\", \"w\") as f:\n",
    "        json.dump({\"best_auc\": best_auc, \"fold_aucs\": fold_aucs, \"params\": study.best_params}, f, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Saved: {sub_path}\")\n",
    "    print(f\"üíæ Saved: {base}_params.json\")\n",
    "    print(f\"   pred range: [{test_pred.min():.4f}, {test_pred.max():.4f}]\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
