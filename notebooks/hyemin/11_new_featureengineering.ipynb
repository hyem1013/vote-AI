{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c520a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22f9bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test  = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n",
    "train[\"voted_bin\"] = (train[\"voted\"] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3e9d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≥µÌÜµ Ïú†Ìã∏ Ìï®Ïàò (bin, ÏïàÏ†Ñ Ï≤òÎ¶¨)\n",
    "def three_bin_diff(x):\n",
    "    return np.where(x <= -2, 0, np.where(x >= 2, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd8d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qb', 'QbE']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = train.columns.str.strip()\n",
    "test.columns  = test.columns.str.strip()\n",
    "\n",
    "# QxA Ïª¨ÎüºÎßå QxÎ°ú Î¶¨ÎÑ§ÏûÑ (QxEÎäî Í∑∏ÎåÄÎ°ú Îë†)\n",
    "rename_map = {c: c[:-1] for c in train.columns if c.startswith(\"Q\") and c.endswith(\"A\")}\n",
    "\n",
    "train = train.rename(columns=rename_map)\n",
    "test  = test.rename(columns=rename_map)\n",
    "\n",
    "# 3) ÌôïÏù∏\n",
    "[c for c in train.columns if c.startswith(\"Qb\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73757af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(6.124683390894205), np.float64(7.802618063442671))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q_EÏö© ÏÇ¨Ï†Ñ Í≥ÑÏÇ∞ (train Í∏∞Ï§Ä)\n",
    "qe_cols = [c for c in train.columns if c.endswith(\"E\")]\n",
    "len(qe_cols), qe_cols[:5]\n",
    "\n",
    "train_log_time = np.log1p(train[qe_cols])\n",
    "\n",
    "P10 = train_log_time.stack().quantile(0.10)\n",
    "P90 = train_log_time.stack().quantile(0.90)\n",
    "\n",
    "P10, P90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289d6e4",
   "metadata": {},
   "source": [
    "### 1. Feature Engineering Ìï®Ïàò Ï†ïÏùò (Ïó∞ÏÜçÌòï + Ïù¥ÏßÑÌòï)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319131d7",
   "metadata": {},
   "source": [
    "##### Q_A (ÌÉúÎèÑ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73e26bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qa_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"neg_att\"] = df[[\"Qb\",\"Qc\",\"Qj\",\"Qm\",\"Qo\",\"Qs\"]].mean(axis=1)\n",
    "    df[\"pos_att\"] = df[[\"Qk\",\"Qq\"]].mean(axis=1)\n",
    "    df[\"att_gap\"] = df[\"pos_att\"] - df[\"neg_att\"]\n",
    "\n",
    "    cert_cols = [\"Qe\",\"Qf\",\"Qh\",\"Qr\"]\n",
    "    df[\"certainty\"] = (df[cert_cols] - 3).abs().mean(axis=1)\n",
    "    df[\"mid_ratio\"] = (df[cert_cols] == 3).sum(axis=1) / len(cert_cols)\n",
    "\n",
    "    df[\"consistency\"] = df[\n",
    "        [\"Qb\",\"Qc\",\"Qj\",\"Qm\",\"Qo\",\"Qs\",\"Qk\",\"Qq\"]\n",
    "    ].std(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148107a2",
   "metadata": {},
   "source": [
    "##### Q_E (ÏùëÎãµÏãúÍ∞Ñ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74111f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qe_features(df, qe_cols, p10, p90):\n",
    "    df = df.copy()\n",
    "    log_time = np.log1p(df[qe_cols])\n",
    "\n",
    "    df[\"time_mean\"]   = log_time.mean(axis=1)\n",
    "    df[\"time_median\"] = log_time.median(axis=1)\n",
    "    df[\"time_std\"]    = log_time.std(axis=1)\n",
    "\n",
    "    df[\"fast_ratio\"] = (log_time < p10).mean(axis=1)\n",
    "    df[\"slow_ratio\"] = (log_time > p90).mean(axis=1)\n",
    "    df[\"outlier_ratio\"] = (df[qe_cols] > 10000).mean(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce324f",
   "metadata": {},
   "source": [
    "##### TP (Big Five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a2be2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tp_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    df[tp_cols] = df[tp_cols].replace(0, np.nan)\n",
    "    df[tp_cols] = df[tp_cols].fillna(df[tp_cols].mean())\n",
    "\n",
    "    df[\"extraversion\"]      = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"]     = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"]       = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"]          = df[\"tp05\"] - df[\"tp10\"]\n",
    "\n",
    "    for col in [\n",
    "        \"extraversion\",\"agreeableness\",\n",
    "        \"conscientiousness\",\"neuroticism\",\"openness\"\n",
    "    ]:\n",
    "        df[col + \"_bin\"] = three_bin_diff(df[col].values)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2891dbe",
   "metadata": {},
   "source": [
    "##### Ïù∏Íµ¨ÌÜµÍ≥Ñ (DEMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a56daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_demo_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    age_map = {\n",
    "        \"10s\":1,\"20s\":2,\"30s\":3,\"40s\":4,\n",
    "        \"50s\":5,\"60s\":6,\"70s+\":7\n",
    "    }\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    df[\"adult_flag\"] = (df[\"age_group\"] != \"10s\").astype(int)\n",
    "\n",
    "    df[\"education_ord\"] = df[\"education\"].replace(0, np.nan)\n",
    "    df[\"engnat_bin\"] = df[\"engnat\"].replace({1:1, 2:0, 0:np.nan})\n",
    "    df[\"gender_bin\"] = df[\"gender\"].map({\"Male\":0, \"Female\":1})\n",
    "\n",
    "    df[\"urban_ord\"] = df[\"urban\"].replace(0, np.nan)\n",
    "\n",
    "    fs = df[\"familysize\"].copy()\n",
    "    fs = fs.mask((fs < 0) | (fs > 1000))\n",
    "    df[\"familysize_clip\"] = fs.clip(upper=12)\n",
    "    df[\"familysize_outlier\"] = (fs > 12).fillna(False).astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4c2e9",
   "metadata": {},
   "source": [
    "##### Îã®Ïñ¥ Ïù∏ÏßÄ (WR / WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0bbdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1,14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1,4)]\n",
    "\n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "\n",
    "    df[\"wr_bin\"] = pd.cut(\n",
    "        df[\"wr_sum\"], bins=[-1,4,9,13], labels=[0,1,2]\n",
    "    ).astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6db93",
   "metadata": {},
   "source": [
    "##### Ï°∞Ìï© Î≥ÄÏàò (Interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86b21a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education_ord\"]\n",
    "    df[\"adult_high_edu\"] = (\n",
    "        (df[\"adult_flag\"]==1) & (df[\"education_ord\"]>=3)\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"edu_cred\"] = df[\"education_ord\"] * df[\"word_credibility\"]\n",
    "    df[\"att_strength\"] = df[\"att_gap\"] * df[\"certainty\"]\n",
    "    df[\"conscientious_att\"] = df[\"conscientiousness\"] * df[\"att_gap\"]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Engineering Ìïú Î≤àÏóê Ï†ÅÏö©\n",
    "\n",
    "def build_features(df):\n",
    "    df = add_demo_features(df)       \n",
    "    df = add_qa_features(df)\n",
    "    df = add_qe_features(df, qe_cols, P10, P90)\n",
    "    df = add_tp_features(df)\n",
    "    df = add_word_features(df)\n",
    "    df = add_interaction_features(df)  \n",
    "    return df\n",
    "\n",
    "train_fe = build_features(train)\n",
    "test_fe  = build_features(test)\n",
    "\n",
    "# word_credibility ÍπåÎ®πÏñ¥ÏÑú Ï∂îÍ∞Ä,,\n",
    "q1, q2 = train_fe[\"word_credibility\"].quantile([1/3, 2/3]).values\n",
    "\n",
    "train_fe[\"cred_bin\"] = np.where(\n",
    "    train_fe[\"word_credibility\"] <= q1, 0,\n",
    "    np.where(train_fe[\"word_credibility\"] <= q2, 1, 2)\n",
    ")\n",
    "\n",
    "test_fe[\"cred_bin\"] = np.where(\n",
    "    test_fe[\"word_credibility\"] <= q1, 0,\n",
    "    np.where(test_fe[\"word_credibility\"] <= q2, 1, 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9290c",
   "metadata": {},
   "source": [
    "### 2. Ïó∞ÏÜçÌòï Î≥ÄÏàò Îã®Î≥ÄÎüâ Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b809f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Ïó∞ÏÜçÌòï ÌîºÏ≤òÎßå ÏßÄÏ†ï\n",
    "cont_features = [\n",
    "    # Q_A\n",
    "    \"neg_att\",\"pos_att\",\"att_gap\",\"certainty\",\"mid_ratio\",\"consistency\",\n",
    "    \n",
    "    # Q_E\n",
    "    \"time_mean\",\"time_median\",\"time_std\",\"fast_ratio\",\"slow_ratio\",\"outlier_ratio\",\n",
    "    \n",
    "    # TP\n",
    "    \"extraversion\",\"agreeableness\",\"conscientiousness\",\n",
    "    \"neuroticism\",\"openness\",\n",
    "    \n",
    "    # Word\n",
    "    \"wr_sum\",\"wf_sum\",\"word_credibility\",\n",
    "    \n",
    "    # Demo (Ïó∞ÏÜç/ÏàúÏÑúÌòï Ï∑®Í∏â)\n",
    "    \"age_ord\",\"education_ord\",\"urban_ord\",\"familysize_clip\",\n",
    "    \n",
    "    # Interaction\n",
    "    \"age_edu\",\"edu_cred\",\"att_strength\",\"conscientious_att\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c8da5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>spearman_corr</th>\n",
       "      <th>p_value</th>\n",
       "      <th>mean_vote_yes</th>\n",
       "      <th>mean_vote_no</th>\n",
       "      <th>mean_diff(no-yes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>age_edu</td>\n",
       "      <td>-0.406469</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.594548</td>\n",
       "      <td>5.050484</td>\n",
       "      <td>-3.544063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>age_ord</td>\n",
       "      <td>-0.379336</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.883339</td>\n",
       "      <td>1.963440</td>\n",
       "      <td>-0.919899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>education_ord</td>\n",
       "      <td>-0.338819</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.910804</td>\n",
       "      <td>2.295792</td>\n",
       "      <td>-0.615011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>edu_cred</td>\n",
       "      <td>-0.332490</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>27.207487</td>\n",
       "      <td>20.147957</td>\n",
       "      <td>-7.059530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wr_sum</td>\n",
       "      <td>-0.158898</td>\n",
       "      <td>3.464809e-255</td>\n",
       "      <td>9.646312</td>\n",
       "      <td>8.969917</td>\n",
       "      <td>-0.676395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>word_credibility</td>\n",
       "      <td>-0.154508</td>\n",
       "      <td>3.142411e-241</td>\n",
       "      <td>9.263691</td>\n",
       "      <td>8.625713</td>\n",
       "      <td>-0.637978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>att_gap</td>\n",
       "      <td>-0.132070</td>\n",
       "      <td>3.030199e-176</td>\n",
       "      <td>0.223935</td>\n",
       "      <td>-0.288892</td>\n",
       "      <td>-0.512827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>att_strength</td>\n",
       "      <td>-0.128953</td>\n",
       "      <td>4.714876e-168</td>\n",
       "      <td>0.201985</td>\n",
       "      <td>-0.537203</td>\n",
       "      <td>-0.739188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_att</td>\n",
       "      <td>-0.128612</td>\n",
       "      <td>3.625164e-167</td>\n",
       "      <td>3.489750</td>\n",
       "      <td>3.192485</td>\n",
       "      <td>-0.297265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg_att</td>\n",
       "      <td>0.106380</td>\n",
       "      <td>1.049847e-114</td>\n",
       "      <td>3.265815</td>\n",
       "      <td>3.481377</td>\n",
       "      <td>0.215562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fast_ratio</td>\n",
       "      <td>0.103321</td>\n",
       "      <td>2.795359e-108</td>\n",
       "      <td>0.087213</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>0.023230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>conscientiousness</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>4.726694e-90</td>\n",
       "      <td>-1.637868</td>\n",
       "      <td>-1.202619</td>\n",
       "      <td>0.435249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>agreeableness</td>\n",
       "      <td>0.078492</td>\n",
       "      <td>3.767838e-63</td>\n",
       "      <td>-0.588087</td>\n",
       "      <td>-0.221725</td>\n",
       "      <td>0.366363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neuroticism</td>\n",
       "      <td>-0.071582</td>\n",
       "      <td>8.452335e-53</td>\n",
       "      <td>0.824791</td>\n",
       "      <td>0.469666</td>\n",
       "      <td>-0.355125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_mean</td>\n",
       "      <td>-0.071136</td>\n",
       "      <td>3.645270e-52</td>\n",
       "      <td>6.964254</td>\n",
       "      <td>6.914349</td>\n",
       "      <td>-0.049905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  spearman_corr        p_value  mean_vote_yes  \\\n",
       "24            age_edu      -0.406469   0.000000e+00       8.594548   \n",
       "20            age_ord      -0.379336   0.000000e+00       2.883339   \n",
       "21      education_ord      -0.338819   0.000000e+00       2.910804   \n",
       "25           edu_cred      -0.332490   0.000000e+00      27.207487   \n",
       "17             wr_sum      -0.158898  3.464809e-255       9.646312   \n",
       "19   word_credibility      -0.154508  3.142411e-241       9.263691   \n",
       "2             att_gap      -0.132070  3.030199e-176       0.223935   \n",
       "26       att_strength      -0.128953  4.714876e-168       0.201985   \n",
       "1             pos_att      -0.128612  3.625164e-167       3.489750   \n",
       "0             neg_att       0.106380  1.049847e-114       3.265815   \n",
       "9          fast_ratio       0.103321  2.795359e-108       0.087213   \n",
       "14  conscientiousness       0.094094   4.726694e-90      -1.637868   \n",
       "13      agreeableness       0.078492   3.767838e-63      -0.588087   \n",
       "15        neuroticism      -0.071582   8.452335e-53       0.824791   \n",
       "6           time_mean      -0.071136   3.645270e-52       6.964254   \n",
       "\n",
       "    mean_vote_no  mean_diff(no-yes)  \n",
       "24      5.050484          -3.544063  \n",
       "20      1.963440          -0.919899  \n",
       "21      2.295792          -0.615011  \n",
       "25     20.147957          -7.059530  \n",
       "17      8.969917          -0.676395  \n",
       "19      8.625713          -0.637978  \n",
       "2      -0.288892          -0.512827  \n",
       "26     -0.537203          -0.739188  \n",
       "1       3.192485          -0.297265  \n",
       "0       3.481377           0.215562  \n",
       "9       0.110443           0.023230  \n",
       "14     -1.202619           0.435249  \n",
       "13     -0.221725           0.366363  \n",
       "15      0.469666          -0.355125  \n",
       "6       6.914349          -0.049905  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spearman & mean diff Íµ¨ÌïòÍ∏∞\n",
    "rows = []\n",
    "\n",
    "for col in cont_features:\n",
    "    x = train_fe[col]\n",
    "    y = train_fe[\"voted_bin\"]\n",
    "\n",
    "    # Spearman (ÏàúÏÑú/ÎπÑÏÑ†Ìòï ÎåÄÏùë)\n",
    "    corr, pval = spearmanr(x, y, nan_policy=\"omit\")\n",
    "\n",
    "    # Í∑∏Î£πÎ≥Ñ ÌèâÍ∑† (Ìï¥ÏÑùÏö©)\n",
    "    mean_0 = x[y == 0].mean()  # Ìà¨Ìëú Ìï®\n",
    "    mean_1 = x[y == 1].mean()  # Ìà¨Ìëú Ïïà Ìï®\n",
    "    diff = mean_1 - mean_0\n",
    "\n",
    "    rows.append({\n",
    "        \"feature\": col,\n",
    "        \"spearman_corr\": corr,\n",
    "        \"p_value\": pval,\n",
    "        \"mean_vote_yes\": mean_0,\n",
    "        \"mean_vote_no\": mean_1,\n",
    "        \"mean_diff(no-yes)\": diff\n",
    "    })\n",
    "\n",
    "univar_cont = pd.DataFrame(rows).sort_values(\n",
    "    by=\"spearman_corr\", key=lambda x: x.abs(), ascending=False\n",
    ")\n",
    "\n",
    "univar_cont.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06306903",
   "metadata": {},
   "source": [
    "üî•ÏµúÏÉÅÏúÑ (Î¨¥Ï°∞Í±¥ Ïú†ÏßÄ)\n",
    "\n",
    "age_edu\n",
    "\n",
    "age_ord\n",
    "\n",
    "education_ord\n",
    "\n",
    "edu_cred\n",
    "\n",
    "‚úÖ Í∞ïÌïú 2Íµ∞\n",
    "\n",
    "wr_sum\n",
    "\n",
    "word_credibility\n",
    "\n",
    "att_gap\n",
    "\n",
    "att_strength\n",
    "\n",
    "pos_att\n",
    "\n",
    "üü° Î≥¥Ï°∞\n",
    "\n",
    "neg_att\n",
    "\n",
    "fast_ratio\n",
    "\n",
    "TP ÏÑ±Í≤© Î≥ÄÏàòÎì§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06347b8",
   "metadata": {},
   "source": [
    "### 2. Ïù¥ÏßÑÌòï Î≥ÄÏàò Îã®Î≥ÄÎüâ Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62ddce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>voted_no_rate_0</th>\n",
       "      <th>voted_no_rate_1</th>\n",
       "      <th>diff(1-0)</th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult_flag</td>\n",
       "      <td>0.837214</td>\n",
       "      <td>0.415014</td>\n",
       "      <td>-0.422200</td>\n",
       "      <td>14215</td>\n",
       "      <td>31317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult_high_edu</td>\n",
       "      <td>0.693837</td>\n",
       "      <td>0.386684</td>\n",
       "      <td>-0.307153</td>\n",
       "      <td>23739</td>\n",
       "      <td>21793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>familysize_outlier</td>\n",
       "      <td>0.546925</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.102481</td>\n",
       "      <td>45487</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cred_bin</td>\n",
       "      <td>0.631933</td>\n",
       "      <td>0.535516</td>\n",
       "      <td>-0.096417</td>\n",
       "      <td>15739</td>\n",
       "      <td>20216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engnat_bin</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>0.537397</td>\n",
       "      <td>-0.033997</td>\n",
       "      <td>12431</td>\n",
       "      <td>33024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender_bin</td>\n",
       "      <td>0.553206</td>\n",
       "      <td>0.539573</td>\n",
       "      <td>-0.013633</td>\n",
       "      <td>24217</td>\n",
       "      <td>21315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  voted_no_rate_0  voted_no_rate_1  diff(1-0)    n_0  \\\n",
       "0          adult_flag         0.837214         0.415014  -0.422200  14215   \n",
       "1      adult_high_edu         0.693837         0.386684  -0.307153  23739   \n",
       "4  familysize_outlier         0.546925         0.444444  -0.102481  45487   \n",
       "5            cred_bin         0.631933         0.535516  -0.096417  15739   \n",
       "3          engnat_bin         0.571394         0.537397  -0.033997  12431   \n",
       "2          gender_bin         0.553206         0.539573  -0.013633  24217   \n",
       "\n",
       "     n_1  \n",
       "0  31317  \n",
       "1  21793  \n",
       "4     45  \n",
       "5  20216  \n",
       "3  33024  \n",
       "2  21315  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_features = [\n",
    "    \"adult_flag\",\n",
    "    \"adult_high_edu\",\n",
    "    \"gender_bin\",\n",
    "    \"engnat_bin\",\n",
    "    \"familysize_outlier\",\n",
    "    \"cred_bin\"  # 0/1\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for col in bin_features:\n",
    "    grp = train_fe.groupby(col)[\"voted_bin\"].agg(\n",
    "        voted_no_rate=\"mean\",\n",
    "        n=\"size\"\n",
    "    )\n",
    "    \n",
    "    # 0 vs 1 Ï∞®Ïù¥ (1 - 0)\n",
    "    rate0 = grp.loc[0, \"voted_no_rate\"] if 0 in grp.index else np.nan\n",
    "    rate1 = grp.loc[1, \"voted_no_rate\"] if 1 in grp.index else np.nan\n",
    "    diff = rate1 - rate0\n",
    "    \n",
    "    rows.append({\n",
    "        \"feature\": col,\n",
    "        \"voted_no_rate_0\": rate0,\n",
    "        \"voted_no_rate_1\": rate1,\n",
    "        \"diff(1-0)\": diff,\n",
    "        \"n_0\": grp.loc[0, \"n\"] if 0 in grp.index else np.nan,\n",
    "        \"n_1\": grp.loc[1, \"n\"] if 1 in grp.index else np.nan,\n",
    "    })\n",
    "\n",
    "univar_bin = pd.DataFrame(rows).sort_values(\n",
    "    by=\"diff(1-0)\", key=lambda x: x.abs(), ascending=False\n",
    ")\n",
    "\n",
    "univar_bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ebce9",
   "metadata": {},
   "source": [
    "‚úÖ Í∞ïÎ†• Ïú†ÏßÄ (ÌôïÏ†ï)\n",
    "\n",
    "adult_flag\n",
    "\n",
    "adult_high_edu\n",
    "\n",
    "üü° Î≥¥Î•ò (importance Î≥¥Í≥† Í≤∞Ï†ï)\n",
    "\n",
    "familysize_outlier\n",
    "\n",
    "cred_bin\n",
    "\n",
    "‚ùå Ï†úÍ±∞ ÌõÑÎ≥¥\n",
    "\n",
    "gender_bin\n",
    "\n",
    "engnat_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93976c54",
   "metadata": {},
   "source": [
    "### 3. Ïó∞ÏÜçÌòï + Ïù¥ÏßÑÌòï Î≥ÄÏàò feature importance Íµ¨ÌïòÍ∏∞\n",
    "- Autogluon Ïù¥Ïö©\n",
    "\n",
    "Ïù¥ÏßÑÌòï\n",
    "\n",
    "adult_flag adult_high_edu \n",
    "\n",
    "familysize_outlier cred_bin \n",
    "\n",
    "Ïó∞ÏÜçÌòï\n",
    "\n",
    "age_edu age_ord education_ord edu_cred \n",
    "\n",
    "wr_sum word_credibility att_gap att_strength pos_att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe745b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260129_042724\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       2.83 GB / 16.00 GB (17.7%)\n",
      "Disk Space Avail:   226.13 GB / 460.43 GB (49.1%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Using hyperparameters preset: hyperparameters='light'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_042724/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    40472\n",
      "Train Data Columns: 13\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2824.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.01 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 7 | ['age_edu', 'age_ord', 'education_ord', 'edu_cred', 'att_gap', ...]\n",
      "\t\t('int', [])   : 6 | ['adult_flag', 'adult_high_edu', 'familysize_outlier', 'cred_bin', 'wr_sum', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 7 | ['age_edu', 'age_ord', 'education_ord', 'edu_cred', 'att_gap', ...]\n",
      "\t\t('int', [])       : 3 | ['cred_bin', 'wr_sum', 'word_credibility']\n",
      "\t\t('int', ['bool']) : 3 | ['adult_flag', 'adult_high_edu', 'familysize_outlier']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.20 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.76s of the 899.87s of remaining time.\n",
      "2026-01-29 13:27:27,898\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.47%)\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 584.86s of the 884.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.12%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t2.21s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 581.14s of the 881.25s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/2.9 GB\n",
      "\t0.7228\t = Validation score   (roc_auc)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 576.52s of the 876.63s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.1 GB\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 574.26s of the 874.37s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.37% memory usage per fold, 53.49%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.37%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t7.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 564.91s of the 865.01s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.0 GB\n",
      "\t0.7272\t = Validation score   (roc_auc)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 562.94s of the 863.05s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/2.9 GB\n",
      "\t0.7278\t = Validation score   (roc_auc)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 561.08s of the 861.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.29%)\n",
      "\t0.7411\t = Validation score   (roc_auc)\n",
      "\t24.17s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 534.21s of the 834.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.47%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 530.86s of the 830.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t0.7397\t = Validation score   (roc_auc)\n",
      "\t31.04s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 498.26s of the 798.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.40%)\n",
      "\t0.7339\t = Validation score   (roc_auc)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 794.59s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.3 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.55, 'NeuralNetTorch_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.2}\n",
      "\t0.7415\t = Validation score   (roc_auc)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 793.31s of the 793.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.24%)\n",
      "\t0.7719\t = Validation score   (roc_auc)\n",
      "\t21.82s\t = Training   runtime\n",
      "\t22.7s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 766.46s of the 766.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\t0.7454\t = Validation score   (roc_auc)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 762.60s of the 762.59s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.5 GB\n",
      "\t0.7538\t = Validation score   (roc_auc)\n",
      "\t4.78s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 756.75s of the 756.74s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.0 GB\n",
      "\t0.7522\t = Validation score   (roc_auc)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 750.61s of the 750.60s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.41% memory usage per fold, 41.63%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.41%)\n",
      "\t0.7456\t = Validation score   (roc_auc)\n",
      "\t24.93s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 723.86s of the 723.86s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.3 GB\n",
      "\t0.7532\t = Validation score   (roc_auc)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 722.22s of the 722.22s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.2 GB\n",
      "\t0.7519\t = Validation score   (roc_auc)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 720.63s of the 720.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.37%)\n",
      "\t0.7405\t = Validation score   (roc_auc)\n",
      "\t21.05s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 696.87s of the 696.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.87%)\n",
      "\t0.7443\t = Validation score   (roc_auc)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 692.55s of the 692.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.78%)\n",
      "\t0.7492\t = Validation score   (roc_auc)\n",
      "\t253.58s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 437.66s of the 437.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.61%)\n",
      "\t0.75\t = Validation score   (roc_auc)\n",
      "\t4.0s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 431.04s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.4 GB\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.615, 'NeuralNetTorch_BAG_L2': 0.308, 'ExtraTreesGini_BAG_L2': 0.077}\n",
      "\t0.7773\t = Validation score   (roc_auc)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 471.47s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 203.1 rows/s (5059 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.4 GB\n",
      "\t1.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.1 GB\n",
      "\t0.7s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.5 GB\n",
      "\tStopping at the best epoch learned earlier - 20.\n",
      "\t16.12s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.5 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t11.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "\t3.15s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.55, 'NeuralNetTorch_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.2}\n",
      "\t1.26s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "\t31.85s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\t1.6s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t4.78s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t2.65s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.7 GB\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t17.14s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t88.52s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.9 GB\n",
      "\t7.92s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.615, 'NeuralNetTorch_BAG_L2': 0.308, 'ExtraTreesGini_BAG_L2': 0.077}\n",
      "\t2.49s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 185.02s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_042724/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMXT_BAG_L1_FULL       0.745925   0.739485     roc_auc        0.007851            NaN    1.100239                 0.007851                     NaN           1.100239            1       True          1\n",
      "1     ExtraTreesGini_BAG_L2_FULL       0.745744   0.753219     roc_auc        0.912699            NaN   40.154261                 0.108323                0.773477           0.732955            2       True         18\n",
      "2       WeightedEnsemble_L2_FULL       0.745656   0.741452     roc_auc        0.063242            NaN   29.832222                 0.001096                     NaN           1.264462            2       True         12\n",
      "3     ExtraTreesEntr_BAG_L2_FULL       0.745177   0.751920     roc_auc        0.909340            NaN   40.104446                 0.104964                0.798606           0.683140            2       True         19\n",
      "4           LightGBM_BAG_L1_FULL       0.745029   0.738105     roc_auc        0.006948            NaN    0.697313                 0.006948                     NaN           0.697313            1       True          2\n",
      "5           CatBoost_BAG_L1_FULL       0.744826   0.739399     roc_auc        0.009111            NaN    0.400031                 0.009111                     NaN           0.400031            1       True          5\n",
      "6    NeuralNetFastAI_BAG_L2_FULL       0.744763   0.740452     roc_auc        0.839570            NaN   56.560547                 0.035194                     NaN          17.139241            2       True         20\n",
      "7    NeuralNetFastAI_BAG_L1_FULL       0.744548   0.741058     roc_auc        0.038659            NaN   16.121358                 0.038659                     NaN          16.121358            1       True          8\n",
      "8            XGBoost_BAG_L1_FULL       0.744255   0.738060     roc_auc        0.007136            NaN    0.155633                 0.007136                     NaN           0.155633            1       True          9\n",
      "9   RandomForestGini_BAG_L2_FULL       0.743726   0.753829     roc_auc        0.919905            NaN   44.204991                 0.115530                0.900426           4.783685            2       True         15\n",
      "10    NeuralNetTorch_BAG_L1_FULL       0.743670   0.739680     roc_auc        0.015636            NaN   11.346163                 0.015636                     NaN          11.346163            1       True         10\n",
      "11  RandomForestEntr_BAG_L2_FULL       0.743036   0.752202     roc_auc        0.904796            NaN   44.618603                 0.100420                0.796526           5.197297            2       True         16\n",
      "12          CatBoost_BAG_L2_FULL       0.741268   0.745625     roc_auc        0.809587            NaN   42.067557                 0.005212                     NaN           2.646251            2       True         17\n",
      "13     LightGBMLarge_BAG_L1_FULL       0.741212   0.733888     roc_auc        0.012505            NaN    3.145948                 0.012505                     NaN           3.145948            1       True         11\n",
      "14          LightGBM_BAG_L2_FULL       0.740790   0.745428     roc_auc        0.817681            NaN   41.024972                 0.013306                     NaN           1.603666            2       True         14\n",
      "15           XGBoost_BAG_L2_FULL       0.737769   0.744285     roc_auc        0.814588            NaN   39.743926                 0.010212                     NaN           0.322620            2       True         21\n",
      "16     LightGBMLarge_BAG_L2_FULL       0.735021   0.749994     roc_auc        0.826182            NaN   47.344925                 0.021807                     NaN           7.923619            2       True         23\n",
      "17    ExtraTreesGini_BAG_L1_FULL       0.734439   0.727207     roc_auc        0.182955       0.834231    0.903673                 0.182955                0.834231           0.903673            1       True          6\n",
      "18    ExtraTreesEntr_BAG_L1_FULL       0.733480   0.727849     roc_auc        0.184122       0.899927    0.781560                 0.184122                0.899927           0.781560            1       True          7\n",
      "19  RandomForestEntr_BAG_L1_FULL       0.731797   0.723709     roc_auc        0.147509       0.861813    1.195767                 0.147509                0.861813           1.195767            1       True          4\n",
      "20  RandomForestGini_BAG_L1_FULL       0.729272   0.722808     roc_auc        0.191944       0.819285    3.573621                 0.191944                0.819285           3.573621            1       True          3\n",
      "21      WeightedEnsemble_L3_FULL       0.724839   0.777349     roc_auc        1.274790            NaN  163.008235                 0.001141                     NaN           2.487997            3       True         24\n",
      "22        LightGBMXT_BAG_L2_FULL       0.722957   0.771910     roc_auc        1.146529            NaN   71.271792                 0.342154                     NaN          31.850486            2       True         13\n",
      "23    NeuralNetTorch_BAG_L2_FULL       0.706547   0.749177     roc_auc        0.823172            NaN  127.936798                 0.018797                     NaN          88.515492            2       True         22\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t659s\t = DyStack   runtime |\t2941s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2941s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_042724\"\n",
      "Train Data Rows:    45532\n",
      "Train Data Columns: 13\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4131.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.52 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 7 | ['age_edu', 'age_ord', 'education_ord', 'edu_cred', 'att_gap', ...]\n",
      "\t\t('int', [])   : 6 | ['adult_flag', 'adult_high_edu', 'familysize_outlier', 'cred_bin', 'wr_sum', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 7 | ['age_edu', 'age_ord', 'education_ord', 'edu_cred', 'att_gap', ...]\n",
      "\t\t('int', [])       : 3 | ['cred_bin', 'wr_sum', 'word_credibility']\n",
      "\t\t('int', ['bool']) : 3 | ['adult_flag', 'adult_high_edu', 'familysize_outlier']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.60 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2941.07s of the 2941.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.99%)\n",
      "\t0.7404\t = Validation score   (roc_auc)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2937.90s of the 2937.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
      "\t0.7385\t = Validation score   (roc_auc)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2935.16s of the 2935.16s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.6 GB\n",
      "\t0.7244\t = Validation score   (roc_auc)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2933.07s of the 2933.06s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.0 GB\n",
      "\t0.7257\t = Validation score   (roc_auc)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2931.05s of the 2931.05s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.52% memory usage per fold, 42.08%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.52%)\n",
      "\t0.7403\t = Validation score   (roc_auc)\n",
      "\t5.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2924.88s of the 2924.88s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.7 GB\n",
      "\t0.7291\t = Validation score   (roc_auc)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2923.15s of the 2923.15s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.8 GB\n",
      "\t0.729\t = Validation score   (roc_auc)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2921.48s of the 2921.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.04%)\n",
      "\t0.7408\t = Validation score   (roc_auc)\n",
      "\t22.34s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2896.59s of the 2896.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.25%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2893.62s of the 2893.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t25.79s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2866.50s of the 2866.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.25%)\n",
      "\t0.7356\t = Validation score   (roc_auc)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 2863.42s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.4 GB\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.4, 'NeuralNetFastAI_BAG_L1': 0.333, 'NeuralNetTorch_BAG_L1': 0.267}\n",
      "\t0.7415\t = Validation score   (roc_auc)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 79.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7519.3 rows/s (5692 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\t0.95s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\t0.75s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.31s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "\tStopping at the best epoch learned earlier - 23.\n",
      "\t20.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t8.53s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "\t3.04s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.4, 'NeuralNetFastAI_BAG_L1': 0.333, 'NeuralNetTorch_BAG_L1': 0.267}\n",
      "\t1.49s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 34.67s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_042724\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>0.724399</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.297063</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>1.066522</td>\n",
       "      <td>0.297063</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>1.066522</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.301837</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>1.066522</td>\n",
       "      <td>0.301837</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>1.066522</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.892128</td>\n",
       "      <td>0.725654</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.283214</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.001825</td>\n",
       "      <td>0.283214</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.001825</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>0.892128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.309712</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.001825</td>\n",
       "      <td>0.309712</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.001825</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>0.729071</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.297885</td>\n",
       "      <td>0.849369</td>\n",
       "      <td>0.715790</td>\n",
       "      <td>0.297885</td>\n",
       "      <td>0.849369</td>\n",
       "      <td>0.715790</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.849369</td>\n",
       "      <td>0.715790</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.849369</td>\n",
       "      <td>0.715790</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.864973</td>\n",
       "      <td>0.729039</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.325135</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.662934</td>\n",
       "      <td>0.325135</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.662934</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
       "      <td>0.864973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.332374</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.662934</td>\n",
       "      <td>0.332374</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.662934</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>0.797957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.040264</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.040264</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.758754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.028101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753925</td>\n",
       "      <td>0.028101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753925</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>0.756520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>0.750747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947400</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947400</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.748219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.387953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.161907</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.489593</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>0.747528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309787</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309787</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.109384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.532290</td>\n",
       "      <td>0.109384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.532290</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  score_val eval_metric  \\\n",
       "0        RandomForestGini_BAG_L1    0.900433   0.724399     roc_auc   \n",
       "1   RandomForestGini_BAG_L1_FULL    0.900433        NaN     roc_auc   \n",
       "2        RandomForestEntr_BAG_L1    0.892128   0.725654     roc_auc   \n",
       "3   RandomForestEntr_BAG_L1_FULL    0.892128        NaN     roc_auc   \n",
       "4          ExtraTreesGini_BAG_L1    0.866419   0.729071     roc_auc   \n",
       "5     ExtraTreesGini_BAG_L1_FULL    0.866419        NaN     roc_auc   \n",
       "6          ExtraTreesEntr_BAG_L1    0.864973   0.729039     roc_auc   \n",
       "7     ExtraTreesEntr_BAG_L1_FULL    0.864973        NaN     roc_auc   \n",
       "8      LightGBMLarge_BAG_L1_FULL    0.797957        NaN     roc_auc   \n",
       "9           LightGBM_BAG_L1_FULL    0.758754        NaN     roc_auc   \n",
       "10           XGBoost_BAG_L1_FULL    0.756520        NaN     roc_auc   \n",
       "11        LightGBMXT_BAG_L1_FULL    0.750747        NaN     roc_auc   \n",
       "12      WeightedEnsemble_L2_FULL    0.748219        NaN     roc_auc   \n",
       "13          CatBoost_BAG_L1_FULL    0.747528        NaN     roc_auc   \n",
       "14    NeuralNetTorch_BAG_L1_FULL    0.745301        NaN     roc_auc   \n",
       "\n",
       "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.297063       0.850035   1.066522                 0.297063   \n",
       "1         0.301837       0.850035   1.066522                 0.301837   \n",
       "2         0.283214       0.859766   1.001825                 0.283214   \n",
       "3         0.309712       0.859766   1.001825                 0.309712   \n",
       "4         0.297885       0.849369   0.715790                 0.297885   \n",
       "5         0.330700       0.849369   0.715790                 0.330700   \n",
       "6         0.325135       0.844699   0.662934                 0.325135   \n",
       "7         0.332374       0.844699   0.662934                 0.332374   \n",
       "8         0.058741            NaN   3.040264                 0.058741   \n",
       "9         0.028101            NaN   0.753925                 0.028101   \n",
       "10        0.026657            NaN   0.159055                 0.026657   \n",
       "11        0.046001            NaN   0.947400                 0.046001   \n",
       "12        0.387953            NaN  31.161907                 0.002540   \n",
       "13        0.007119            NaN   0.309787                 0.007119   \n",
       "14        0.109384            NaN   8.532290                 0.109384   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.850035           1.066522            1       True   \n",
       "1                 0.850035           1.066522            1       True   \n",
       "2                 0.859766           1.001825            1       True   \n",
       "3                 0.859766           1.001825            1       True   \n",
       "4                 0.849369           0.715790            1       True   \n",
       "5                 0.849369           0.715790            1       True   \n",
       "6                 0.844699           0.662934            1       True   \n",
       "7                 0.844699           0.662934            1       True   \n",
       "8                      NaN           3.040264            1       True   \n",
       "9                      NaN           0.753925            1       True   \n",
       "10                     NaN           0.159055            1       True   \n",
       "11                     NaN           0.947400            1       True   \n",
       "12                     NaN           1.489593            2       True   \n",
       "13                     NaN           0.309787            1       True   \n",
       "14                     NaN           8.532290            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           3  \n",
       "1          15  \n",
       "2           4  \n",
       "3          16  \n",
       "4           6  \n",
       "5          18  \n",
       "6           7  \n",
       "7          19  \n",
       "8          23  \n",
       "9          14  \n",
       "10         21  \n",
       "11         13  \n",
       "12         24  \n",
       "13         17  \n",
       "14         22  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "features = [\n",
    "    # Ïù¥ÏßÑÌòï\n",
    "    \"adult_flag\", \"adult_high_edu\", \"familysize_outlier\", \"cred_bin\",\n",
    "    # Ïó∞ÏÜçÌòï\n",
    "    \"age_edu\", \"age_ord\", \"education_ord\", \"edu_cred\",\n",
    "    \"wr_sum\", \"word_credibility\",\n",
    "    \"att_gap\", \"att_strength\", \"pos_att\"\n",
    "]\n",
    "\n",
    "train_ag = train_fe[features + [\"voted_bin\"]].copy()\n",
    "\n",
    "\n",
    "# ÌïôÏäµ\n",
    "predictor = TabularPredictor(\n",
    "    label=\"voted_bin\",\n",
    "    problem_type=\"binary\",\n",
    "    eval_metric=\"roc_auc\"\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    presets=\"good_quality\"\n",
    ")\n",
    "\n",
    "# Î¶¨ÎçîÎ≥¥Îìú ÌôïÏù∏\n",
    "leaderboard = predictor.leaderboard(train_ag, silent=True)\n",
    "leaderboard.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51decf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t5.07s\t= Expected runtime (1.01s per shuffle set)\n",
      "\t3.51s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult_flag</th>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.018442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wr_sum</th>\n",
       "      <td>0.026156</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>0.017764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_ord</th>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.011962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_ord</th>\n",
       "      <td>0.019185</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.012331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_edu</th>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_credibility</th>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_gap</th>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>-0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu_cred</th>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_strength</th>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cred_bin</th>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adult_high_edu</th>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.063183</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>-0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_att</th>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>familysize_outlier</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.815650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.000426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    importance    stddev   p_value  n  p99_high   p99_low\n",
       "adult_flag            0.028832  0.005046  0.000108  5  0.039223  0.018442\n",
       "wr_sum                0.026156  0.004076  0.000069  5  0.034549  0.017764\n",
       "age_ord               0.019679  0.003748  0.000151  5  0.027397  0.011962\n",
       "education_ord         0.019185  0.003328  0.000105  5  0.026038  0.012331\n",
       "age_edu               0.015421  0.006380  0.002837  5  0.028558  0.002285\n",
       "word_credibility      0.008819  0.001857  0.000222  5  0.012642  0.004996\n",
       "att_gap               0.002349  0.001352  0.008878  5  0.005131 -0.000434\n",
       "edu_cred              0.002185  0.000611  0.000663  5  0.003444  0.000927\n",
       "att_strength          0.001678  0.000598  0.001650  5  0.002909  0.000446\n",
       "cred_bin              0.001616  0.000749  0.004247  5  0.003159  0.000074\n",
       "adult_high_edu        0.001233  0.001432  0.063183  5  0.004181 -0.001714\n",
       "pos_att               0.000961  0.000377  0.002337  5  0.001737  0.000185\n",
       "familysize_outlier   -0.000077  0.000170  0.815650  5  0.000273 -0.000426"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance ÎΩëÍ∏∞ (TopÎßå)\n",
    "fi = predictor.feature_importance(train_ag)\n",
    "fi.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47c1ea",
   "metadata": {},
   "source": [
    "### 3. Î≤îÏ£ºÌòï Î≥ÄÏàò Îã®Î≥ÄÎüâ Î∂ÑÏÑù Î∞è Î¶¨ÏΩîÎî© & feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "389b3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== engnat ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engnat</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>12431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537397</td>\n",
       "      <td>33024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engnat  voted_no_rate      n\n",
       "0       0       0.623377     77\n",
       "2       2       0.571394  12431\n",
       "1       1       0.537397  33024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== gender ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0.553206</td>\n",
       "      <td>24217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0.539573</td>\n",
       "      <td>21315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  voted_no_rate      n\n",
       "1    Male       0.553206  24217\n",
       "0  Female       0.539573  21315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== hand ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.633540</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.592844</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.545317</td>\n",
       "      <td>39058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.540494</td>\n",
       "      <td>4692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hand  voted_no_rate      n\n",
       "0     0       0.633540    161\n",
       "3     3       0.592844   1621\n",
       "1     1       0.545317  39058\n",
       "2     2       0.540494   4692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== married ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>married</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629572</td>\n",
       "      <td>31550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.422454</td>\n",
       "      <td>3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.333433</td>\n",
       "      <td>10059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   married  voted_no_rate      n\n",
       "0        0       0.677419     93\n",
       "1        1       0.629572  31550\n",
       "3        3       0.422454   3830\n",
       "2        2       0.333433  10059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== race ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian</td>\n",
       "      <td>0.704565</td>\n",
       "      <td>6834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.622402</td>\n",
       "      <td>4330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black</td>\n",
       "      <td>0.597786</td>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Native American</td>\n",
       "      <td>0.587591</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indigenous Australian</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>White</td>\n",
       "      <td>0.495776</td>\n",
       "      <td>31248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    race  voted_no_rate      n\n",
       "0                   Arab       0.709402    351\n",
       "1                  Asian       0.704565   6834\n",
       "5                  Other       0.622402   4330\n",
       "2                  Black       0.597786   2168\n",
       "4        Native American       0.587591    548\n",
       "3  Indigenous Australian       0.547170     53\n",
       "6                  White       0.495776  31248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== religion ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Muslim</td>\n",
       "      <td>0.687081</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sikh</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buddhist</td>\n",
       "      <td>0.621176</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christian_Mormon</td>\n",
       "      <td>0.619159</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hindu</td>\n",
       "      <td>0.613016</td>\n",
       "      <td>1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.582809</td>\n",
       "      <td>4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atheist</td>\n",
       "      <td>0.572704</td>\n",
       "      <td>10192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agnostic</td>\n",
       "      <td>0.542602</td>\n",
       "      <td>9624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Christian_Other</td>\n",
       "      <td>0.539615</td>\n",
       "      <td>5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christian_Catholic</td>\n",
       "      <td>0.526512</td>\n",
       "      <td>6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jewish</td>\n",
       "      <td>0.449692</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Christian_Protestant</td>\n",
       "      <td>0.434667</td>\n",
       "      <td>4875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                religion  voted_no_rate      n\n",
       "9                 Muslim       0.687081   1192\n",
       "11                  Sikh       0.641026    117\n",
       "2               Buddhist       0.621176    850\n",
       "4       Christian_Mormon       0.619159    428\n",
       "7                  Hindu       0.613016   1429\n",
       "10                 Other       0.582809   4770\n",
       "1                Atheist       0.572704  10192\n",
       "0               Agnostic       0.542602   9624\n",
       "5        Christian_Other       0.539615   5137\n",
       "3     Christian_Catholic       0.526512   6431\n",
       "8                 Jewish       0.449692    487\n",
       "6   Christian_Protestant       0.434667   4875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== urban ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urban</th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>17767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.541545</td>\n",
       "      <td>18534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.492872</td>\n",
       "      <td>8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490683</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   urban  voted_no_rate      n\n",
       "3      3       0.580402  17767\n",
       "2      2       0.541545  18534\n",
       "1      1       0.492872   8909\n",
       "0      0       0.490683    322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw ÏÉÅÌÉúÎ°ú Îã®Î≥ÄÎüâ Î∂ÑÏÑù\n",
    "raw_cat_cols = [\n",
    "    \"engnat\",     # 1,2,0\n",
    "    \"gender\",     # Male, Female\n",
    "    \"hand\",       # 1,2,3,0\n",
    "    \"married\",    # 1,2,3,0\n",
    "    \"race\",       # string\n",
    "    \"religion\",   # string\n",
    "    \"urban\"       # 1,2,3,0\n",
    "]\n",
    "\n",
    "def cat_univariate_raw(df, col, target=\"voted_bin\"):\n",
    "    return (\n",
    "        df\n",
    "        .groupby(col)[target]\n",
    "        .agg(\n",
    "            voted_no_rate=\"mean\",\n",
    "            n=\"count\"\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(\"voted_no_rate\", ascending=False)\n",
    "    )\n",
    "\n",
    "for col in raw_cat_cols:\n",
    "    print(f\"\\n=== {col} ===\")\n",
    "    display(cat_univariate_raw(train, col))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127a2ac",
   "metadata": {},
   "source": [
    "engnat\n",
    "married\n",
    "race\n",
    "religion\n",
    "urban\n",
    "Ïù¥Ïô∏ hand, gender ÏÇ¨Ïö© X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97f030d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Other_NA</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single</th>\n",
       "      <td>0.629572</td>\n",
       "      <td>31550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Divorced_Widowed</th>\n",
       "      <td>0.422454</td>\n",
       "      <td>3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.333433</td>\n",
       "      <td>10059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  voted_no_rate      n\n",
       "married_cat                           \n",
       "Other_NA               0.677419     93\n",
       "Single                 0.629572  31550\n",
       "Divorced_Widowed       0.422454   3830\n",
       "Married                0.333433  10059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.704565</td>\n",
       "      <td>6834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.623817</td>\n",
       "      <td>5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.597786</td>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.495776</td>\n",
       "      <td>31248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          voted_no_rate      n\n",
       "race_cat                      \n",
       "Asian          0.704565   6834\n",
       "Other          0.623817   5282\n",
       "Black          0.597786   2168\n",
       "White          0.495776  31248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voted_no_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muslim</th>\n",
       "      <td>0.687081</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.594334</td>\n",
       "      <td>7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atheist_Agnostic</th>\n",
       "      <td>0.558084</td>\n",
       "      <td>19816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christian</th>\n",
       "      <td>0.506313</td>\n",
       "      <td>16871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jewish</th>\n",
       "      <td>0.449692</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  voted_no_rate      n\n",
       "religion_cat                          \n",
       "Muslim                 0.687081   1192\n",
       "Other                  0.594334   7166\n",
       "Atheist_Agnostic       0.558084  19816\n",
       "Christian              0.506313  16871\n",
       "Jewish                 0.449692    487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÏÇ¨Ïö©Ìï† Ïª¨Îüº Î¶¨ÏΩîÎî©\n",
    "def recode_married(x):\n",
    "    # original: 0=NA/Other, 1=Single, 2=Married, 3=Divorced/Widowed\n",
    "    if pd.isna(x):\n",
    "        return \"NA\"\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        return \"NA\"\n",
    "    if x == 1:\n",
    "        return \"Single\"\n",
    "    if x == 2:\n",
    "        return \"Married\"\n",
    "    if x == 3:\n",
    "        return \"Divorced_Widowed\"\n",
    "    return \"Other_NA\"   # 0 or anything else\n",
    "\n",
    "\n",
    "def recode_race(x):\n",
    "    # original: strings like White, Asian, Black, Arab, Native American, Indigenous Australian, Other\n",
    "    if pd.isna(x):\n",
    "        return \"NA\"\n",
    "    x = str(x).strip()\n",
    "    if x in [\"White\", \"Asian\", \"Black\"]:\n",
    "        return x\n",
    "    # everything else -> Other (Arab, Native American, Indigenous Australian, Other, etc.)\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def recode_religion(x):\n",
    "    # original: strings like Christian_Catholic, Christian_Protestant, Jewish, Muslim, Atheist, Agnostic, etc.\n",
    "    if pd.isna(x):\n",
    "        return \"NA\"\n",
    "    x = str(x).strip()\n",
    "\n",
    "    # Christian bucket\n",
    "    if x.startswith(\"Christian\"):\n",
    "        return \"Christian\"\n",
    "\n",
    "    # Atheist / Agnostic bucket\n",
    "    if x in [\"Atheist\", \"Agnostic\"]:\n",
    "        return \"Atheist_Agnostic\"\n",
    "\n",
    "    # Keep major religions separately\n",
    "    if x in [\"Jewish\", \"Muslim\"]:\n",
    "        return x\n",
    "\n",
    "    # Everything else -> Other (Buddhist, Hindu, Sikh, Mormon, Other, etc.)\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "# Apply to train/test (raw or fe; both are fine as long as columns exist)\n",
    "for df in [train, test]:\n",
    "    df[\"married_cat\"]  = df[\"married\"].apply(recode_married)\n",
    "    df[\"race_cat\"]     = df[\"race\"].apply(recode_race)\n",
    "    df[\"religion_cat\"] = df[\"religion\"].apply(recode_religion)\n",
    "\n",
    "# quick check (train)\n",
    "display(train.groupby(\"married_cat\")[\"voted_bin\"].agg(voted_no_rate=\"mean\", n=\"count\").sort_values(\"voted_no_rate\", ascending=False))\n",
    "display(train.groupby(\"race_cat\")[\"voted_bin\"].agg(voted_no_rate=\"mean\", n=\"count\").sort_values(\"voted_no_rate\", ascending=False))\n",
    "display(train.groupby(\"religion_cat\")[\"voted_bin\"].agg(voted_no_rate=\"mean\", n=\"count\").sort_values(\"voted_no_rate\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61bcc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÎÇòÎ®∏ÏßÄ \n",
    "df[\"engnat_bin\"] = df[\"engnat\"].replace({1: 1, 2: 0, 0: np.nan})\n",
    "df[\"urban_ord\"] = df[\"urban\"].replace(0, np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "822e580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïó∞ÏÜçÌòï + Ïù¥ÏßÑÌòï + Î≤îÏ£ºÌòï Ïãπ Î™®ÏïÑÏ£ºÍ∏∞\n",
    "def add_cat_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"married_cat\"]  = df[\"married\"].apply(recode_married)\n",
    "    df[\"race_cat\"]     = df[\"race\"].apply(recode_race)\n",
    "    df[\"religion_cat\"] = df[\"religion\"].apply(recode_religion)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_features(df):\n",
    "    df = add_qa_features(df)\n",
    "    df = add_qe_features(df, qe_cols, P10, P90)\n",
    "    df = add_tp_features(df)\n",
    "    df = add_demo_features(df)\n",
    "    df = add_word_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_cat_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ad6ab",
   "metadata": {},
   "source": [
    "### 4. ÏµúÏ¢Ö feature importance Íµ¨ÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "615d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260129_051055\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       3.72 GB / 16.00 GB (23.3%)\n",
      "Disk Space Avail:   222.43 GB / 460.43 GB (48.3%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Using hyperparameters preset: hyperparameters='light'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_051055/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    40472\n",
      "Train Data Columns: 16\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3824.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.51 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 9 | ['age_ord', 'education_ord', 'age_edu', 'att_gap', 'edu_cred', ...]\n",
      "\t\t('int', [])    : 4 | ['wr_sum', 'word_credibility', 'adult_flag', 'adult_high_edu']\n",
      "\t\t('object', []) : 3 | ['married_cat', 'race_cat', 'religion_cat']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['married_cat', 'race_cat', 'religion_cat']\n",
      "\t\t('float', [])     : 9 | ['age_ord', 'education_ord', 'age_edu', 'att_gap', 'edu_cred', ...]\n",
      "\t\t('int', [])       : 2 | ['wr_sum', 'word_credibility']\n",
      "\t\t('int', ['bool']) : 2 | ['adult_flag', 'adult_high_edu']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.59 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.77s of the 899.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.21%)\n",
      "\t0.7641\t = Validation score   (roc_auc)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 596.29s of the 896.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\t0.7628\t = Validation score   (roc_auc)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 592.85s of the 892.95s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.0 GB\n",
      "\t0.7532\t = Validation score   (roc_auc)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 590.35s of the 890.46s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.6 GB\n",
      "\t0.7547\t = Validation score   (roc_auc)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 588.19s of the 888.30s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.43% memory usage per fold, 45.72%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.43%)\n",
      "\t0.7646\t = Validation score   (roc_auc)\n",
      "\t20.68s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 566.08s of the 866.19s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.7 GB\n",
      "\t0.7574\t = Validation score   (roc_auc)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 564.39s of the 864.49s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.5 GB\n",
      "\t0.7582\t = Validation score   (roc_auc)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 562.69s of the 862.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.23%)\n",
      "\t0.763\t = Validation score   (roc_auc)\n",
      "\t23.68s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 535.96s of the 836.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.46%)\n",
      "\t0.7628\t = Validation score   (roc_auc)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 532.67s of the 832.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\t0.7633\t = Validation score   (roc_auc)\n",
      "\t29.72s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 501.56s of the 801.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.18%)\n",
      "\t0.7607\t = Validation score   (roc_auc)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 797.64s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.4, 'NeuralNetTorch_BAG_L1': 0.32, 'NeuralNetFastAI_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.04, 'XGBoost_BAG_L1': 0.04}\n",
      "\t0.7657\t = Validation score   (roc_auc)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 796.36s of the 796.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.15%)\n",
      "\t0.7699\t = Validation score   (roc_auc)\n",
      "\t19.18s\t = Training   runtime\n",
      "\t3.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 772.37s of the 772.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.30%)\n",
      "\t0.7646\t = Validation score   (roc_auc)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 769.24s of the 769.23s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.7 GB\n",
      "\t0.7667\t = Validation score   (roc_auc)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 764.50s of the 764.49s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.3 GB\n",
      "\t0.7666\t = Validation score   (roc_auc)\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 759.16s of the 759.15s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.50% memory usage per fold, 42.02%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.50%)\n",
      "\t0.7658\t = Validation score   (roc_auc)\n",
      "\t17.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 739.95s of the 739.94s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.0 GB\n",
      "\t0.7699\t = Validation score   (roc_auc)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 738.18s of the 738.17s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.0 GB\n",
      "\t0.7693\t = Validation score   (roc_auc)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 736.46s of the 736.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.57%)\n",
      "\t0.7647\t = Validation score   (roc_auc)\n",
      "\t27.21s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 705.79s of the 705.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.50%)\n",
      "\t0.764\t = Validation score   (roc_auc)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 702.13s of the 702.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n",
      "\t0.7643\t = Validation score   (roc_auc)\n",
      "\t30.21s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 670.20s of the 670.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.35%)\n",
      "\t0.7642\t = Validation score   (roc_auc)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 665.39s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.1 GB\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.435, 'ExtraTreesGini_BAG_L2': 0.391, 'ExtraTreesEntr_BAG_L2': 0.13, 'RandomForestGini_BAG_L2': 0.043}\n",
      "\t0.7722\t = Validation score   (roc_auc)\n",
      "\t2.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 236.97s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 775.8 rows/s (5059 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.3 GB\n",
      "\t1.25s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.1 GB\n",
      "\t0.91s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.28s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t3.05s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.4 GB\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t18.1s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t11.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "\t3.47s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.4, 'NeuralNetTorch_BAG_L1': 0.32, 'NeuralNetFastAI_BAG_L1': 0.2, 'LightGBMXT_BAG_L1': 0.04, 'XGBoost_BAG_L1': 0.04}\n",
      "\t1.26s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "\t6.81s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\t0.79s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t1.83s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.8 GB\n",
      "\tStopping at the best epoch learned earlier - 17.\n",
      "\t16.78s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.23s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t7.43s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.1/3.8 GB\n",
      "\t3.92s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.435, 'ExtraTreesGini_BAG_L2': 0.391, 'ExtraTreesEntr_BAG_L2': 0.13, 'RandomForestGini_BAG_L2': 0.043}\n",
      "\t2.33s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 77.44s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_051055/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     NeuralNetTorch_BAG_L2_FULL       0.770726   0.764258     roc_auc        0.773061            NaN  49.589390                 0.028873                     NaN           7.425807            2       True         22\n",
      "1       WeightedEnsemble_L2_FULL       0.770639   0.765700     roc_auc        0.093191            NaN  35.049248                 0.001299                     NaN           1.256524            2       True         12\n",
      "2         LightGBMXT_BAG_L1_FULL       0.770362   0.764077     roc_auc        0.011223            NaN   1.247374                 0.011223                     NaN           1.247374            1       True          1\n",
      "3           LightGBM_BAG_L2_FULL       0.770017   0.764633     roc_auc        0.754070            NaN  42.955404                 0.009881                     NaN           0.791820            2       True         14\n",
      "4           CatBoost_BAG_L2_FULL       0.769992   0.765782     roc_auc        0.749260            NaN  43.997736                 0.005072                     NaN           1.834153            2       True         17\n",
      "5    NeuralNetFastAI_BAG_L2_FULL       0.769777   0.764667     roc_auc        0.784958            NaN  58.938640                 0.040770                     NaN          16.775056            2       True         20\n",
      "6            XGBoost_BAG_L2_FULL       0.769715   0.764008     roc_auc        0.754459            NaN  42.395494                 0.010271                     NaN           0.231911            2       True         21\n",
      "7           CatBoost_BAG_L1_FULL       0.769517   0.764604     roc_auc        0.005117            NaN   3.053263                 0.005117                     NaN           3.053263            1       True          5\n",
      "8           LightGBM_BAG_L1_FULL       0.768660   0.762817     roc_auc        0.008597            NaN   0.905813                 0.008597                     NaN           0.905813            1       True          2\n",
      "9      LightGBMLarge_BAG_L2_FULL       0.768541   0.764159     roc_auc        0.756536            NaN  46.086066                 0.012348                     NaN           3.922482            2       True         23\n",
      "10    NeuralNetTorch_BAG_L1_FULL       0.768529   0.763321     roc_auc        0.023800            NaN  11.194563                 0.023800                     NaN          11.194563            1       True         10\n",
      "11    ExtraTreesEntr_BAG_L2_FULL       0.768344   0.769302     roc_auc        0.859298            NaN  42.940893                 0.115109                0.794530           0.777310            2       True         19\n",
      "12   NeuralNetFastAI_BAG_L1_FULL       0.768234   0.763004     roc_auc        0.040909            NaN  18.099370                 0.040909                     NaN          18.099370            1       True          8\n",
      "13  RandomForestEntr_BAG_L2_FULL       0.768108   0.766638     roc_auc        0.839590            NaN  46.572240                 0.095402                0.776616           4.408657            2       True         16\n",
      "14     LightGBMLarge_BAG_L1_FULL       0.767954   0.760689     roc_auc        0.013021            NaN   3.466236                 0.013021                     NaN           3.466236            1       True         11\n",
      "15           XGBoost_BAG_L1_FULL       0.767760   0.762828     roc_auc        0.010843            NaN   0.198154                 0.010843                     NaN           0.198154            1       True          9\n",
      "16    ExtraTreesGini_BAG_L2_FULL       0.767721   0.769895     roc_auc        0.878878            NaN  42.985530                 0.134690                0.813622           0.821947            2       True         18\n",
      "17      WeightedEnsemble_L3_FULL       0.767665   0.772196     roc_auc        1.172707            NaN  56.647186                 0.001197                     NaN           2.332926            3       True         24\n",
      "18  RandomForestGini_BAG_L2_FULL       0.767462   0.766739     roc_auc        0.876158            NaN  45.909752                 0.131970                0.807073           3.746168            2       True         15\n",
      "19    ExtraTreesGini_BAG_L1_FULL       0.765024   0.757366     roc_auc        0.168891       0.809702   0.739202                 0.168891                0.809702           0.739202            1       True          6\n",
      "20        LightGBMXT_BAG_L2_FULL       0.764657   0.769937     roc_auc        0.789742            NaN  48.968835                 0.045554                     NaN           6.805251            2       True         13\n",
      "21    ExtraTreesEntr_BAG_L1_FULL       0.764567   0.758234     roc_auc        0.171937       0.804825   0.737875                 0.171937                0.804825           0.737875            1       True          7\n",
      "22  RandomForestGini_BAG_L1_FULL       0.763399   0.753199     roc_auc        0.151271       1.017027   1.281758                 0.151271                1.017027           1.281758            1       True          3\n",
      "23  RandomForestEntr_BAG_L1_FULL       0.762890   0.754684     roc_auc        0.138579       0.776135   1.239976                 0.138579                0.776135           1.239976            1       True          4\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t316s\t = DyStack   runtime |\t3284s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3284s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_051055\"\n",
      "Train Data Rows:    45532\n",
      "Train Data Columns: 16\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4206.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.96 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 9 | ['age_ord', 'education_ord', 'age_edu', 'att_gap', 'edu_cred', ...]\n",
      "\t\t('int', [])    : 4 | ['wr_sum', 'word_credibility', 'adult_flag', 'adult_high_edu']\n",
      "\t\t('object', []) : 3 | ['married_cat', 'race_cat', 'religion_cat']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['married_cat', 'race_cat', 'religion_cat']\n",
      "\t\t('float', [])     : 9 | ['age_ord', 'education_ord', 'age_edu', 'att_gap', 'edu_cred', ...]\n",
      "\t\t('int', [])       : 2 | ['wr_sum', 'word_credibility']\n",
      "\t\t('int', ['bool']) : 2 | ['adult_flag', 'adult_high_edu']\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.04 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3283.53s of the 3283.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.05%)\n",
      "\t0.7651\t = Validation score   (roc_auc)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3280.45s of the 3280.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.28%)\n",
      "\t0.7634\t = Validation score   (roc_auc)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3277.45s of the 3277.45s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.4 GB\n",
      "\t0.7559\t = Validation score   (roc_auc)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3275.06s of the 3275.06s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/4.1 GB\n",
      "\t0.7566\t = Validation score   (roc_auc)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3272.72s of the 3272.72s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.85% memory usage per fold, 43.42%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.85%)\n",
      "\t0.7652\t = Validation score   (roc_auc)\n",
      "\t23.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3248.37s of the 3248.37s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.9 GB\n",
      "\t0.7592\t = Validation score   (roc_auc)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3246.59s of the 3246.59s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=10, gpus=0, mem=0.2/3.9 GB\n",
      "\t0.7595\t = Validation score   (roc_auc)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3244.83s of the 3244.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
      "\t0.7643\t = Validation score   (roc_auc)\n",
      "\t25.14s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3217.02s of the 3217.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.29%)\n",
      "\t0.7633\t = Validation score   (roc_auc)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3213.14s of the 3213.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\t0.7637\t = Validation score   (roc_auc)\n",
      "\t32.39s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3179.23s of the 3179.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.34%)\n",
      "\t0.761\t = Validation score   (roc_auc)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3175.81s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.4 GB\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.318, 'NeuralNetFastAI_BAG_L1': 0.273, 'NeuralNetTorch_BAG_L1': 0.227, 'LightGBMXT_BAG_L1': 0.136, 'ExtraTreesGini_BAG_L1': 0.045}\n",
      "\t0.7665\t = Validation score   (roc_auc)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 109.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4609.9 rows/s (5692 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.3 GB\n",
      "\t1.15s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.3 GB\n",
      "\t0.81s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t3.62s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.6 GB\n",
      "\tStopping at the best epoch learned earlier - 19.\n",
      "\t21.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0\n",
      "\t0.2s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.7 GB\n",
      "/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t11.39s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/3.8 GB\n",
      "\t3.65s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.318, 'NeuralNetFastAI_BAG_L1': 0.273, 'NeuralNetTorch_BAG_L1': 0.227, 'LightGBMXT_BAG_L1': 0.136, 'ExtraTreesGini_BAG_L1': 0.045}\n",
      "\t1.42s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 42.64s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/AutogluonModels/ag-20260129_051055\")\n"
     ]
    }
   ],
   "source": [
    "train_fe = build_features(train)\n",
    "test_fe  = build_features(test)\n",
    "\n",
    "feature_cols = [\n",
    "    # continuous / binary\n",
    "    \"age_ord\", \"education_ord\", \"age_edu\",\n",
    "    \"wr_sum\", \"word_credibility\",\n",
    "    \"att_gap\", \"edu_cred\", \"att_strength\", \"pos_att\",\n",
    "    \"adult_flag\", \"adult_high_edu\", \"engnat_bin\",\n",
    "\n",
    "    # categorical\n",
    "    \"married_cat\", \"race_cat\", \"religion_cat\",\n",
    "\n",
    "    # ordinal\n",
    "    \"urban_ord\"\n",
    "]\n",
    "\n",
    "train_ag = train_fe[feature_cols + [\"voted_bin\"]].copy()\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=\"voted_bin\",\n",
    "    problem_type=\"binary\",\n",
    "    eval_metric=\"roc_auc\"\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    presets=\"good_quality\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbb10f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 16 features using 5000 rows with 5 shuffle sets...\n",
      "\t20.12s\t= Expected runtime (4.02s per shuffle set)\n",
      "\t7.17s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race_cat</th>\n",
       "      <td>0.034640</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>1.209520e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038663</td>\n",
       "      <td>0.030617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_ord</th>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>4.612430e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038316</td>\n",
       "      <td>0.021079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adult_flag</th>\n",
       "      <td>0.018253</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>6.231600e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.012536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married_cat</th>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>4.448789e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.006094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engnat_bin</th>\n",
       "      <td>0.011717</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>2.419311e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.010098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wr_sum</th>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>2.512322e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.006045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_credibility</th>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>9.538608e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>0.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion_cat</th>\n",
       "      <td>0.009909</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>2.021416e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_edu</th>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>2.257677e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013260</td>\n",
       "      <td>0.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_ord</th>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>1.061550e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu_cred</th>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>1.283913e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.003574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_att</th>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>6.602097e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urban_ord</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>2.119633e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_gap</th>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>5.643238e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att_strength</th>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>1.244271e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.004051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adult_high_edu</th>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>2.338722e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance    stddev       p_value  n  p99_high   p99_low\n",
       "race_cat            0.034640  0.001954  1.209520e-06  5  0.038663  0.030617\n",
       "education_ord       0.029697  0.004186  4.612430e-05  5  0.038316  0.021079\n",
       "adult_flag          0.018253  0.002777  6.231600e-05  5  0.023970  0.012536\n",
       "married_cat         0.012661  0.003189  4.448789e-04  5  0.019228  0.006094\n",
       "engnat_bin          0.011717  0.000786  2.419311e-06  5  0.013336  0.010098\n",
       "wr_sum              0.010936  0.002376  2.512322e-04  5  0.015828  0.006045\n",
       "word_credibility    0.010024  0.001699  9.538608e-05  5  0.013522  0.006525\n",
       "religion_cat        0.009909  0.002035  2.021416e-04  5  0.014100  0.005718\n",
       "age_edu             0.009239  0.001953  2.257677e-04  5  0.013260  0.005219\n",
       "age_ord             0.008382  0.001460  1.061550e-04  5  0.011388  0.005376\n",
       "edu_cred            0.005733  0.001048  1.283913e-04  5  0.007891  0.003574\n",
       "pos_att             0.004824  0.000745  6.602097e-05  5  0.006357  0.003291\n",
       "urban_ord           0.004717  0.000981  2.119633e-04  5  0.006737  0.002698\n",
       "att_gap             0.004574  0.000380  5.643238e-06  5  0.005356  0.003792\n",
       "att_strength        0.004336  0.000138  1.244271e-07  5  0.004621  0.004051\n",
       "adult_high_edu      0.003724  0.000794  2.338722e-04  5  0.005359  0.002089"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance ÎΩëÍ∏∞ (TopÎßå)\n",
    "fi = predictor.feature_importance(train_ag)\n",
    "fi.sort_values(\"importance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652efd0",
   "metadata": {},
   "source": [
    "Tier 1 (ÌïµÏã¨ Í≥®Í≤©)\n",
    "\n",
    "race_cat\n",
    "\n",
    "education_ord\n",
    "\n",
    "adult_flag\n",
    "\n",
    "married_cat\n",
    "\n",
    "engnat_bin\n",
    "\n",
    "wr_sum\n",
    "\n",
    "word_credibility\n",
    "\n",
    "Tier 2 (ÏÑ§Î™Ö Î≥¥Í∞ï)\n",
    "\n",
    "religion_cat\n",
    "\n",
    "age_edu\n",
    "\n",
    "age_ord\n",
    "\n",
    "edu_cred\n",
    "\n",
    "pos_att\n",
    "\n",
    "Tier 3 (Îî•Îü¨ÎãùÏóêÏÑú Ïû¨ÌèâÍ∞Ä)\n",
    "\n",
    "att_gap\n",
    "\n",
    "att_strength\n",
    "\n",
    "adult_high_edu\n",
    "\n",
    "urban_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df8cc94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üèÜ DCN-V2 ÏµúÏ¢Ö Ï†úÏ∂úÏö© (Î≤ÑÍ∑∏/ÎàÑÏàò/ÏïàÏ†ïÏÑ± ÏàòÏ†ï ÏôÑÎ£å)\n",
      "================================================================================\n",
      "\n",
      "üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎìú...\n",
      "Train: (45532, 79), Test: (11383, 77)\n",
      "Ìà¨Ìëú ÏïàÌï®(positive) ÎπÑÏú®: 0.547\n",
      "ÌÅ¥ÎûòÏä§ ÎπÑÏú® (neg:pos) ‚âà 0.83:1\n",
      "üî® Feature Engineering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:33:43,492]\u001b[0m A new study created in memory with name: no-name-2ef9fe5a-951d-45cd-9e17-cde845bfd3c2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÏôÑÎ£å: (45532, 110), (11383, 108)\n",
      "\n",
      "üìä ÏµúÏ¢Ö ÌîºÏ≤ò: 14 numeric + 3 cat = 17 total\n",
      "\n",
      "üîß Categorical Encoding (Unseen ÎåÄÏùë)...\n",
      "   race_cat: 5 categories\n",
      "   married_cat: 5 categories\n",
      "   religion_cat: 6 categories\n",
      "\n",
      "================================================================================\n",
      "üîç Optuna ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù (25 trials)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:   4%|‚ñç         | 1/25 [01:12<28:49, 72.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:34:55,560]\u001b[0m Trial 0 finished with value: 0.7640053879388116 and parameters: {'hidden': 256, 'n_cross': 3, 'dropout': 0.23120372808848733, 'lr': 0.0006153331256530192, 'wd': 1.493656855461763e-06, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.3939819704323989, 'focal_gamma': 2.832442640800422}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:   8%|‚ñä         | 2/25 [02:41<31:31, 82.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:36:24,945]\u001b[0m Trial 1 finished with value: 0.762821064630377 and parameters: {'hidden': 192, 'n_cross': 2, 'dropout': 0.3049512863264476, 'lr': 0.0021928619507738728, 'wd': 7.476312062252308e-06, 'batch_size': 256, 'loss_type': 'focal', 'focal_alpha': 0.2912139968434072, 'focal_gamma': 2.785175961393014}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  12%|‚ñà‚ñè        | 3/25 [04:14<32:00, 87.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:37:58,279]\u001b[0m Trial 2 finished with value: 0.7639425773568747 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.3215089703802877, 'lr': 0.0006579145666993107, 'wd': 1.5673095467235414e-06, 'batch_size': 512, 'loss_type': 'bce', 'focal_alpha': 0.21953442280127677, 'focal_gamma': 2.684233026512157}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  16%|‚ñà‚ñå        | 4/25 [05:27<28:34, 81.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:39:11,187]\u001b[0m Trial 3 finished with value: 0.763704079317906 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.3818640804157564, 'lr': 0.0009878277403270854, 'wd': 9.717775305059631e-05, 'batch_size': 512, 'loss_type': 'bce', 'focal_alpha': 0.39391692555291175, 'focal_gamma': 2.7751328233611146}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  20%|‚ñà‚ñà        | 5/25 [06:55<27:57, 83.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:40:39,018]\u001b[0m Trial 4 finished with value: 0.7586525121194146 and parameters: {'hidden': 192, 'n_cross': 4, 'dropout': 0.2176985004103839, 'lr': 0.0007397534164346214, 'wd': 1.3667272915456224e-06, 'batch_size': 512, 'loss_type': 'focal', 'focal_alpha': 0.2713506653387179, 'focal_gamma': 2.2809345096873805}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  24%|‚ñà‚ñà‚ñç       | 6/25 [08:01<24:38, 77.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:41:45,086]\u001b[0m Trial 5 finished with value: 0.7630089785156249 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.39737738732010347, 'lr': 0.01051019547347606, 'wd': 3.945908811099999e-06, 'batch_size': 512, 'loss_type': 'focal', 'focal_alpha': 0.35425406933718917, 'focal_gamma': 2.0740446517340905}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  28%|‚ñà‚ñà‚ñä       | 7/25 [09:49<26:20, 87.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:43:33,412]\u001b[0m Trial 6 finished with value: 0.7616245379879556 and parameters: {'hidden': 384, 'n_cross': 3, 'dropout': 0.26617960497052984, 'lr': 0.00040201101730064396, 'wd': 8.569331925053988e-06, 'batch_size': 512, 'loss_type': 'focal', 'focal_alpha': 0.29444298503238986, 'focal_gamma': 2.119594245938302}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [10:36<21:11, 74.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:44:20,353]\u001b[0m Trial 7 finished with value: 0.7608944977100391 and parameters: {'hidden': 256, 'n_cross': 4, 'dropout': 0.2987591192728782, 'lr': 0.003331094193916386, 'wd': 1.9170041589170666e-05, 'batch_size': 512, 'loss_type': 'focal', 'focal_alpha': 0.26287119621526533, 'focal_gamma': 2.508570691164703}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [11:52<19:58, 74.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:45:35,547]\u001b[0m Trial 8 finished with value: 0.7622297697886578 and parameters: {'hidden': 192, 'n_cross': 4, 'dropout': 0.2457596330983245, 'lr': 0.00042764271132082304, 'wd': 7.400385759087375e-06, 'batch_size': 512, 'loss_type': 'bce', 'focal_alpha': 0.3742921180375436, 'focal_gamma': 2.8036720768991144}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [12:42<16:51, 67.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:46:26,296]\u001b[0m Trial 9 finished with value: 0.7605324073400023 and parameters: {'hidden': 256, 'n_cross': 4, 'dropout': 0.37921825998469866, 'lr': 0.0012975622576159589, 'wd': 2.138729075414893e-06, 'batch_size': 512, 'loss_type': 'focal', 'focal_alpha': 0.20139042610623814, 'focal_gamma': 2.510747302577566}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [13:35<14:39, 62.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:47:18,608]\u001b[0m Trial 10 finished with value: 0.7630551895053962 and parameters: {'hidden': 256, 'n_cross': 3, 'dropout': 0.20150946386325863, 'lr': 0.02196351972975781, 'wd': 0.00045390921584440366, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.3379949613316222, 'focal_gamma': 2.9682380234043237}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [15:05<15:24, 71.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:48:48,621]\u001b[0m Trial 11 finished with value: 0.7624779760168441 and parameters: {'hidden': 256, 'n_cross': 3, 'dropout': 0.32888786590033564, 'lr': 0.0003310611456567973, 'wd': 1.302351808341558e-06, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.2148579373428467, 'focal_gamma': 2.6539989106470596}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [16:17<14:18, 71.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:50:01,218]\u001b[0m Trial 12 finished with value: 0.7632560917767215 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.3465298018258697, 'lr': 0.004330571625749953, 'wd': 6.717715238348049e-05, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.2439270837469243, 'focal_gamma': 2.9922514570539236}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [17:30<13:11, 71.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:51:14,233]\u001b[0m Trial 13 finished with value: 0.7629899577871331 and parameters: {'hidden': 256, 'n_cross': 3, 'dropout': 0.26316360920364246, 'lr': 0.0007335673594070618, 'wd': 1.0317840912152478e-06, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.32934469713899767, 'focal_gamma': 2.6446736852680854}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [18:57<12:44, 76.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:52:40,964]\u001b[0m Trial 14 finished with value: 0.76394319489131 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.29242295168022564, 'lr': 0.0017995874107817624, 'wd': 0.0009355903554079245, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.2331112562770756, 'focal_gamma': 2.320850178619817}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [19:59<10:48, 72.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:53:42,853]\u001b[0m Trial 15 finished with value: 0.7632599701961892 and parameters: {'hidden': 384, 'n_cross': 3, 'dropout': 0.2324637654987361, 'lr': 0.0017933398696491445, 'wd': 0.0007086372936028797, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.32185199124210256, 'focal_gamma': 2.322576260515312}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [20:57<09:03, 67.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:54:41,322]\u001b[0m Trial 16 finished with value: 0.7636386101874312 and parameters: {'hidden': 256, 'n_cross': 2, 'dropout': 0.28034106536240305, 'lr': 0.0053594115069491586, 'wd': 0.00019554295990246637, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.39743674524519557, 'focal_gamma': 2.3384834454681886}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [21:52<07:27, 63.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:55:35,633]\u001b[0m Trial 17 finished with value: 0.7636545550262885 and parameters: {'hidden': 256, 'n_cross': 3, 'dropout': 0.24045831877019366, 'lr': 0.007105972441935078, 'wd': 3.3302381560872376e-05, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.25023092472139963, 'focal_gamma': 2.175085040579309}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [23:03<06:36, 66.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:56:46,643]\u001b[0m Trial 18 finished with value: 0.7638213339595905 and parameters: {'hidden': 384, 'n_cross': 3, 'dropout': 0.2868491473847308, 'lr': 0.001550705024755782, 'wd': 0.00025601264248343474, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.36314596746190864, 'focal_gamma': 2.3992946483188065}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [24:18<05:43, 68.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:58:01,667]\u001b[0m Trial 19 finished with value: 0.7633173550045644 and parameters: {'hidden': 192, 'n_cross': 2, 'dropout': 0.20412394369743492, 'lr': 0.0022079534246549114, 'wd': 2.4878539518778382e-05, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.3073263473316586, 'focal_gamma': 2.454500202631525}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.764005:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [25:38<04:48, 72.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 15:59:21,529]\u001b[0m Trial 20 finished with value: 0.7616955323694735 and parameters: {'hidden': 384, 'n_cross': 4, 'dropout': 0.35536710896088436, 'lr': 0.0010799469301872484, 'wd': 0.000987485397383764, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.22981021675571447, 'focal_gamma': 2.195780426026256}. Best is trial 0 with value: 0.7640053879388116.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.764245:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [27:16<04:00, 80.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 16:01:00,428]\u001b[0m Trial 21 finished with value: 0.7642452778577706 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.3215959950219359, 'lr': 0.0005948625155744105, 'wd': 2.8232625723379355e-06, 'batch_size': 512, 'loss_type': 'bce', 'focal_alpha': 0.22441917000690262, 'focal_gamma': 2.64411161074485}. Best is trial 21 with value: 0.7642452778577706.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.764245:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [29:04<02:56, 88.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 16:02:48,413]\u001b[0m Trial 22 finished with value: 0.7641328083386313 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.32988329182816795, 'lr': 0.000475523957762377, 'wd': 3.63495390399594e-06, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.27358283493793467, 'focal_gamma': 2.8684780444982247}. Best is trial 21 with value: 0.7642452778577706.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.764245:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [30:38<01:30, 90.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 16:04:22,102]\u001b[0m Trial 23 finished with value: 0.7632052163337345 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.32112604095430886, 'lr': 0.0005278760842468562, 'wd': 3.2914161586956905e-06, 'batch_size': 512, 'loss_type': 'bce', 'focal_alpha': 0.28621633863256424, 'focal_gamma': 2.8703825409596897}. Best is trial 21 with value: 0.7642452778577706.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.764245: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [32:43<00:00, 78.55s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-29 16:06:27,343]\u001b[0m Trial 24 finished with value: 0.7636934472669935 and parameters: {'hidden': 384, 'n_cross': 2, 'dropout': 0.34034415651795896, 'lr': 0.0005413568118415262, 'wd': 3.38625548255424e-06, 'batch_size': 256, 'loss_type': 'bce', 'focal_alpha': 0.2701020580488975, 'focal_gamma': 2.904074248596353}. Best is trial 21 with value: 0.7642452778577706.\u001b[0m\n",
      "\n",
      "‚úÖ Optuna ÏôÑÎ£å!\n",
      "üèÜ Best CV AUC: 0.76425\n",
      "üîß Best Parameters:\n",
      "   hidden: 384\n",
      "   n_cross: 2\n",
      "   dropout: 0.3215959950219359\n",
      "   lr: 0.0005948625155744105\n",
      "   wd: 2.8232625723379355e-06\n",
      "   batch_size: 512\n",
      "   loss_type: bce\n",
      "   focal_alpha: 0.22441917000690262\n",
      "   focal_gamma: 2.64411161074485\n",
      "\n",
      "================================================================================\n",
      "üöÄ ÏµúÏ¢Ö ÌïôÏäµ: 5-Fold √ó 3 Seeds = 15 Models ÏïôÏÉÅÎ∏î\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üå± Seed 1/3 (seed=42)\n",
      "================================================================================\n",
      "   Fold 1/5...\n",
      "   ‚úÖ Fold 1 AUC: 0.77548\n",
      "   Fold 2/5...\n",
      "   ‚úÖ Fold 2 AUC: 0.76460\n",
      "   Fold 3/5...\n",
      "   ‚úÖ Fold 3 AUC: 0.76079\n",
      "   Fold 4/5...\n",
      "   ‚úÖ Fold 4 AUC: 0.75676\n",
      "   Fold 5/5...\n",
      "   ‚úÖ Fold 5 AUC: 0.76069\n",
      "\n",
      "   üèÜ Seed 1 OOF AUC: 0.76333\n",
      "\n",
      "================================================================================\n",
      "üå± Seed 2/3 (seed=123)\n",
      "================================================================================\n",
      "   Fold 1/5...\n",
      "   ‚úÖ Fold 1 AUC: 0.75664\n",
      "   Fold 2/5...\n",
      "   ‚úÖ Fold 2 AUC: 0.76302\n",
      "   Fold 3/5...\n",
      "   ‚úÖ Fold 3 AUC: 0.76722\n",
      "   Fold 4/5...\n",
      "   ‚úÖ Fold 4 AUC: 0.76757\n",
      "   Fold 5/5...\n",
      "   ‚úÖ Fold 5 AUC: 0.76504\n",
      "\n",
      "   üèÜ Seed 2 OOF AUC: 0.76378\n",
      "\n",
      "================================================================================\n",
      "üå± Seed 3/3 (seed=777)\n",
      "================================================================================\n",
      "   Fold 1/5...\n",
      "   ‚úÖ Fold 1 AUC: 0.76192\n",
      "   Fold 2/5...\n",
      "   ‚úÖ Fold 2 AUC: 0.77078\n",
      "   Fold 3/5...\n",
      "   ‚úÖ Fold 3 AUC: 0.75854\n",
      "   Fold 4/5...\n",
      "   ‚úÖ Fold 4 AUC: 0.76195\n",
      "   Fold 5/5...\n",
      "   ‚úÖ Fold 5 AUC: 0.76955\n",
      "\n",
      "   üèÜ Seed 3 OOF AUC: 0.76425\n",
      "\n",
      "================================================================================\n",
      "üéâ ÏµúÏ¢Ö Í≤∞Í≥º\n",
      "================================================================================\n",
      "üèÜ ÏµúÏ¢Ö OOF AUC: 0.76543\n",
      "üìä Ï†ÑÏ≤¥ Fold AUC: 0.76404 ¬± 0.00517\n",
      "üìä ÏµúÍ≥† Fold AUC: 0.77548\n",
      "üìä ÏµúÏ†Ä Fold AUC: 0.75664\n",
      "üìä Fold AUC Î≤îÏúÑ: 0.01885\n",
      "================================================================================\n",
      "\n",
      "üíæ Ï†úÏ∂ú ÌååÏùº: submission_dcn_final_fixed.csv\n",
      "üìä ÏòàÏ∏°Í∞í Î≤îÏúÑ: [0.1246, 0.9921]\n",
      "üìä ÏòàÏ∏°Í∞í ÌèâÍ∑†: 0.5141\n",
      "üìä ÏòàÏ∏°Í∞í std: 0.2483\n",
      "\n",
      "================================================================================\n",
      "üèÜ ÏôÑÎ£å!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "üèÜ DCN-V2 ÏµúÏ¢Ö Ï†úÏ∂úÏö© (Î≤ÑÍ∑∏/ÎàÑÏàò/ÏïàÏ†ïÏÑ± ÏàòÏ†ï ÏôÑÎ£å)\n",
    "\n",
    "Fix Summary\n",
    "1) Optuna param key mismatch Ìï¥Í≤∞: suggest Ïù¥Î¶ÑÍ≥º best_params ÌÇ§ ÌÜµÏùº\n",
    "2) FoldÎ≥Ñ StandardScaler Ï†ÅÏö© (ÎàÑÏàò Ï†úÍ±∞)\n",
    "3) DCN CrossLayer ÏàòÏãù ÏàòÏ†ï (biasÍ∞Ä x0Ïóê Í≥±Ìï¥ÏßÄÎèÑÎ°ù)\n",
    "4) Loss ÏòµÏÖòÌôî: BCEWithLogitsLoss(pos_weight) vs FocalLoss (OptunaÏóêÏÑú ÏÑ†ÌÉù)\n",
    "5) BatchNorm ÏïàÏ†ïÌôî: train loader drop_last=True\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BASE_SEED = 42\n",
    "np.random.seed(BASE_SEED)\n",
    "torch.manual_seed(BASE_SEED)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üèÜ DCN-V2 ÏµúÏ¢Ö Ï†úÏ∂úÏö© (Î≤ÑÍ∑∏/ÎàÑÏàò/ÏïàÏ†ïÏÑ± ÏàòÏ†ï ÏôÑÎ£å)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==================== 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Feature Engineering ====================\n",
    "\n",
    "print(\"\\nüìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎìú...\")\n",
    "\n",
    "train = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test  = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n",
    "train[\"voted_bin\"] = (train[\"voted\"] == 2).astype(int)\n",
    "\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")\n",
    "pos_rate = train[\"voted_bin\"].mean()\n",
    "print(f\"Ìà¨Ìëú ÏïàÌï®(positive) ÎπÑÏú®: {pos_rate:.3f}\")\n",
    "print(f\"ÌÅ¥ÎûòÏä§ ÎπÑÏú® (neg:pos) ‚âà {(1-pos_rate)/(pos_rate+1e-9):.2f}:1\")\n",
    "\n",
    "train.columns = train.columns.str.strip()\n",
    "test.columns  = test.columns.str.strip()\n",
    "\n",
    "rename_map = {c: c[:-1] for c in train.columns if c.startswith(\"Q\") and c.endswith(\"A\")}\n",
    "train = train.rename(columns=rename_map)\n",
    "test  = test.rename(columns=rename_map)\n",
    "\n",
    "qe_cols = [c for c in train.columns if c.endswith(\"E\")]\n",
    "train_log_time = np.log1p(train[qe_cols])\n",
    "P10 = train_log_time.stack().quantile(0.10)\n",
    "P90 = train_log_time.stack().quantile(0.90)\n",
    "\n",
    "def add_qa_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"neg_att\"] = df[[\"Qb\",\"Qc\",\"Qj\",\"Qm\",\"Qo\",\"Qs\"]].mean(axis=1)\n",
    "    df[\"pos_att\"] = df[[\"Qk\",\"Qq\"]].mean(axis=1)\n",
    "    df[\"att_gap\"] = df[\"pos_att\"] - df[\"neg_att\"]\n",
    "    cert_cols = [\"Qe\",\"Qf\",\"Qh\",\"Qr\"]\n",
    "    df[\"certainty\"] = (df[cert_cols] - 3).abs().mean(axis=1)\n",
    "    df[\"mid_ratio\"] = (df[cert_cols] == 3).sum(axis=1) / len(cert_cols)\n",
    "    df[\"consistency\"] = df[[\"Qb\",\"Qc\",\"Qj\",\"Qm\",\"Qo\",\"Qs\",\"Qk\",\"Qq\"]].std(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_qe_features(df, qe_cols, p10, p90):\n",
    "    df = df.copy()\n",
    "    log_time = np.log1p(df[qe_cols])\n",
    "    df[\"time_mean\"] = log_time.mean(axis=1)\n",
    "    df[\"time_median\"] = log_time.median(axis=1)\n",
    "    df[\"time_std\"] = log_time.std(axis=1)\n",
    "    df[\"fast_ratio\"] = (log_time < p10).mean(axis=1)\n",
    "    df[\"slow_ratio\"] = (log_time > p90).mean(axis=1)\n",
    "    df[\"outlier_ratio\"] = (df[qe_cols] > 10000).mean(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_tp_features(df):\n",
    "    df = df.copy()\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    df[tp_cols] = df[tp_cols].replace(0, np.nan)\n",
    "    df[tp_cols] = df[tp_cols].fillna(df[tp_cols].mean())\n",
    "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "    return df\n",
    "\n",
    "def add_demo_features(df):\n",
    "    df = df.copy()\n",
    "    age_map = {\"10s\":1,\"20s\":2,\"30s\":3,\"40s\":4,\"50s\":5,\"60s\":6,\"70s+\":7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    df[\"adult_flag\"] = (df[\"age_group\"] != \"10s\").astype(int)\n",
    "    df[\"education_ord\"] = df[\"education\"].replace(0, np.nan)\n",
    "    df[\"engnat_bin\"] = df[\"engnat\"].replace({1:1, 2:0, 0:np.nan})\n",
    "    df[\"urban_ord\"] = df[\"urban\"].replace(0, np.nan)\n",
    "    return df\n",
    "\n",
    "def add_word_features(df):\n",
    "    df = df.copy()\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1,14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1,4)]\n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "    return df\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education_ord\"]\n",
    "    df[\"adult_high_edu\"] = ((df[\"adult_flag\"]==1) & (df[\"education_ord\"]>=3)).astype(int)\n",
    "    df[\"edu_cred\"] = df[\"education_ord\"] * df[\"word_credibility\"]\n",
    "    return df\n",
    "\n",
    "def recode_married(x):\n",
    "    if pd.isna(x): return \"NA\"\n",
    "    try: x = int(x)\n",
    "    except: return \"NA\"\n",
    "    if x == 1: return \"Single\"\n",
    "    if x == 2: return \"Married\"\n",
    "    if x == 3: return \"Divorced_Widowed\"\n",
    "    return \"Other_NA\"\n",
    "\n",
    "def recode_race(x):\n",
    "    if pd.isna(x): return \"NA\"\n",
    "    x = str(x).strip()\n",
    "    if x in [\"White\", \"Asian\", \"Black\"]: return x\n",
    "    return \"Other\"\n",
    "\n",
    "def recode_religion(x):\n",
    "    if pd.isna(x): return \"NA\"\n",
    "    x = str(x).strip()\n",
    "    if x.startswith(\"Christian\"): return \"Christian\"\n",
    "    if x in [\"Atheist\", \"Agnostic\"]: return \"Atheist_Agnostic\"\n",
    "    if x in [\"Jewish\", \"Muslim\"]: return x\n",
    "    return \"Other\"\n",
    "\n",
    "def add_cat_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"married_cat\"] = df[\"married\"].apply(recode_married)\n",
    "    df[\"race_cat\"] = df[\"race\"].apply(recode_race)\n",
    "    df[\"religion_cat\"] = df[\"religion\"].apply(recode_religion)\n",
    "    return df\n",
    "\n",
    "def build_features(df):\n",
    "    df = add_qa_features(df)\n",
    "    df = add_qe_features(df, qe_cols, P10, P90)\n",
    "    df = add_tp_features(df)\n",
    "    df = add_demo_features(df)\n",
    "    df = add_word_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_cat_features(df)\n",
    "    return df\n",
    "\n",
    "print(\"üî® Feature Engineering...\")\n",
    "train_fe = build_features(train)\n",
    "test_fe  = build_features(test)\n",
    "print(f\"‚úÖ ÏôÑÎ£å: {train_fe.shape}, {test_fe.shape}\")\n",
    "\n",
    "# ==================== 2. Feature ÏÑ†ÌÉù ====================\n",
    "\n",
    "NUM_COLS = [\n",
    "    \"age_edu\", \"education_ord\", \"adult_flag\",\n",
    "    \"wr_sum\", \"word_credibility\", \"edu_cred\",\n",
    "    \"pos_att\", \"neg_att\", \"certainty\", \"consistency\",\n",
    "    \"time_mean\", \"time_std\",\n",
    "    \"urban_ord\", \"engnat_bin\"\n",
    "]\n",
    "CAT_COLS = [\"race_cat\", \"married_cat\", \"religion_cat\"]\n",
    "TARGET = \"voted_bin\"\n",
    "\n",
    "print(f\"\\nüìä ÏµúÏ¢Ö ÌîºÏ≤ò: {len(NUM_COLS)} numeric + {len(CAT_COLS)} cat = {len(NUM_COLS)+len(CAT_COLS)} total\")\n",
    "\n",
    "# ==================== 3. ÏïàÏ†ÑÌïú Categorical Encoding ====================\n",
    "\n",
    "print(\"\\nüîß Categorical Encoding (Unseen ÎåÄÏùë)...\")\n",
    "\n",
    "for df in [train_fe, test_fe]:\n",
    "    for c in NUM_COLS:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    for c in CAT_COLS:\n",
    "        df[c] = df[c].astype(str).fillna(\"NA\")\n",
    "\n",
    "cat_maps = {}\n",
    "cat_dims = []\n",
    "for c in CAT_COLS:\n",
    "    all_values = set(train_fe[c].unique()) | set(test_fe[c].unique())\n",
    "    vocab = [\"<UNK>\"] + sorted(all_values)\n",
    "    cat_maps[c] = {v: i for i, v in enumerate(vocab)}\n",
    "    cat_dims.append(len(vocab))\n",
    "    print(f\"   {c}: {len(vocab)} categories\")\n",
    "\n",
    "def safe_encode_cat(series, mapping):\n",
    "    return series.map(lambda x: mapping.get(x, 0)).astype(int).values\n",
    "\n",
    "# Ï†ÑÏó≠ median (foldÎ≥Ñ ÎàÑÏàòÎäî scalerÏóêÏÑú ÎßâÍ≥†, medianÏùÄ ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏòÅÌñ• Ï†ÅÏùå)\n",
    "# Îçî ÏóÑÍ≤©Ìûà ÌïòÎ†§Î©¥ foldÎßàÎã§ medianÎèÑ train foldÏóêÏÑú Í≥ÑÏÇ∞ÌïòÎèÑÎ°ù Î∞îÍøÄ Ïàò ÏûàÏùå.\n",
    "global_num_median = train_fe[NUM_COLS].median()\n",
    "\n",
    "X_num_all = train_fe[NUM_COLS].fillna(global_num_median).values\n",
    "X_cat_all = np.stack([safe_encode_cat(train_fe[c], cat_maps[c]) for c in CAT_COLS], axis=1)\n",
    "y_all = train_fe[TARGET].values.astype(np.float32)\n",
    "\n",
    "test_num_all = test_fe[NUM_COLS].fillna(global_num_median).values\n",
    "test_cat_all = np.stack([safe_encode_cat(test_fe[c], cat_maps[c]) for c in CAT_COLS], axis=1)\n",
    "\n",
    "# ==================== 4. DCN-V2 Î™®Îç∏ ====================\n",
    "\n",
    "class CrossLayer(nn.Module):\n",
    "    \"\"\"DCN-V2 Cross Layer (ÏàòÏãù ÏàòÏ†ï: biasÍ∞Ä x0Ïóê Í≥±Ìï¥ÏßÄÎèÑÎ°ù)\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, x0, x):\n",
    "        # x_{l+1} = x0 ‚äô (W x + b) + x\n",
    "        return x0 * (self.weight(x) + self.bias) + x\n",
    "\n",
    "class DeepCrossNetworkV2(nn.Module):\n",
    "    def __init__(self, num_dim, cat_dims, hidden=256, n_cross=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embs = nn.ModuleList()\n",
    "        emb_out_dim = 0\n",
    "        for d in cat_dims:\n",
    "            e = min(50, max(8, int(round(2.0 * (d ** 0.56)))))\n",
    "            self.embs.append(nn.Embedding(d, e))\n",
    "            emb_out_dim += e\n",
    "\n",
    "        input_dim = num_dim + emb_out_dim\n",
    "\n",
    "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        self.cross_layers = nn.ModuleList([CrossLayer(input_dim) for _ in range(n_cross)])\n",
    "\n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden, hidden // 2),\n",
    "            nn.BatchNorm1d(hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden // 2, hidden // 4),\n",
    "            nn.BatchNorm1d(hidden // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout / 2),\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(input_dim + hidden // 4, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        cat_emb = torch.cat([emb(x_cat[:, i]) for i, emb in enumerate(self.embs)], dim=1)\n",
    "        x = torch.cat([x_num, cat_emb], dim=1)\n",
    "        x = self.input_bn(x)\n",
    "\n",
    "        x0 = x\n",
    "        x_cross = x\n",
    "        for cross in self.cross_layers:\n",
    "            x_cross = cross(x0, x_cross)\n",
    "\n",
    "        x_deep = self.deep(x)\n",
    "        x_final = torch.cat([x_cross, x_deep], dim=1)\n",
    "        return self.output(x_final).squeeze(1)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, gamma=2.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-bce)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * bce\n",
    "        return loss.mean()\n",
    "\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "# ==================== 5. Optuna ÌäúÎãù (FoldÎ≥Ñ scaler Ï†ÅÏö© + loss ÏòµÏÖòÌôî) ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç Optuna ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù (25 trials)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def compute_pos_weight(y_train_np):\n",
    "    pos = float(y_train_np.sum())\n",
    "    neg = float(len(y_train_np) - pos)\n",
    "    # pos_weight = neg/pos\n",
    "    return torch.tensor([neg / (pos + 1e-9)], device=DEVICE)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # Íµ¨Ï°∞\n",
    "        \"hidden\": trial.suggest_categorical(\"hidden\", [192, 256, 384]),\n",
    "        \"n_cross\": trial.suggest_int(\"n_cross\", 2, 4),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.2, 0.4),\n",
    "\n",
    "        # ÏµúÏ†ÅÌôî\n",
    "        \"lr\": trial.suggest_float(\"lr\", 3e-4, 3e-2, log=True),\n",
    "        \"wd\": trial.suggest_float(\"wd\", 1e-6, 1e-3, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [256, 512]),\n",
    "\n",
    "        # loss\n",
    "        \"loss_type\": trial.suggest_categorical(\"loss_type\", [\"bce\", \"focal\"]),\n",
    "        \"focal_alpha\": trial.suggest_float(\"focal_alpha\", 0.2, 0.4),\n",
    "        \"focal_gamma\": trial.suggest_float(\"focal_gamma\", 2.0, 3.0),\n",
    "    }\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=BASE_SEED)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kfold.split(X_num_all, y_all), 1):\n",
    "        X_tr_raw, X_va_raw = X_num_all[tr_idx], X_num_all[va_idx]\n",
    "        Xc_tr, Xc_va = X_cat_all[tr_idx], X_cat_all[va_idx]\n",
    "        y_tr, y_va = y_all[tr_idx], y_all[va_idx]\n",
    "\n",
    "        # ‚úÖ FoldÎ≥Ñ scaler (ÎàÑÏàò Ï†úÍ±∞)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_tr_raw)\n",
    "        X_va = scaler.transform(X_va_raw)\n",
    "\n",
    "        dl_tr = DataLoader(\n",
    "            TabDataset(X_tr, Xc_tr, y_tr),\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            drop_last=True,   # ‚úÖ BN ÏïàÏ†ïÌôî\n",
    "        )\n",
    "        dl_va = DataLoader(\n",
    "            TabDataset(X_va, Xc_va, y_va),\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        model = DeepCrossNetworkV2(\n",
    "            num_dim=len(NUM_COLS),\n",
    "            cat_dims=cat_dims,\n",
    "            hidden=params[\"hidden\"],\n",
    "            n_cross=params[\"n_cross\"],\n",
    "            dropout=params[\"dropout\"],\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"], weight_decay=params[\"wd\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "        if params[\"loss_type\"] == \"bce\":\n",
    "            pos_weight = compute_pos_weight(y_tr)\n",
    "            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        else:\n",
    "            criterion = FocalLoss(alpha=params[\"focal_alpha\"], gamma=params[\"focal_gamma\"])\n",
    "\n",
    "        best_auc, patience = 0.0, 0\n",
    "\n",
    "        for epoch in range(50):\n",
    "            model.train()\n",
    "            for xb_num, xb_cat, yb in dl_tr:\n",
    "                xb_num = xb_num.to(DEVICE)\n",
    "                xb_cat = xb_cat.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            # val\n",
    "            model.eval()\n",
    "            preds, tgts = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb_num, xb_cat, yb in dl_va:\n",
    "                    xb_num = xb_num.to(DEVICE)\n",
    "                    xb_cat = xb_cat.to(DEVICE)\n",
    "                    p = torch.sigmoid(model(xb_num, xb_cat)).cpu().numpy()\n",
    "                    preds.append(p)\n",
    "                    tgts.append(yb.numpy())\n",
    "\n",
    "            val_auc = roc_auc_score(np.concatenate(tgts), np.concatenate(preds))\n",
    "\n",
    "            if val_auc > best_auc + 1e-6:\n",
    "                best_auc = val_auc\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= 7:\n",
    "                    break\n",
    "\n",
    "        fold_scores.append(best_auc)\n",
    "\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=BASE_SEED))\n",
    "study.optimize(objective, n_trials=25, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\n‚úÖ Optuna ÏôÑÎ£å!\")\n",
    "print(f\"üèÜ Best CV AUC: {study.best_value:.5f}\")\n",
    "print(\"üîß Best Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "# ==================== 6. ÏµúÏ¢Ö ÌïôÏäµ: 5-Fold √ó 3 Seeds ÏïôÏÉÅÎ∏î ====================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ ÏµúÏ¢Ö ÌïôÏäµ: 5-Fold √ó 3 Seeds = 15 Models ÏïôÏÉÅÎ∏î\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "SEEDS = [42, 123, 777]\n",
    "\n",
    "all_oof_preds = []\n",
    "all_test_preds = []\n",
    "all_fold_aucs = []\n",
    "\n",
    "for seed_idx, seed in enumerate(SEEDS, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üå± Seed {seed_idx}/3 (seed={seed})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    oof_preds = np.zeros(len(X_num_all), dtype=np.float32)\n",
    "    test_preds = np.zeros(len(test_num_all), dtype=np.float32)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kfold.split(X_num_all, y_all), 1):\n",
    "        print(f\"   Fold {fold}/5...\")\n",
    "\n",
    "        X_tr_raw, X_va_raw = X_num_all[tr_idx], X_num_all[va_idx]\n",
    "        Xc_tr, Xc_va = X_cat_all[tr_idx], X_cat_all[va_idx]\n",
    "        y_tr, y_va = y_all[tr_idx], y_all[va_idx]\n",
    "\n",
    "        # ‚úÖ FoldÎ≥Ñ scaler (ÎàÑÏàò Ï†úÍ±∞)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_tr_raw)\n",
    "        X_va = scaler.transform(X_va_raw)\n",
    "        X_te = scaler.transform(test_num_all)\n",
    "\n",
    "        dl_tr = DataLoader(\n",
    "            TabDataset(X_tr, Xc_tr, y_tr),\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            drop_last=True,   # ‚úÖ BN ÏïàÏ†ïÌôî\n",
    "        )\n",
    "        dl_va = DataLoader(\n",
    "            TabDataset(X_va, Xc_va, y_va),\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        model = DeepCrossNetworkV2(\n",
    "            num_dim=len(NUM_COLS),\n",
    "            cat_dims=cat_dims,\n",
    "            hidden=best_params[\"hidden\"],\n",
    "            n_cross=best_params[\"n_cross\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"wd\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "        if best_params[\"loss_type\"] == \"bce\":\n",
    "            pos_weight = compute_pos_weight(y_tr)\n",
    "            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        else:\n",
    "            criterion = FocalLoss(alpha=best_params[\"focal_alpha\"], gamma=best_params[\"focal_gamma\"])\n",
    "\n",
    "        best_auc, best_state, patience = 0.0, None, 0\n",
    "\n",
    "        for epoch in range(80):\n",
    "            model.train()\n",
    "            for xb_num, xb_cat, yb in dl_tr:\n",
    "                xb_num = xb_num.to(DEVICE)\n",
    "                xb_cat = xb_cat.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if epoch % 5 == 0 or epoch > 50:\n",
    "                model.eval()\n",
    "                preds, tgts = [], []\n",
    "                with torch.no_grad():\n",
    "                    for xb_num, xb_cat, yb in dl_va:\n",
    "                        xb_num = xb_num.to(DEVICE)\n",
    "                        xb_cat = xb_cat.to(DEVICE)\n",
    "                        p = torch.sigmoid(model(xb_num, xb_cat)).cpu().numpy()\n",
    "                        preds.append(p)\n",
    "                        tgts.append(yb.numpy())\n",
    "\n",
    "                val_auc = roc_auc_score(np.concatenate(tgts), np.concatenate(preds))\n",
    "\n",
    "                if val_auc > best_auc + 1e-6:\n",
    "                    best_auc = val_auc\n",
    "                    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "                    if patience >= 10:\n",
    "                        break\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        model.eval()\n",
    "\n",
    "        # OOF\n",
    "        with torch.no_grad():\n",
    "            va_num = torch.tensor(X_va, dtype=torch.float32).to(DEVICE)\n",
    "            va_cat = torch.tensor(Xc_va, dtype=torch.long).to(DEVICE)\n",
    "            oof_preds[va_idx] = torch.sigmoid(model(va_num, va_cat)).cpu().numpy()\n",
    "\n",
    "        # Test\n",
    "        with torch.no_grad():\n",
    "            te_num = torch.tensor(X_te, dtype=torch.float32).to(DEVICE)\n",
    "            te_cat = torch.tensor(test_cat_all, dtype=torch.long).to(DEVICE)\n",
    "            test_preds += torch.sigmoid(model(te_num, te_cat)).cpu().numpy() / 5.0\n",
    "\n",
    "        fold_auc = roc_auc_score(y_va, oof_preds[va_idx])\n",
    "        all_fold_aucs.append(fold_auc)\n",
    "        print(f\"   ‚úÖ Fold {fold} AUC: {fold_auc:.5f}\")\n",
    "\n",
    "    seed_oof_auc = roc_auc_score(y_all, oof_preds)\n",
    "    print(f\"\\n   üèÜ Seed {seed_idx} OOF AUC: {seed_oof_auc:.5f}\")\n",
    "\n",
    "    all_oof_preds.append(oof_preds)\n",
    "    all_test_preds.append(test_preds)\n",
    "\n",
    "final_oof = np.mean(all_oof_preds, axis=0)\n",
    "final_test = np.mean(all_test_preds, axis=0)\n",
    "final_auc = roc_auc_score(y_all, final_oof)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üèÜ ÏµúÏ¢Ö OOF AUC: {final_auc:.5f}\")\n",
    "print(f\"üìä Ï†ÑÏ≤¥ Fold AUC: {np.mean(all_fold_aucs):.5f} ¬± {np.std(all_fold_aucs):.5f}\")\n",
    "print(f\"üìä ÏµúÍ≥† Fold AUC: {np.max(all_fold_aucs):.5f}\")\n",
    "print(f\"üìä ÏµúÏ†Ä Fold AUC: {np.min(all_fold_aucs):.5f}\")\n",
    "print(f\"üìä Fold AUC Î≤îÏúÑ: {np.max(all_fold_aucs) - np.min(all_fold_aucs):.5f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"index\": test_fe[\"index\"] if \"index\" in test_fe.columns else np.arange(len(test_fe)),\n",
    "    \"voted\": final_test\n",
    "})\n",
    "submission.to_csv(\"submission_dcn_final_fixed.csv\", index=False)\n",
    "\n",
    "print(f\"\\nüíæ Ï†úÏ∂ú ÌååÏùº: submission_dcn_final_fixed.csv\")\n",
    "print(f\"üìä ÏòàÏ∏°Í∞í Î≤îÏúÑ: [{final_test.min():.4f}, {final_test.max():.4f}]\")\n",
    "print(f\"üìä ÏòàÏ∏°Í∞í ÌèâÍ∑†: {final_test.mean():.4f}\")\n",
    "print(f\"üìä ÏòàÏ∏°Í∞í std: {final_test.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ ÏôÑÎ£å!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51c1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
