{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_MLP_v1_baseline 요약\n",
    "\n",
    "- 모델: VotingMLP/Residual MLP\n",
    "- 피처: neg/pos/neutral/confident, Big5 diff/strength, wr/wf/cred, demo ordinal, hand/married/race/religion\n",
    "- 학습/평가: 단일 split, BCEWithLogits + pos_weight, ReduceLROnPlateau\n",
    "- 제출파일: submission_01_MLP_v1_baseline.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0f1e877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "687b6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(\"../../data/raw/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb5d45",
   "metadata": {},
   "source": [
    "### 1. 공통 전처리/피처 생성 + train/test 일괄 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1c5339ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45532, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>conscientiousness_diff</th>\n",
       "      <th>conscientiousness_strength</th>\n",
       "      <th>neuroticism_diff</th>\n",
       "      <th>neuroticism_strength</th>\n",
       "      <th>openness_diff</th>\n",
       "      <th>openness_strength</th>\n",
       "      <th>wr_sum</th>\n",
       "      <th>wf_sum</th>\n",
       "      <th>word_credibility</th>\n",
       "      <th>cred_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>363</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  \\\n",
       "0      0  3.0   363  4.0  1370  5.0   997  1.0  1024  2.0  ...   \n",
       "1      1  5.0   647  5.0  1313  3.0  3387  5.0  2969  1.0  ...   \n",
       "2      2  4.0  1623  1.0  1480  1.0  1021  4.0  3374  5.0  ...   \n",
       "3      3  3.0   504  3.0  2311  4.0   992  3.0  3245  1.0  ...   \n",
       "4      4  1.0   927  1.0   707  5.0   556  2.0  1062  1.0  ...   \n",
       "\n",
       "   conscientiousness_diff  conscientiousness_strength  neuroticism_diff  \\\n",
       "0                    -2.0                         2.0              -3.0   \n",
       "1                    -4.0                         4.0               0.0   \n",
       "2                    -5.0                         5.0               4.0   \n",
       "3                    -2.0                         2.0               0.0   \n",
       "4                    -5.0                         5.0               4.0   \n",
       "\n",
       "   neuroticism_strength  openness_diff  openness_strength  wr_sum  wf_sum  \\\n",
       "0                   3.0           -1.0                1.0     7.0     0.0   \n",
       "1                   0.0           -3.0                3.0     8.0     0.0   \n",
       "2                   4.0            0.0                0.0    10.0     1.0   \n",
       "3                   0.0           -2.0                2.0     5.0     0.0   \n",
       "4                   4.0           -6.0                6.0    11.0     1.0   \n",
       "\n",
       "   word_credibility  cred_bin  \n",
       "0               7.0      High  \n",
       "1               8.0      High  \n",
       "2               9.0      High  \n",
       "3               5.0       Mid  \n",
       "4              10.0      High  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Unified train/test pipeline\n",
    "# =========================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# 공통 전처리/피처 생성 함수\n",
    "# -----------------------------\n",
    "def build_features(df_raw, cfg=None, is_train=True):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # 0) voted -> voted_bin (train에만 존재)\n",
    "    if is_train and \"voted\" in df.columns:\n",
    "        df[\"voted_bin\"] = (df[\"voted\"] == 2).astype(int)\n",
    "\n",
    "    # 1) age_group -> ordinal\n",
    "    if \"age_group\" in df.columns:\n",
    "        age_map = {\"10s\":1, \"20s\":2, \"30s\":3, \"40s\":4, \"50s\":5, \"60s\":6, \"+70s\":7}\n",
    "        df[\"age_group_ord\"] = df[\"age_group\"].map(age_map).astype(\"float32\")\n",
    "\n",
    "    # 2) education (0=무응답 -> NaN -> train 평균으로 대치)\n",
    "    if \"education\" in df.columns:\n",
    "        df[\"education\"] = pd.to_numeric(df[\"education\"], errors=\"coerce\")\n",
    "        df.loc[df[\"education\"] == 0, \"education\"] = np.nan\n",
    "        if cfg is not None:\n",
    "            df[\"education\"] = df[\"education\"].fillna(cfg[\"education_mean\"])\n",
    "        df[\"education\"] = df[\"education\"].astype(\"float32\")\n",
    "\n",
    "    # 3) married_bin (1=미혼 vs 기타, 0=무응답 NaN)\n",
    "    if \"married\" in df.columns:\n",
    "        df[\"married\"] = pd.to_numeric(df[\"married\"], errors=\"coerce\")\n",
    "        df.loc[df[\"married\"] == 0, \"married\"] = np.nan\n",
    "        df[\"married_bin\"] = (df[\"married\"] == 1).astype(\"float32\")\n",
    "\n",
    "    # 4) hand_bin (3=양손 vs 기타, 0=무응답 NaN)\n",
    "    if \"hand\" in df.columns:\n",
    "        df[\"hand\"] = pd.to_numeric(df[\"hand\"], errors=\"coerce\")\n",
    "        df.loc[df[\"hand\"] == 0, \"hand\"] = np.nan\n",
    "        df[\"hand_bin\"] = (df[\"hand\"] == 3).astype(\"float32\")\n",
    "\n",
    "    # 5) urban_ord (0=무응답 NaN)\n",
    "    if \"urban\" in df.columns:\n",
    "        df[\"urban\"] = pd.to_numeric(df[\"urban\"], errors=\"coerce\")\n",
    "        df.loc[df[\"urban\"] == 0, \"urban\"] = np.nan\n",
    "        df[\"urban_ord\"] = df[\"urban\"].astype(\"float32\")\n",
    "\n",
    "    # 6) race/religion 단순화: train에서 뽑은 top-k만 살리고 나머지 Other\n",
    "    def simplify_major_other(series, majors):\n",
    "        return series.apply(lambda x: x if x in majors else \"Other\")\n",
    "\n",
    "    if \"race\" in df.columns and cfg is not None:\n",
    "        df[\"race_simple\"] = simplify_major_other(df[\"race\"], cfg[\"race_majors\"]).astype(str)\n",
    "\n",
    "    if \"religion\" in df.columns and cfg is not None:\n",
    "        df[\"religion_simple\"] = simplify_major_other(df[\"religion\"], cfg[\"religion_majors\"]).astype(str)\n",
    "\n",
    "    # 7) Q_A: neg_att / pos_att / confident_ratio / neutral_ratio\n",
    "    neg_cols = [\"QbA\",\"QcA\",\"QjA\",\"QmA\",\"QoA\",\"QsA\"]\n",
    "    pos_cols = [\"QkA\",\"QqA\"]\n",
    "    other_cols = [\"QeA\",\"QfA\",\"QhA\",\"QrA\"]\n",
    "\n",
    "    for col in neg_cols + pos_cols + other_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    if all(c in df.columns for c in neg_cols):\n",
    "        df[\"neg_att\"] = df[neg_cols].mean(axis=1)\n",
    "\n",
    "    if all(c in df.columns for c in pos_cols):\n",
    "        df[\"pos_att\"] = df[pos_cols].mean(axis=1)\n",
    "\n",
    "    if all(c in df.columns for c in other_cols):\n",
    "        other = df[other_cols]\n",
    "        df[\"neutral_ratio\"] = (other == 3).mean(axis=1).astype(\"float32\")\n",
    "        df[\"confident_ratio\"] = ((other <= 2) | (other >= 4)).mean(axis=1).astype(\"float32\")\n",
    "\n",
    "    # 8) TP Big5 diff/strength\n",
    "    tp_pairs = {\n",
    "        \"extraversion\": (\"tp01\", \"tp06\"),\n",
    "        \"agreeableness\": (\"tp07\", \"tp02\"),\n",
    "        \"conscientiousness\": (\"tp03\", \"tp08\"),\n",
    "        \"neuroticism\": (\"tp04\", \"tp09\"),\n",
    "        \"openness\": (\"tp05\", \"tp10\"),\n",
    "    }\n",
    "    for trait, (a, b) in tp_pairs.items():\n",
    "        if a in df.columns and b in df.columns:\n",
    "            df[a] = pd.to_numeric(df[a], errors=\"coerce\")\n",
    "            df[b] = pd.to_numeric(df[b], errors=\"coerce\")\n",
    "            df[f\"{trait}_diff\"] = (df[a] - df[b]).astype(\"float32\")\n",
    "            df[f\"{trait}_strength\"] = df[f\"{trait}_diff\"].abs().astype(\"float32\")\n",
    "\n",
    "    # 9) 단어 인지: wr_sum / wf_sum / word_credibility\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "    if all(c in df.columns for c in wr_cols):\n",
    "        df[\"wr_sum\"] = df[wr_cols].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    if all(c in df.columns for c in wf_cols):\n",
    "        df[\"wf_sum\"] = df[wf_cols].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    if \"wr_sum\" in df.columns and \"wf_sum\" in df.columns:\n",
    "        df[\"word_credibility\"] = (df[\"wr_sum\"] - df[\"wf_sum\"]).astype(\"float32\")\n",
    "\n",
    "    # 9-1) 단어 인지 구간화 (EDA 기준)\n",
    "    if \"word_credibility\" in df.columns:\n",
    "        df[\"cred_bin\"] = pd.cut(\n",
    "            df[\"word_credibility\"],\n",
    "            bins=[-3, 1, 6, 13],\n",
    "            labels=[\"Low\", \"Mid\", \"High\"]\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# (train에서) cfg 만들기: education 평균 + race/religion top-k\n",
    "# -----------------------------\n",
    "train = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test  = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n",
    "cfg = {}\n",
    "edu = pd.to_numeric(train[\"education\"], errors=\"coerce\").replace(0, np.nan)\n",
    "cfg[\"education_mean\"] = float(edu.mean())\n",
    "\n",
    "cfg[\"race_majors\"] = set(train[\"race\"].value_counts(dropna=True).head(5).index)\n",
    "cfg[\"religion_majors\"] = set(train[\"religion\"].value_counts(dropna=True).head(5).index)\n",
    "\n",
    "# -----------------------------\n",
    "# train/test 동일 파이프라인 적용\n",
    "# -----------------------------\n",
    "df_train_final = build_features(train, cfg=cfg, is_train=True)\n",
    "df_test_final  = build_features(test,  cfg=cfg, is_train=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 모델 입력 컬럼\n",
    "# -----------------------------\n",
    "target = \"voted_bin\"\n",
    "feature_cols = [\n",
    "    \"neg_att\", \"pos_att\", \"neutral_ratio\", \"confident_ratio\",\n",
    "    \"extraversion_diff\", \"extraversion_strength\",\n",
    "    \"agreeableness_diff\", \"agreeableness_strength\",\n",
    "    \"conscientiousness_diff\", \"conscientiousness_strength\",\n",
    "    \"neuroticism_diff\", \"neuroticism_strength\",\n",
    "    \"openness_diff\", \"openness_strength\",\n",
    "    \"wr_sum\", \"wf_sum\", \"word_credibility\",\n",
    "    \"age_group_ord\", \"education\", \"urban_ord\",\n",
    "    \"hand_bin\", \"married_bin\",\n",
    "    \"race_simple\", \"religion_simple\",\n",
    "]\n",
    "\n",
    "cat_cols = [\"race_simple\", \"religion_simple\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 범주형 인코딩 (train 기준) + 결측치 대치 (train 평균 기준)\n",
    "# -----------------------------\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train_final[col] = le.fit_transform(df_train_final[col].astype(str))\n",
    "    df_test_final[col] = le.transform(df_test_final[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "numeric_train = df_train_final[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "numeric_test = df_test_final[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "train_means = numeric_train.mean()\n",
    "\n",
    "df_train_final[num_cols] = numeric_train.fillna(train_means)\n",
    "df_test_final[num_cols] = numeric_test.fillna(train_means)\n",
    "\n",
    "X = df_train_final[feature_cols].values\n",
    "y = df_train_final[target].values\n",
    "\n",
    "print(df_train_final.shape)\n",
    "df_train_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "273e383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urban                         0.007072\n",
       "hand                          0.003536\n",
       "married                       0.002043\n",
       "cred_bin                      0.000176\n",
       "wr_02                         0.000000\n",
       "wr_11                         0.000000\n",
       "wr_10                         0.000000\n",
       "wr_09                         0.000000\n",
       "wr_08                         0.000000\n",
       "wr_07                         0.000000\n",
       "wr_06                         0.000000\n",
       "wr_05                         0.000000\n",
       "wr_04                         0.000000\n",
       "wr_03                         0.000000\n",
       "wf_03                         0.000000\n",
       "wr_01                         0.000000\n",
       "tp04                          0.000000\n",
       "wf_02                         0.000000\n",
       "wf_01                         0.000000\n",
       "voted                         0.000000\n",
       "tp10                          0.000000\n",
       "tp09                          0.000000\n",
       "tp08                          0.000000\n",
       "tp07                          0.000000\n",
       "tp06                          0.000000\n",
       "wr_12                         0.000000\n",
       "wr_13                         0.000000\n",
       "voted_bin                     0.000000\n",
       "agreeableness_diff            0.000000\n",
       "word_credibility              0.000000\n",
       "wf_sum                        0.000000\n",
       "wr_sum                        0.000000\n",
       "openness_strength             0.000000\n",
       "openness_diff                 0.000000\n",
       "neuroticism_strength          0.000000\n",
       "neuroticism_diff              0.000000\n",
       "conscientiousness_strength    0.000000\n",
       "conscientiousness_diff        0.000000\n",
       "agreeableness_strength        0.000000\n",
       "extraversion_strength         0.000000\n",
       "age_group_ord                 0.000000\n",
       "extraversion_diff             0.000000\n",
       "confident_ratio               0.000000\n",
       "neutral_ratio                 0.000000\n",
       "pos_att                       0.000000\n",
       "neg_att                       0.000000\n",
       "religion_simple               0.000000\n",
       "race_simple                   0.000000\n",
       "urban_ord                     0.000000\n",
       "hand_cat                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.isna().mean().sort_values(ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6f48160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "voted_bin\n",
       "1    0.546824\n",
       "0    0.453176\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final[\"voted_bin\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bf8d5",
   "metadata": {},
   "source": [
    "### 2. 결측/분포 체크\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32b75c",
   "metadata": {},
   "source": [
    "### 3. Train/Validation 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "416f5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X = df_train_final[feature_cols].values\n",
    "y = df_train_final[target].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# scale numeric features (train 기준)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57020816",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 모델 정의 (PyTorch MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "66859b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualMLPBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x = x + residual\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class VotingMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, num_blocks=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.in_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[ResidualMLPBlock(hidden_dim, dropout=dropout) for _ in range(num_blocks)])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_proj(x)\n",
    "        x = self.blocks(x)\n",
    "        return self.head(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d902d6",
   "metadata": {},
   "source": [
    "### 5. 학습 세팅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ef00b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingMLP(input_dim=X.shape[1], hidden_dim=512, num_blocks=4, dropout=0.3)\n",
    "\n",
    "# 불균형 보정 (pos_weight)\n",
    "pos_weight = (len(y_train) - y_train.sum()) / (y_train.sum() + 1e-6)\n",
    "pos_weight_t = torch.tensor([pos_weight], dtype=torch.float32)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_t)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=3e-4)\n",
    "\n",
    "# val loss 기준으로 lr 감소\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-5\n",
    ")\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e04ff",
   "metadata": {},
   "source": [
    "### 6. 학습 루프 (20~30 epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c179141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train 0.6333 | val 0.5729\n",
      "Epoch 5 | train 0.5496 | val 0.5498\n",
      "Epoch 10 | train 0.5364 | val 0.5222\n",
      "Epoch 15 | train 0.5284 | val 0.5217\n",
      "Epoch 20 | train 0.5245 | val 0.5199\n",
      "Epoch 25 | train 0.5235 | val 0.5173\n",
      "Epoch 30 | train 0.5209 | val 0.5158\n",
      "Epoch 35 | train 0.5202 | val 0.5150\n",
      "Epoch 40 | train 0.5202 | val 0.5139\n",
      "Epoch 45 | train 0.5195 | val 0.5142\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "best_val = float('inf')\n",
    "patience = 6\n",
    "patience_ctr = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = model(X_train_t)\n",
    "    loss = criterion(logits, y_train_t)\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model(X_val_t)\n",
    "        val_loss = criterion(val_logits, y_val_t)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss.item() < best_val - 1e-4:\n",
    "        best_val = val_loss.item()\n",
    "        patience_ctr = 0\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch} | train {loss.item():.4f} | val {val_loss.item():.4f}\")\n",
    "\n",
    "    if patience_ctr >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# best model restore\n",
    "if 'best_state' in locals():\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e7dc4",
   "metadata": {},
   "source": [
    "### 7. Validation 성능평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4c73e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6916\n",
      "Validation ROC-AUC: 0.7620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_logits = model(X_val_t)\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy().ravel()\n",
    "    val_pred = (val_probs >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_val, val_pred)\n",
    "auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(f\"Validation ROC-AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb73ab",
   "metadata": {},
   "source": [
    "### 8. Test 예측 & 제출 파일 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4a01a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved submission_prob_class2.csv\n"
     ]
    }
   ],
   "source": [
    "# test 예측\n",
    "X_test = df_test_final[feature_cols].values\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model.eval()\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_logits = model(X_test_t)\n",
    "    test_probs = torch.sigmoid(test_logits).cpu().numpy().ravel()\n",
    "\n",
    "# index 기준으로 제출 파일 생성\n",
    "test_pred = pd.DataFrame({\n",
    "    \"index\": df_test_final[\"index\"].values,\n",
    "    \"voted\": test_probs\n",
    "})\n",
    "\n",
    "sub = pd.read_csv(\"../../data/raw/sample_submission.csv\")\n",
    "\n",
    "sub[\"voted\"] = test_probs\n",
    "\n",
    "sub.to_csv(\"submission_01_MLP_v1_baseline.csv\", index=False)\n",
    "print(\"saved submission_01_MLP_v1_baseline.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d189f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index     voted\n",
      "0      0  0.892855\n",
      "1      1  0.781640\n",
      "2      2  0.400190\n",
      "3      3  0.219252\n",
      "4      4  0.664711\n",
      "count    11383.000000\n",
      "mean         0.525277\n",
      "std          0.260404\n",
      "min          0.125817\n",
      "25%          0.310033\n",
      "50%          0.422660\n",
      "75%          0.766478\n",
      "max          0.997147\n",
      "Name: voted, dtype: float64\n",
      "rows: 11383 cols: ['index', 'voted']\n"
     ]
    }
   ],
   "source": [
    "print(sub.head())\n",
    "print(sub[\"voted\"].describe())\n",
    "print(\"rows:\", len(sub), \"cols:\", sub.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dad70b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626353001051943 0.23736469989480577 1.0\n"
     ]
    }
   ],
   "source": [
    "auc_pos1 = roc_auc_score(y_val, val_probs)        # 지금 방식 (pos=1)\n",
    "auc_pos2 = roc_auc_score(1 - y_val, val_probs)    # pos를 반대로 본 것과 동일\n",
    "\n",
    "print(auc_pos1, auc_pos2, auc_pos1 + auc_pos2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ce665",
   "metadata": {},
   "source": [
    "### 전체 흐름 요약\n",
    "1. **데이터 로드**: train/test 원본을 불러옴\n",
    "2. **공통 전처리/파생 변수 생성**: Q_A 태도 요약, Big5 diff/strength, 단어 인지, 인구통계 파생, 범주 단순화\n",
    "3. **결측/분포 확인**: 결측 비율과 클래스 분포 확인\n",
    "4. **학습/검증 분리**: stratified split\n",
    "5. **스케일링**: train 기준 표준화 후 val/test에 동일 적용\n",
    "6. **모델 정의**: Residual MLP\n",
    "7. **학습 세팅**: AdamW, pos_weight, LR scheduler, early stopping\n",
    "8. **학습/평가**: validation accuracy/AUC 확인\n",
    "9. **테스트 예측**: 확률 출력\n",
    "10. **제출 파일 생성**: 확률값을 submission에 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd3a687",
   "metadata": {},
   "source": [
    "### 사용한 모델/학습 요약\n",
    "- 모델: VotingMLP (Residual MLP)\n",
    "- 구조: hidden_dim=512, num_blocks=4, dropout=0.3, GELU + LayerNorm\n",
    "- 손실: BCEWithLogitsLoss + pos_weight\n",
    "- 최적화: AdamW (lr=3e-4, weight_decay=3e-4)\n",
    "- 스케줄러: ReduceLROnPlateau (val loss 기준)\n",
    "- 기타: StandardScaler, gradient clipping, early stopping\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}