{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14_Ensemble_FT_MLP_v2 ìš”ì•½\n",
    "\n",
    "- ëª¨ë¸: FT-Transformer + MLP ì•™ìƒë¸” (SEEDS=[42,2024,7777])\n",
    "- í”¼ì²˜: new3 ë²„ì „(ì›ë¬¸í•­ + íŒŒìƒ í˜¼í•©)\n",
    "- í•™ìŠµ/í‰ê°€: KFold 5, seed ì•™ìƒë¸”\n",
    "- ì œì¶œíŒŒì¼: submission_14_Ensemble_FT_MLP_v2.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80b755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ Device: cpu\n",
      "ğŸŒ± Seeds: [42, 2024, 7777]\n",
      "ğŸ“Š Total: 3 seeds Ã— 2 models Ã— 5 folds = 30 models\n",
      "\n",
      "ğŸ“‚ ë°ì´í„° ë¡œë”©...\n",
      "Train: (45532, 79), Test: (11383, 77)\n",
      "\n",
      "ğŸ“Š í”¼ì²˜: base=13, TE=5, ì´=18\n",
      "\n",
      "============================================================\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "############################################################\n",
      "ğŸŒ± SEED 1/3 (seed=42)\n",
      "############################################################\n",
      "\n",
      "  ğŸ“‚ Fold 1/5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 420\u001b[39m\n\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_auc\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 354\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# MLP\u001b[39;00m\n\u001b[32m    353\u001b[39m mlp = MLP(n_feat, hidden_dims=[\u001b[32m256\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m64\u001b[39m], dropout=\u001b[32m0.3\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m mlp, auc_mlp = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m all_aucs[\u001b[33m'\u001b[39m\u001b[33mmlp\u001b[39m\u001b[33m'\u001b[39m].append(auc_mlp)\n\u001b[32m    357\u001b[39m seed_oof_mlp[va_idx] = predict(mlp, va_loader, DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 238\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, val_y, device, lr)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m         x = batch[\u001b[32m0\u001b[39m].to(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m(device)\n\u001b[32m    239\u001b[39m         preds.append(torch.sigmoid(model(x)).cpu().numpy())\n\u001b[32m    241\u001b[39m preds = np.concatenate(preds).ravel()\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ğŸ¯ íˆ¬í‘œ ì˜ˆì¸¡ ìµœì¢… ëª¨ë¸ v7\n",
    "==========================\n",
    "ê²€ì¦ëœ 18ê°œ í”¼ì²˜ (Permutation Importance ê¸°ë°˜)\n",
    "- Target Encodingì´ í•µì‹¬ (84% ì¤‘ìš”ë„)\n",
    "- MLP + FT-Transformer ì•™ìƒë¸”\n",
    "- 3 Seeds\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "SEEDS = [42, 2024, 7777]\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 60\n",
    "PATIENCE = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ Device: {DEVICE}\")\n",
    "print(f\"ğŸŒ± Seeds: {SEEDS}\")\n",
    "print(f\"ğŸ“Š Total: {len(SEEDS)} seeds Ã— 2 models Ã— {N_FOLDS} folds = {len(SEEDS)*2*N_FOLDS} models\")\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“‚ ë°ì´í„° ë¡œë”©...\")\n",
    "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test_raw = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    for col in ['education', 'married', 'urban', 'engnat']:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_base_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # age_ord\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    \n",
    "    # Interaction\n",
    "    df['age_edu'] = df['age_ord'] * df['education']\n",
    "    df['is_teenager'] = (df['age_ord'] == 1).astype(int)\n",
    "    df['teen_low_edu'] = df['is_teenager'] * (df['education'] <= 2).astype(float)\n",
    "    \n",
    "    # WR sum\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    df['wr_sum'] = df[wr_cols].sum(axis=1)\n",
    "    \n",
    "    # ë³µí•© ì¹´í…Œê³ ë¦¬ (TEìš©)\n",
    "    df['age_edu_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str)\n",
    "    df['age_edu_mar_cat'] = df['age_group'].astype(str) + '_' + df['education'].astype(str) + '_' + df['married'].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Target Encoding (CV leak ë°©ì§€)\n",
    "# ============================================================\n",
    "def target_encode(train_df, val_df, test_df, col, target_col, smoothing=10):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    agg = train_df.groupby(col)[target_col].agg(['mean', 'count'])\n",
    "    agg['te'] = (agg['count'] * agg['mean'] + smoothing * global_mean) / (agg['count'] + smoothing)\n",
    "    te_map = agg['te'].to_dict()\n",
    "    \n",
    "    return (\n",
    "        train_df[col].map(te_map).fillna(global_mean).values,\n",
    "        val_df[col].map(te_map).fillna(global_mean).values,\n",
    "        test_df[col].map(te_map).fillna(global_mean).values\n",
    "    )\n",
    "\n",
    "\n",
    "def create_te_features(train_df, val_df, test_df):\n",
    "    te = {'train': {}, 'val': {}, 'test': {}}\n",
    "    \n",
    "    # ë‹¨ì¼ TE\n",
    "    for col, sm in [('age_group', 10), ('race', 10), ('religion', 10)]:\n",
    "        tr, va, ts = target_encode(train_df, val_df, test_df, col, 'voted_bin', sm)\n",
    "        te['train'][f'{col}_te'] = tr\n",
    "        te['val'][f'{col}_te'] = va\n",
    "        te['test'][f'{col}_te'] = ts\n",
    "    \n",
    "    # ë³µí•© TE\n",
    "    for col, sm in [('age_edu_cat', 5), ('age_edu_mar_cat', 3)]:\n",
    "        tr, va, ts = target_encode(train_df, val_df, test_df, col, 'voted_bin', sm)\n",
    "        te['train'][f'{col}_te'] = tr\n",
    "        te['val'][f'{col}_te'] = va\n",
    "        te['test'][f'{col}_te'] = ts\n",
    "    \n",
    "    return te\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (ê²€ì¦ëœ 18ê°œ)\n",
    "# ============================================================\n",
    "base_features = [\n",
    "    # ì›ë³¸ (5ê°œ)\n",
    "    'age_ord', 'education', 'married', 'urban', 'engnat',\n",
    "    # Interaction (4ê°œ)\n",
    "    'age_edu', 'is_teenager', 'teen_low_edu', 'wr_sum',\n",
    "    # TP ìƒìœ„ (4ê°œ)\n",
    "    'tp07', 'tp06', 'tp04', 'tp03',\n",
    "]\n",
    "\n",
    "te_features = [\n",
    "    'age_group_te', 'race_te', 'religion_te',\n",
    "    'age_edu_cat_te', 'age_edu_mar_cat_te',\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“Š í”¼ì²˜: base={len(base_features)}, TE={len(te_features)}, ì´={len(base_features)+len(te_features)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset & Models\n",
    "# ============================================================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev, h),\n",
    "                nn.BatchNorm1d(h),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_token=64, n_layers=2, n_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(1, d_token)\n",
    "        self.cls = nn.Parameter(torch.randn(1, 1, d_token) * 0.02)\n",
    "        \n",
    "        encoder = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token, nhead=n_heads, dim_feedforward=d_token*4,\n",
    "            dropout=dropout, activation='gelu', batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_token),\n",
    "            nn.Linear(d_token, 1)\n",
    "        )\n",
    "        self.input_dim = input_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, features) -> (batch, features, d_token)\n",
    "        x = x.unsqueeze(-1)  # (batch, features, 1)\n",
    "        x = self.embed(x)     # (batch, features, d_token)\n",
    "        \n",
    "        cls = self.cls.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = self.transformer(x)\n",
    "        return self.head(x[:, 0])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# í•™ìŠµ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def train_model(model, train_loader, val_loader, val_y, device, lr=1e-3):\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10)\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "                preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "        \n",
    "        preds = np.concatenate(preds).ravel()\n",
    "        auc = roc_auc_score(val_y, preds)\n",
    "        \n",
    "        if auc > best_auc + 1e-5:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        if no_improve >= PATIENCE:\n",
    "            break\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, best_auc\n",
    "\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "            preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ë©”ì¸\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš€ í•™ìŠµ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train_clean = preprocess(train_raw)\n",
    "    test_clean = preprocess(test_raw)\n",
    "    \n",
    "    train_fe = build_base_features(train_clean)\n",
    "    test_fe = build_base_features(test_clean)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    oof_mlp = np.zeros(len(train_fe))\n",
    "    oof_ft = np.zeros(len(train_fe))\n",
    "    test_mlp = np.zeros(len(test_fe))\n",
    "    test_ft = np.zeros(len(test_fe))\n",
    "    \n",
    "    all_aucs = {'mlp': [], 'ft': []}\n",
    "    \n",
    "    for seed_idx, seed in enumerate(SEEDS):\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"ğŸŒ± SEED {seed_idx+1}/{len(SEEDS)} (seed={seed})\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        set_seed(seed)\n",
    "        \n",
    "        seed_oof_mlp = np.zeros(len(train_fe))\n",
    "        seed_oof_ft = np.zeros(len(train_fe))\n",
    "        seed_test_mlp = np.zeros(len(test_fe))\n",
    "        seed_test_ft = np.zeros(len(test_fe))\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "        \n",
    "        for fold, (tr_idx, va_idx) in enumerate(skf.split(train_fe, train_fe[\"voted_bin\"])):\n",
    "            print(f\"\\n  ğŸ“‚ Fold {fold+1}/{N_FOLDS}\")\n",
    "            \n",
    "            tr_df = train_fe.iloc[tr_idx].reset_index(drop=True)\n",
    "            va_df = train_fe.iloc[va_idx].reset_index(drop=True)\n",
    "            ts_df = test_fe.copy()\n",
    "            \n",
    "            # Target Encoding\n",
    "            te = create_te_features(tr_df, va_df, ts_df)\n",
    "            \n",
    "            # í”¼ì²˜ í•©ì¹˜ê¸°\n",
    "            X_tr = tr_df[base_features].copy()\n",
    "            X_va = va_df[base_features].copy()\n",
    "            X_ts = ts_df[base_features].copy()\n",
    "            \n",
    "            for te_name in te_features:\n",
    "                X_tr[te_name] = te['train'][te_name]\n",
    "                X_va[te_name] = te['val'][te_name]\n",
    "                X_ts[te_name] = te['test'][te_name]\n",
    "            \n",
    "            # NaN ì²˜ë¦¬\n",
    "            for col in X_tr.columns:\n",
    "                med = X_tr[col].median()\n",
    "                X_tr[col] = X_tr[col].fillna(med)\n",
    "                X_va[col] = X_va[col].fillna(med)\n",
    "                X_ts[col] = X_ts[col].fillna(med)\n",
    "            \n",
    "            # ìŠ¤ì¼€ì¼ë§\n",
    "            scaler = StandardScaler()\n",
    "            X_tr_s = scaler.fit_transform(X_tr)\n",
    "            X_va_s = scaler.transform(X_va)\n",
    "            X_ts_s = scaler.transform(X_ts)\n",
    "            \n",
    "            y_tr = tr_df[\"voted_bin\"].values\n",
    "            y_va = va_df[\"voted_bin\"].values\n",
    "            \n",
    "            # DataLoader\n",
    "            tr_ds = TabDataset(X_tr_s, y_tr)\n",
    "            va_ds = TabDataset(X_va_s, y_va)\n",
    "            ts_ds = TabDataset(X_ts_s)\n",
    "            \n",
    "            tr_loader = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "            va_loader = DataLoader(va_ds, batch_size=BATCH_SIZE)\n",
    "            ts_loader = DataLoader(ts_ds, batch_size=BATCH_SIZE)\n",
    "            \n",
    "            n_feat = X_tr_s.shape[1]\n",
    "            \n",
    "            # MLP\n",
    "            mlp = MLP(n_feat, hidden_dims=[256, 128, 64], dropout=0.3)\n",
    "            mlp, auc_mlp = train_model(mlp, tr_loader, va_loader, y_va, DEVICE, lr=1e-3)\n",
    "            all_aucs['mlp'].append(auc_mlp)\n",
    "            \n",
    "            seed_oof_mlp[va_idx] = predict(mlp, va_loader, DEVICE)\n",
    "            seed_test_mlp += predict(mlp, ts_loader, DEVICE) / N_FOLDS\n",
    "            \n",
    "            # FT-Transformer\n",
    "            ft = FTTransformer(n_feat, d_token=64, n_layers=2, n_heads=4, dropout=0.2)\n",
    "            ft, auc_ft = train_model(ft, tr_loader, va_loader, y_va, DEVICE, lr=5e-4)\n",
    "            all_aucs['ft'].append(auc_ft)\n",
    "            \n",
    "            seed_oof_ft[va_idx] = predict(ft, va_loader, DEVICE)\n",
    "            seed_test_ft += predict(ft, ts_loader, DEVICE) / N_FOLDS\n",
    "            \n",
    "            print(f\"     MLP: {auc_mlp:.5f}, FT: {auc_ft:.5f}\")\n",
    "        \n",
    "        # Seed í‰ê· \n",
    "        oof_mlp += seed_oof_mlp / len(SEEDS)\n",
    "        oof_ft += seed_oof_ft / len(SEEDS)\n",
    "        test_mlp += seed_test_mlp / len(SEEDS)\n",
    "        test_ft += seed_test_ft / len(SEEDS)\n",
    "    \n",
    "    # ============================================\n",
    "    # ìµœì¢… ê²°ê³¼\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¯ ìµœì¢… ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    auc_mlp = roc_auc_score(train_fe[\"voted_bin\"], oof_mlp)\n",
    "    auc_ft = roc_auc_score(train_fe[\"voted_bin\"], oof_ft)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š MLP OOF: {auc_mlp:.5f} (mean: {np.mean(all_aucs['mlp']):.5f})\")\n",
    "    print(f\"ğŸ“Š FT OOF:  {auc_ft:.5f} (mean: {np.mean(all_aucs['ft']):.5f})\")\n",
    "    \n",
    "    # ìµœì  ê°€ì¤‘ì¹˜ íƒìƒ‰\n",
    "    best_w, best_auc = 0.5, 0\n",
    "    for w in np.arange(0.2, 0.8, 0.05):\n",
    "        blend = w * oof_mlp + (1-w) * oof_ft\n",
    "        auc = roc_auc_score(train_fe[\"voted_bin\"], blend)\n",
    "        if auc > best_auc:\n",
    "            best_w, best_auc = w, auc\n",
    "    \n",
    "    print(f\"\\nğŸ† ìµœì  ì•™ìƒë¸” (MLP:{best_w:.2f} + FT:{1-best_w:.2f}): {best_auc:.5f}\")\n",
    "    \n",
    "    # ìµœì¢… ì˜ˆì¸¡\n",
    "    final = best_w * test_mlp + (1-best_w) * test_ft\n",
    "    \n",
    "    # ì €ì¥\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else range(len(test_raw)),\n",
    "        \"voted\": final\n",
    "    })\n",
    "    sub.to_csv(\"submission_14_Ensemble_FT_MLP_v2_mlp.csv\", index=False)\n",
    "    \n",
    "    # ê°œë³„ë„ ì €ì¥\n",
    "    pd.DataFrame({\"index\": sub[\"index\"], \"voted\": test_mlp}).to_csv(\"submission_14_Ensemble_FT_MLP_v2_mlp.csv\", index=False)\n",
    "    pd.DataFrame({\"index\": sub[\"index\"], \"voted\": test_ft}).to_csv(\"submission_14_Ensemble_FT_MLP_v2_mlp.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ì €ì¥: submission_.csv\")\n",
    "    print(f\"   ì˜ˆì¸¡ ë²”ìœ„: [{final.min():.4f}, {final.max():.4f}]\")\n",
    "    \n",
    "    return best_auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a90082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}