{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f86640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 0. Setup\n",
    "# =========================================\n",
    "import os, gc, random, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "TRAIN_PATH = \"/content/vote_ai/train.csv\"\n",
    "TEST_PATH  = \"/content/vote_ai/test_x.csv\"\n",
    "assert os.path.exists(TRAIN_PATH), f\"Missing: {TRAIN_PATH}\"\n",
    "assert os.path.exists(TEST_PATH),  f\"Missing: {TEST_PATH}\"\n",
    "\n",
    "SEED = 42\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from string import ascii_lowercase\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "TRAIN_PATH = \"/content/vote_ai/train.csv\"     # 네 코랩에 맞춘 경로\n",
    "TEST_PATH  = \"/content/vote_ai/test_x.csv\"\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "N_FOLDS = 7\n",
    "N_REPEAT = 3\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "seed_everything(SEED)\n",
    "\n",
    "# =========================\n",
    "# Load\n",
    "# =========================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train[\"voted_bin\"] = (train[\"voted\"] == 2).astype(int).values\n",
    "y = train[\"voted_bin\"].astype(np.float32).values\n",
    "\n",
    "# =========================\n",
    "# Feature Engineering (Rank1-lite, 안전버전)\n",
    "#  - flip 공개문항만 (secret flip은 데이터/정의 불확실로 일단 제외)\n",
    "#  - delay\n",
    "#  - Mach features\n",
    "#  - categorical dummies\n",
    "#  - QE 원본은 drop (delay로 요약)\n",
    "# =========================\n",
    "def fe_rank1_safe(train_df, test_df):\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    dataset = [train_df, test_df]\n",
    "\n",
    "    qs = list(ascii_lowercase)[:20]\n",
    "    A_cols = [f\"Q{q}A\" for q in qs]\n",
    "    E_cols = [f\"Q{q}E\" for q in qs]\n",
    "\n",
    "    # 1) flip 공개문항(1등이 자주 쓰는 subset)\n",
    "    flipping_columns = [\"QeA\",\"QfA\",\"QkA\",\"QqA\",\"QrA\"]\n",
    "    for df in dataset:\n",
    "        for c in flipping_columns:\n",
    "            if c in df.columns:\n",
    "                # 0/NaN은 그대로 두고 1~5만 flip\n",
    "                df[c] = np.where(df[c].between(1,5), 6 - df[c], df[c])\n",
    "\n",
    "    # 2) Mach-like features\n",
    "    for df in dataset:\n",
    "        df[\"T\"] = df[\"QcA\"] - df[\"QfA\"] + df[\"QoA\"] - df[\"QrA\"] + df[\"QsA\"]\n",
    "        df[\"V\"] = df[\"QbA\"] - df[\"QeA\"] + df[\"QhA\"] + df[\"QjA\"] + df[\"QmA\"] - df[\"QqA\"]\n",
    "        df[\"M\"] = -df[\"QkA\"]\n",
    "        df[\"Mach_score\"] = df[A_cols].replace(0, np.nan).mean(axis=1)\n",
    "\n",
    "    # 3) delay\n",
    "    for df in dataset:\n",
    "        e = df[E_cols].clip(lower=100, upper=60000)  # 너가 기존에 하던 클립 반영\n",
    "        df[\"delay_sum\"] = e.sum(axis=1)\n",
    "        df[\"delay\"] = np.power(df[\"delay_sum\"].clip(lower=0), 1/10)\n",
    "\n",
    "    # 4) tp (기본 diff만, 1등처럼 뒤집기는 일단 보류)\n",
    "    tps = [f\"tp{i:02d}\" for i in range(1,11)]\n",
    "    for df in dataset:\n",
    "        for c in tps:\n",
    "            df.loc[df[c] == 0, c] = np.nan\n",
    "        df[\"Ex\"]  = df[\"tp01\"] - df[\"tp06\"]\n",
    "        df[\"Ag\"]  = df[\"tp07\"] - df[\"tp02\"]\n",
    "        df[\"Con\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "        df[\"Es\"]  = df[\"tp09\"] - df[\"tp04\"]\n",
    "        df[\"Op\"]  = df[\"tp05\"] - df[\"tp10\"]\n",
    "\n",
    "    # 5) categorical -> string\n",
    "    cat_cols = [\"education\",\"engnat\",\"married\",\"urban\",\"age_group\",\"gender\",\"race\",\"religion\",\"hand\"]\n",
    "    for df in dataset:\n",
    "        for c in cat_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(str)\n",
    "\n",
    "    # 6) drop QE 원본, index\n",
    "    drop_cols = E_cols + [\"index\"]\n",
    "    for df in dataset:\n",
    "        for c in drop_cols:\n",
    "            if c in df.columns:\n",
    "                df.drop(columns=[c], inplace=True)\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"voted\", \"voted_bin\"])\n",
    "    X_test  = test_df.copy()\n",
    "\n",
    "    X_train = pd.get_dummies(X_train)\n",
    "    X_test  = pd.get_dummies(X_test)\n",
    "    X_train, X_test = X_train.align(X_test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "    # ✅ inf/nan 정리\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "    X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    med = X_train.median()\n",
    "    X_train = X_train.fillna(med)\n",
    "    X_test  = X_test.fillna(med)\n",
    "\n",
    "    # ✅ 스케일링 (NN 필수)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.values).astype(np.float32)\n",
    "    X_test  = scaler.transform(X_test.values).astype(np.float32)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "X, X_test = fe_rank1_safe(train, test)\n",
    "print(\"X:\", X.shape, \"X_test:\", X_test.shape)\n",
    "print(\"nan ratio:\", np.isnan(X).mean(), \"inf ratio:\", np.isinf(X).mean())\n",
    "\n",
    "# =========================\n",
    "# Model (강한 MLP: Residual-ish)\n",
    "# =========================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=256, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden)\n",
    "        self.out = nn.Linear(hidden, 1)\n",
    "        self.act = nn.SiLU()\n",
    "        self.dp = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dp(self.act(self.bn1(self.fc1(x))))\n",
    "        h = self.dp(self.act(self.bn2(self.fc2(x))))\n",
    "        x = x + h  # residual\n",
    "        return self.out(x).squeeze(1)\n",
    "\n",
    "def train_fold(model, tr_loader, va_loader, y_tr_np, y_va_np):\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # ✅ pos_weight는 train 기준\n",
    "    pos = float(y_tr_np.mean())\n",
    "    pos_weight = torch.tensor([(1-pos)/(pos+1e-6)], device=DEVICE)\n",
    "    crit = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "\n",
    "    best_auc, best_state = -1, None\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for xb, yb in tr_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "        sched.step()\n",
    "\n",
    "        model.eval()\n",
    "        pred = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in va_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                pred.append(torch.sigmoid(model(xb)).detach().cpu().numpy())\n",
    "        pred = np.concatenate(pred)\n",
    "        auc = roc_auc_score(y_va_np, pred)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return best_auc, model\n",
    "\n",
    "# =========================\n",
    "# CV + Repeat\n",
    "# =========================\n",
    "X_t = torch.tensor(X, dtype=torch.float32)\n",
    "y_t = torch.tensor(y, dtype=torch.float32)\n",
    "Xtest_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "oof = np.zeros(len(X), dtype=np.float32)\n",
    "test_pred = np.zeros(len(X_test), dtype=np.float32)\n",
    "auc_list = []\n",
    "\n",
    "for rep in range(N_REPEAT):\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED + rep)\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, y_tr = X_t[tr_idx], y_t[tr_idx]\n",
    "        X_va, y_va = X_t[va_idx], y_t[va_idx]\n",
    "\n",
    "        tr_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True,\n",
    "                               drop_last=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "        va_loader = DataLoader(TensorDataset(X_va, y_va), batch_size=BATCH_SIZE, shuffle=False,\n",
    "                               drop_last=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "        model = MLP(in_dim=X.shape[1], hidden=256, dropout=0.25)\n",
    "        auc, model = train_fold(model, tr_loader, va_loader, y_tr.numpy(), y_va.numpy())\n",
    "        auc_list.append(auc)\n",
    "        print(f\"[rep {rep+1}/{N_REPEAT}][fold {fold}/{N_FOLDS}] AUC={auc:.5f}\")\n",
    "\n",
    "        # OOF\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_va = torch.sigmoid(model(X_va.to(DEVICE))).detach().cpu().numpy()\n",
    "            oof[va_idx] += pred_va / N_REPEAT\n",
    "\n",
    "        # TEST\n",
    "        te_loader = DataLoader(TensorDataset(Xtest_t, torch.zeros(len(Xtest_t))), batch_size=BATCH_SIZE,\n",
    "                               shuffle=False, drop_last=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "        pred_ts = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in te_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                pred_ts.append(torch.sigmoid(model(xb)).detach().cpu().numpy())\n",
    "        pred_ts = np.concatenate(pred_ts)\n",
    "        test_pred += pred_ts / (N_REPEAT * N_FOLDS)\n",
    "\n",
    "oof_auc = roc_auc_score(y, oof)\n",
    "print(\"\\n====================\")\n",
    "print(\"OOF AUC:\", float(oof_auc))\n",
    "print(\"Fold mean:\", float(np.mean(auc_list)))\n",
    "print(\"====================\\n\")\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"index\": test[\"index\"] if \"index\" in test.columns else np.arange(len(test)),\n",
    "    \"voted\": test_pred\n",
    "})\n",
    "sub.to_csv(\"submission_nn_rank1_safe.csv\", index=False)\n",
    "print(\"saved -> submission_nn_rank1_safe.csv\")\n",
    "print(\"pred range:\", float(test_pred.min()), float(test_pred.max()))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
