{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3931ee13",
   "metadata": {},
   "source": [
    "# 15_MLP_v4_new3 ÏöîÏïΩ\n",
    "\n",
    "- Î™®Îç∏: MLP Îã®ÎèÖ\n",
    "- ÌîºÏ≤ò: new3 Í∏∞Î∞ò Ï∂ïÏÜå Î≤ÑÏ†Ñ\n",
    "- ÌïôÏäµ/ÌèâÍ∞Ä: Îã®Ïùº/Í∞ÑÎã® Ïã§Ìóò\n",
    "- Ï†úÏ∂úÌååÏùº: submission_15_MLP_v4_new3.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8bf161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎî©...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:29 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       4.80 GB / 16.00 GB (30.0%)\n",
      "Disk Space Avail:   220.09 GB / 460.43 GB (47.8%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=10, num_bag_sets=2\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~10x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 5400s of the 21600s of remaining time (25%).\n",
      "DyStack: Disabling memory safe fit mode in DyStack because GPUs were detected and num_gpus='auto' (GPUs cannot be used in memory safe fit mode). If you want to use memory safe fit mode, manually set `num_gpus=0`.\n",
      "Running DyStack sub-fit ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (45532, 79), Test: (11383, 77)\n",
      "\n",
      "üìä ÌîºÏ≤ò: 17Í∞ú\n",
      "üìä Train: (45532, 18), Test: (11383, 17)\n",
      "\n",
      "============================================================\n",
      "üöÄ AutoGluon ÌïôÏäµ ÏãúÏûë (Îî•Îü¨Îãù Only)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 5400s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/autogluon_models/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    40472\n",
      "Train Data Columns: 17\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4936.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.74 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 10 | ['education', 'married', 'urban', 'engnat', 'age_edu', ...]\n",
      "\t\t('int', [])    :  3 | ['age_ord', 'is_teenager', 'wr_sum']\n",
      "\t\t('object', []) :  4 | ['age_group', 'race', 'religion', 'gender']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['age_group', 'race', 'religion']\n",
      "\t\t('float', [])     : 9 | ['education', 'married', 'urban', 'engnat', 'age_edu', ...]\n",
      "\t\t('int', [])       : 2 | ['age_ord', 'wr_sum']\n",
      "\t\t('int', ['bool']) : 3 | ['is_teenager', 'teen_low_edu', 'gender']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.63 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 100, 'learning_rate': 0.001, 'dropout_prob': 0.3}],\n",
      "\t'FASTAI': [{}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3599.02s of the 5399.87s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=0.89%)\n",
      "\t0.7674\t = Validation score   (roc_auc)\n",
      "\t57.42s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3538.64s of the 5339.49s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=0.60%)\n",
      "\t0.767\t = Validation score   (roc_auc)\n",
      "\t79.15s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 5257.52s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.3 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'NeuralNetTorch_BAG_L1': 0.5}\n",
      "\t0.7689\t = Validation score   (roc_auc)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 2 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5257.26s of the 5257.25s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.09%)\n",
      "\t0.7681\t = Validation score   (roc_auc)\n",
      "\t58.49s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 5195.99s of the 5195.98s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\t0.7671\t = Validation score   (roc_auc)\n",
      "\t66.38s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 525.73s of the 5126.66s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.364, 'NeuralNetTorch_BAG_L1': 0.364, 'NeuralNetFastAI_BAG_L2': 0.227, 'NeuralNetTorch_BAG_L2': 0.045}\n",
      "\t0.769\t = Validation score   (roc_auc)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 273.85s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1384.7 rows/s (4048 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.1 GB\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t11.52s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.1 GB\n",
      "\t9.58s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'NeuralNetTorch_BAG_L1': 0.5}\n",
      "\t0.24s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\tStopping at the best epoch learned earlier - 9.\n",
      "\t9.72s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\t6.04s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.364, 'NeuralNetTorch_BAG_L1': 0.364, 'NeuralNetFastAI_BAG_L2': 0.227, 'NeuralNetTorch_BAG_L2': 0.045}\n",
      "\t0.49s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 36.98s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/autogluon_models/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                         model  score_holdout  score_val eval_metric  pred_time_test pred_time_val   fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L2_FULL       0.775834   0.768876     roc_auc        0.071420          None  21.338595                 0.001314                   None           0.243083            2       True          3\n",
      "1     WeightedEnsemble_L3_FULL       0.775815   0.768969     roc_auc        0.136688          None  37.339683                 0.001265                   None           0.486296            3       True          6\n",
      "2   NeuralNetTorch_BAG_L2_FULL       0.775231   0.767110     roc_auc        0.092411          None  27.138060                 0.022305                   None           6.042548            2       True          5\n",
      "3  NeuralNetFastAI_BAG_L2_FULL       0.774773   0.768086     roc_auc        0.113118          None  30.810839                 0.043012                   None           9.715327            2       True          4\n",
      "4  NeuralNetFastAI_BAG_L1_FULL       0.773453   0.767355     roc_auc        0.046994          None  11.517827                 0.046994                   None          11.517827            1       True          1\n",
      "5   NeuralNetTorch_BAG_L1_FULL       0.773447   0.767048     roc_auc        0.023112          None   9.577685                 0.023112                   None           9.577685            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t311s\t = DyStack   runtime |\t21289s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 21289s\n",
      "AutoGluon will save models to \"/Users/admin/vote_AI/notebooks/hyemin/autogluon_models\"\n",
      "Train Data Rows:    45532\n",
      "Train Data Columns: 17\n",
      "Label Column:       voted_bin\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4432.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.45 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 10 | ['education', 'married', 'urban', 'engnat', 'age_edu', ...]\n",
      "\t\t('int', [])    :  3 | ['age_ord', 'is_teenager', 'wr_sum']\n",
      "\t\t('object', []) :  4 | ['age_group', 'race', 'religion', 'gender']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['age_group', 'race', 'religion']\n",
      "\t\t('float', [])     : 9 | ['education', 'married', 'urban', 'engnat', 'age_edu', ...]\n",
      "\t\t('int', [])       : 2 | ['age_ord', 'wr_sum']\n",
      "\t\t('int', ['bool']) : 3 | ['is_teenager', 'teen_low_edu', 'gender']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.08 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 100, 'learning_rate': 0.001, 'dropout_prob': 0.3}],\n",
      "\t'FASTAI': [{}],\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 21288.39s of the 21288.39s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=1.02%)\n",
      "\t0.7685\t = Validation score   (roc_auc)\n",
      "\t72.2s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 21212.25s of the 21212.25s of remaining time.\n",
      "\tFitting 20 child models (S1F1 - S2F10) | Fitting with ParallelLocalFoldFittingStrategy (10 workers, per: cpus=1, gpus=0, memory=0.60%)\n",
      "\t0.7684\t = Validation score   (roc_auc)\n",
      "\t106.57s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2128.84s of the 21102.74s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.529, 'NeuralNetFastAI_BAG_L1': 0.471}\n",
      "\t0.7699\t = Validation score   (roc_auc)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 186.09s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2514.7 rows/s (4554 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.2 GB\n",
      "\tStopping at the best epoch learned earlier - 11.\n",
      "\t11.96s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting 1 model on all data | Fitting with cpus=10, gpus=0, mem=0.0/4.4 GB\n",
      "\t10.36s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.529, 'NeuralNetFastAI_BAG_L1': 0.471}\n",
      "\t0.27s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 22.38s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/admin/vote_AI/notebooks/hyemin/autogluon_models\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä ÌïôÏäµ Í≤∞Í≥º\n",
      "============================================================\n",
      "\n",
      "Î™®Îç∏ Î¶¨ÎçîÎ≥¥Îìú:\n",
      "                         model  score_val eval_metric  pred_time_val  \\\n",
      "0          WeightedEnsemble_L2   0.769921     roc_auc       1.815608   \n",
      "1       NeuralNetFastAI_BAG_L1   0.768468     roc_auc       1.077892   \n",
      "2        NeuralNetTorch_BAG_L1   0.768362     roc_auc       0.732504   \n",
      "3     WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN   \n",
      "4   NeuralNetTorch_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
      "5  NeuralNetFastAI_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  179.039301                0.005212           0.271461            2   \n",
      "1   72.199208                1.077892          72.199208            1   \n",
      "2  106.568632                0.732504         106.568632            1   \n",
      "3   22.589385                     NaN           0.271461            2   \n",
      "4   10.361822                     NaN          10.361822            1   \n",
      "5   11.956102                     NaN          11.956102            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0      False          3  \n",
      "1      False          1  \n",
      "2      False          2  \n",
      "3       True          6  \n",
      "4       True          5  \n",
      "5       True          4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 17 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best CV Score: {'roc_auc': np.float64(0.7796167167899445), 'accuracy': 0.7060309233066854, 'balanced_accuracy': np.float64(0.712470588443225), 'mcc': 0.4251088557939523, 'f1': 0.7054292568058276, 'precision': 0.78024438927024, 'recall': 0.6437063217929151}\n",
      "\n",
      "============================================================\n",
      "üíæ ÏòàÏ∏° & Ï†ÄÏû•\n",
      "============================================================\n",
      "\n",
      "üíæ Ï†ÄÏû•: submission_20_new3_test.csv\n",
      "   ÏòàÏ∏° Î≤îÏúÑ: [0.1509, 0.9986]\n",
      "   ÏòàÏ∏° ÌèâÍ∑†: 0.5566\n",
      "\n",
      "üìä Feature Importance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t6.17s\t= Expected runtime (1.23s per shuffle set)\n",
      "\t4.84s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              importance    stddev   p_value  n  p99_high   p99_low\n",
      "education       0.031160  0.006127  0.000170  5  0.043775  0.018546\n",
      "race            0.025484  0.002198  0.000007  5  0.030009  0.020959\n",
      "religion        0.013782  0.001424  0.000013  5  0.016714  0.010849\n",
      "engnat          0.011540  0.000879  0.000004  5  0.013349  0.009731\n",
      "age_edu         0.010784  0.003428  0.001077  5  0.017843  0.003724\n",
      "married         0.009932  0.002201  0.000271  5  0.014465  0.005400\n",
      "age_ord         0.007348  0.001379  0.000142  5  0.010189  0.004508\n",
      "wr_sum          0.005398  0.001795  0.001273  5  0.009092  0.001703\n",
      "age_group       0.004696  0.000950  0.000190  5  0.006652  0.002741\n",
      "tp06            0.003408  0.001795  0.006598  5  0.007104 -0.000287\n",
      "is_teenager     0.003310  0.001408  0.003136  5  0.006210  0.000410\n",
      "tp07            0.003297  0.000823  0.000431  5  0.004992  0.001601\n",
      "tp03            0.003104  0.001292  0.002898  5  0.005765  0.000444\n",
      "teen_low_edu    0.002509  0.001801  0.017858  5  0.006217 -0.001200\n",
      "gender          0.002201  0.000652  0.000823  5  0.003543  0.000859\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "üéØ AutoGluon Îî•Îü¨Îãù Only\n",
    "========================\n",
    "- Í≤ÄÏ¶ùÎêú 18Í∞ú ÌîºÏ≤ò ÏÇ¨Ïö©\n",
    "- Tree Î™®Îç∏ Ï†úÏô∏, Îî•Îü¨ÎãùÎßå\n",
    "- ÏûêÎèô ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# AutoGluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# ============================================================\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎî© & Ï†ÑÏ≤òÎ¶¨\n",
    "# ============================================================\n",
    "print(\"üìÇ Îç∞Ïù¥ÌÑ∞ Î°úÎî©...\")\n",
    "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test_raw = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    for col in ['education', 'married', 'urban', 'engnat']:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # age_ord\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    \n",
    "    # Interaction\n",
    "    df['age_edu'] = df['age_ord'] * df['education']\n",
    "    df['is_teenager'] = (df['age_ord'] == 1).astype(int)\n",
    "    df['teen_low_edu'] = df['is_teenager'] * (df['education'] <= 2).astype(float)\n",
    "    \n",
    "    # WR sum\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    df['wr_sum'] = df[wr_cols].sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨ & ÌîºÏ≤ò ÏÉùÏÑ±\n",
    "train = preprocess(train_raw)\n",
    "test = preprocess(test_raw)\n",
    "\n",
    "train = build_features(train)\n",
    "test = build_features(test)\n",
    "\n",
    "# ============================================================\n",
    "# ÌîºÏ≤ò ÏÑ†ÌÉù (Í≤ÄÏ¶ùÎêú 18Í∞ú + Î≤îÏ£ºÌòï)\n",
    "# ============================================================\n",
    "features = [\n",
    "    # ÏõêÎ≥∏ (5Í∞ú)\n",
    "    'age_ord', 'education', 'married', 'urban', 'engnat',\n",
    "    # Interaction (4Í∞ú)\n",
    "    'age_edu', 'is_teenager', 'teen_low_edu', 'wr_sum',\n",
    "    # TP ÏÉÅÏúÑ (4Í∞ú)\n",
    "    'tp07', 'tp06', 'tp04', 'tp03',\n",
    "    # Î≤îÏ£ºÌòï (AutoGluonÏù¥ ÏïåÏïÑÏÑú TE Ìï¥Ï§å)\n",
    "    'age_group', 'race', 'religion', 'gender',\n",
    "]\n",
    "\n",
    "# ÌÉÄÍ≤ü\n",
    "label = 'voted_bin'\n",
    "\n",
    "# ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "train_data = train[features + [label]].copy()\n",
    "test_data = test[features].copy()\n",
    "\n",
    "print(f\"\\nüìä ÌîºÏ≤ò: {len(features)}Í∞ú\")\n",
    "print(f\"üìä Train: {train_data.shape}, Test: {test_data.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# AutoGluon ÌïôÏäµ\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ AutoGluon ÌïôÏäµ ÏãúÏûë (Îî•Îü¨Îãù Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Îî•Îü¨Îãù ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "nn_options = {\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'dropout_prob': 0.3,\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'NN_TORCH': nn_options,  # PyTorch MLP\n",
    "    'FASTAI': {},             # FastAI Neural Net\n",
    "}\n",
    "\n",
    "# Tree Î™®Îç∏ Ï†úÏô∏\n",
    "excluded = ['GBM', 'CAT', 'XGB', 'RF', 'XT', 'KNN', 'LR']\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric='roc_auc',\n",
    "    path='autogluon_models'\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    excluded_model_types=excluded,\n",
    "    presets='high_quality',      # ÌïµÏã¨ Î≥ÄÍ≤Ω\n",
    "    time_limit=3600 * 6,\n",
    "    num_bag_folds=10,            # 5 -> 10\n",
    "    num_bag_sets=2,              # Ï∂îÍ∞Ä (ÏãúÍ∞Ñ Í¥úÏ∞ÆÏúºÎ©¥)\n",
    "    num_stack_levels=1,          # 0 -> 1\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Í≤∞Í≥º ÌôïÏù∏\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ÌïôÏäµ Í≤∞Í≥º\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Î¶¨ÎçîÎ≥¥Îìú\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(\"\\nÎ™®Îç∏ Î¶¨ÎçîÎ≥¥Îìú:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# CV Ï†êÏàò\n",
    "print(f\"\\nüèÜ Best CV Score: {predictor.evaluate(train_data)}\")\n",
    "\n",
    "# ============================================================\n",
    "# ÏòàÏ∏° & Ï†ÄÏû•\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ ÏòàÏ∏° & Ï†ÄÏû•\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ÏòàÏ∏°\n",
    "test_pred = predictor.predict_proba(test_data)\n",
    "\n",
    "# voted_bin=1 (Ìà¨Ìëú ÏïàÌï®)Ïùò ÌôïÎ•†\n",
    "if isinstance(test_pred, pd.DataFrame):\n",
    "    if 1 in test_pred.columns:\n",
    "        pred_proba = test_pred[1].values\n",
    "    else:\n",
    "        pred_proba = test_pred.iloc[:, 1].values\n",
    "else:\n",
    "    pred_proba = test_pred\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "sub = pd.DataFrame({\n",
    "    \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else range(len(test_raw)),\n",
    "    \"voted\": pred_proba\n",
    "})\n",
    "sub.to_csv(\"submission_15_MLP_v4_new3.csv\", index=False)\n",
    "\n",
    "print(f\"\\nüíæ Ï†ÄÏû•: submission_15_MLP_v4_new3.csv\")\n",
    "print(f\"   ÏòàÏ∏° Î≤îÏúÑ: [{pred_proba.min():.4f}, {pred_proba.max():.4f}]\")\n",
    "print(f\"   ÏòàÏ∏° ÌèâÍ∑†: {pred_proba.mean():.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nüìä Feature Importance:\")\n",
    "importance = predictor.feature_importance(train_data)\n",
    "print(importance.head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}