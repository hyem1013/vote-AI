{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb65392",
   "metadata": {},
   "source": [
    "# 09_7th_test 요약\n",
    "\n",
    "- 모델: FT-Transformer + Optuna(가능 시)\n",
    "- 라벨: voted==2 를 양성으로 학습, 제출은 P(voted==2) 확률\n",
    "- 피처: age_group_ord, education, reliability_score, total_time_log, tp_emo, cat: race/religion/age_edu/married_cat\n",
    "- 학습/평가: train/val 8:2 stratified split, StandardScaler + LabelEncoder, ROC-AUC 기준\n",
    "- 제출파일: submission_prob_7th_test.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc125664",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "# 공통 하이퍼파라미터\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de394a11",
   "metadata": {},
   "source": [
    "## 2. 설정값 및 시드 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "PATIENCE = 6\n",
    "OPTUNA_TRIALS = 50  # 필요 시 조절\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa5857",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test_raw  = pd.read_csv(\"../../data/raw/test_x.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134b599",
   "metadata": {},
   "source": [
    "## 4. 피처 생성 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa619b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 공통 전처리/피처 생성 함수\n",
    "# -----------------------------\n",
    "def build_features(df_raw, cfg=None, is_train=True):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # 0) voted -> voted_bin (train only)\n",
    "    if is_train and \"voted\" in df.columns:\n",
    "        df[\"voted_bin\"] = (df[\"voted\"] == 2).astype(int)\n",
    "\n",
    "    # 1) age_group -> ordinal\n",
    "    if \"age_group\" in df.columns:\n",
    "        age_map = {\"10s\":1, \"20s\":2, \"30s\":3, \"40s\":4, \"50s\":5, \"60s\":6, \"+70s\":7}\n",
    "        df[\"age_group_ord\"] = df[\"age_group\"].map(age_map).astype(\"float32\")\n",
    "\n",
    "    # 2) education (0 -> NaN -> train mean)\n",
    "    if \"education\" in df.columns:\n",
    "        df[\"education\"] = pd.to_numeric(df[\"education\"], errors=\"coerce\")\n",
    "        df.loc[df[\"education\"] == 0, \"education\"] = np.nan\n",
    "        if cfg is not None:\n",
    "            df[\"education\"] = df[\"education\"].fillna(cfg[\"education_mean\"])\n",
    "        df[\"education\"] = df[\"education\"].astype(\"float32\")\n",
    "\n",
    "    # 3) familysize (clip + numeric)\n",
    "    if \"familysize\" in df.columns:\n",
    "        df[\"familysize\"] = pd.to_numeric(df[\"familysize\"], errors=\"coerce\")\n",
    "        df[\"familysize\"] = df[\"familysize\"].clip(upper=15).astype(\"float32\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # (A) Machiavellianism: mach_score / mach_std\n",
    "    # -----------------------------\n",
    "    # QaA ~ QtA 전체 사용 (0은 무응답으로 NaN 처리)\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]  # 20개\n",
    "    exist_qa = [c for c in qa_cols if c in df.columns]\n",
    "\n",
    "    # reverse scoring (Gemini v2 가이드)\n",
    "    reverse_cols = ['QaA', 'QdA', 'QgA', 'QiA', 'QlA', 'QnA', 'QpA', 'QrA', 'QtA']\n",
    "    for col in exist_qa:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[df[col] == 0, col] = np.nan\n",
    "        if col in reverse_cols:\n",
    "            df[col] = 6 - df[col]\n",
    "\n",
    "    if len(exist_qa) >= 10:  # 최소한 좀 있어야 의미 있음\n",
    "        df[\"mach_score\"] = df[exist_qa].mean(axis=1).astype(\"float32\")\n",
    "        df[\"mach_std\"]   = df[exist_qa].std(axis=1).astype(\"float32\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # (B) Q_E time: total_time_log\n",
    "    # -----------------------------\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    exist_qe = [c for c in qe_cols if c in df.columns]\n",
    "    for col in exist_qe:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df.loc[df[col] < 0, col] = np.nan\n",
    "        df[col] = np.log1p(df[col].clip(lower=0, upper=1e6))  # log1p + clip\n",
    "\n",
    "    if len(exist_qe) >= 10:\n",
    "        df[\"total_time_log\"] = df[exist_qe].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # (C) Word reliability: reliability_score\n",
    "    # -----------------------------\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    exist_wr = [c for c in wr_cols if c in df.columns]\n",
    "    exist_wf = [c for c in wf_cols if c in df.columns]\n",
    "\n",
    "    for col in exist_wr + exist_wf:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    if len(exist_wr) == 13:\n",
    "        df[\"wr_sum\"] = df[exist_wr].sum(axis=1).astype(\"float32\")\n",
    "    if len(exist_wf) == 3:\n",
    "        df[\"wf_sum\"] = df[exist_wf].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    if \"wr_sum\" in df.columns and \"wf_sum\" in df.columns:\n",
    "        df[\"reliability_score\"] = (df[\"wr_sum\"] - (df[\"wf_sum\"] * 2)).astype(\"float32\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # (D) Big5: tp_extra / tp_agree / tp_cons / tp_emo / tp_open\n",
    "    # -----------------------------\n",
    "    # 7점 척도 역채점: 8 - x\n",
    "    def _num(s): \n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    if \"tp01\" in df.columns and \"tp06\" in df.columns:\n",
    "        df[\"tp_extra\"] = ((_num(df[\"tp01\"]) + (7 - _num(df[\"tp06\"]))) / 2).astype(\"float32\")\n",
    "    if \"tp02\" in df.columns and \"tp07\" in df.columns:\n",
    "        df[\"tp_agree\"] = (((7 - _num(df[\"tp02\"])) + _num(df[\"tp07\"])) / 2).astype(\"float32\")\n",
    "    if \"tp03\" in df.columns and \"tp08\" in df.columns:\n",
    "        df[\"tp_cons\"]  = ((_num(df[\"tp03\"]) + (7 - _num(df[\"tp08\"]))) / 2).astype(\"float32\")\n",
    "    if \"tp04\" in df.columns and \"tp09\" in df.columns:\n",
    "        df[\"tp_emo\"]   = (((7 - _num(df[\"tp04\"])) + _num(df[\"tp09\"])) / 2).astype(\"float32\")\n",
    "    if \"tp05\" in df.columns and \"tp10\" in df.columns:\n",
    "        df[\"tp_open\"]  = ((_num(df[\"tp05\"]) + (7 - _num(df[\"tp10\"]))) / 2).astype(\"float32\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Categorical: race / religion / age_edu / urban / gender / married / hand\n",
    "    # -----------------------------\n",
    "    # married_cat / hand_cat (0 -> NaN -> string)\n",
    "    if \"married\" in df.columns:\n",
    "        df[\"married\"] = pd.to_numeric(df[\"married\"], errors=\"coerce\")\n",
    "        df.loc[df[\"married\"] == 0, \"married\"] = np.nan\n",
    "        df[\"married_cat\"] = df[\"married\"].astype(\"string\")\n",
    "\n",
    "    if \"hand\" in df.columns:\n",
    "        df[\"hand\"] = pd.to_numeric(df[\"hand\"], errors=\"coerce\")\n",
    "        df.loc[df[\"hand\"] == 0, \"hand\"] = np.nan\n",
    "        df[\"hand_cat\"] = df[\"hand\"].astype(\"string\")\n",
    "\n",
    "    # urban_cat / gender_cat: 원본을 카테고리로 유지\n",
    "    if \"urban\" in df.columns:\n",
    "        df[\"urban\"] = pd.to_numeric(df[\"urban\"], errors=\"coerce\")\n",
    "        df.loc[df[\"urban\"] == 0, \"urban\"] = np.nan\n",
    "        df[\"urban_cat\"] = df[\"urban\"].astype(\"string\")\n",
    "\n",
    "    if \"gender\" in df.columns:\n",
    "        df[\"gender\"] = pd.to_numeric(df[\"gender\"], errors=\"coerce\")\n",
    "        df.loc[df[\"gender\"] == 0, \"gender\"] = np.nan\n",
    "        df[\"gender_cat\"] = df[\"gender\"].astype(\"string\")\n",
    "\n",
    "    # age_edu: age_group + \"_\" + education\n",
    "    if \"age_group\" in df.columns and \"education\" in df.columns:\n",
    "        edu_str = df[\"education\"].fillna(-1).round(0).astype(\"int\").astype(str)\n",
    "        df[\"age_edu\"] = df[\"age_group\"].astype(str) + \"_\" + edu_str\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "target = \"voted_bin\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28773f03",
   "metadata": {},
   "source": [
    "## 5. 피처 리스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9447f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    # NUM\n",
    "    \"age_group_ord\", \"education\",\n",
    "    \"reliability_score\", \"total_time_log\", \"tp_emo\",\n",
    "    # CAT\n",
    "    \"race\", \"religion\", \"age_edu\", \"married_cat\",\n",
    "]\n",
    "\n",
    "cat_cols = [\"race\", \"religion\", \"age_edu\", \"married_cat\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7165b",
   "metadata": {},
   "source": [
    "## 6. 전처리 함수 (인코딩/스케일링)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd24fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_cat(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    s = s.fillna(\"__MISSING__\")\n",
    "    s = s.replace({\"<NA>\": \"__MISSING__\", \"nan\": \"__MISSING__\", \"NaN\": \"__MISSING__\"})\n",
    "    return s\n",
    "\n",
    "\n",
    "def _fit_label_encoders(df_train, cat_cols):\n",
    "    encoders = {}\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        s = _normalize_cat(df_train[col])\n",
    "        # __MISSING__ 토큰 보장\n",
    "        if \"__MISSING__\" not in s.unique():\n",
    "            s = pd.concat([s, pd.Series([\"__MISSING__\"])], ignore_index=True)\n",
    "        le.fit(s.astype(str))\n",
    "        encoders[col] = le\n",
    "    return encoders\n",
    "\n",
    "\n",
    "def _transform_with_encoder(series, le: LabelEncoder):\n",
    "    s = _normalize_cat(series)\n",
    "    classes = set(le.classes_)\n",
    "    s = s.apply(lambda x: x if x in classes else \"__MISSING__\")\n",
    "    return le.transform(s.astype(str))\n",
    "\n",
    "\n",
    "def preprocess_split_fit_transform(df_train, df_val, df_test, feature_cols, cat_cols, target):\n",
    "    # target\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "\n",
    "    # 인코더 fit (train only)\n",
    "    encoders = _fit_label_encoders(df_train, cat_cols)\n",
    "\n",
    "    # categorical transform\n",
    "    X_cat_train = np.stack([_transform_with_encoder(df_train[c], encoders[c]) for c in cat_cols], axis=1)\n",
    "    X_cat_val   = np.stack([_transform_with_encoder(df_val[c], encoders[c])   for c in cat_cols], axis=1)\n",
    "    X_cat_test  = np.stack([_transform_with_encoder(df_test[c], encoders[c])  for c in cat_cols], axis=1)\n",
    "\n",
    "    # numeric\n",
    "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "    train_num = df_train[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    val_num   = df_val[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    test_num  = df_test[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    train_means = train_num.mean()\n",
    "    train_num = train_num.fillna(train_means)\n",
    "    val_num   = val_num.fillna(train_means)\n",
    "    test_num  = test_num.fillna(train_means)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_num_train = scaler.fit_transform(train_num.values)\n",
    "    X_num_val   = scaler.transform(val_num.values)\n",
    "    X_num_test  = scaler.transform(test_num.values)\n",
    "\n",
    "    return {\n",
    "        \"X_num_train\": X_num_train,\n",
    "        \"X_num_val\": X_num_val,\n",
    "        \"X_num_test\": X_num_test,\n",
    "        \"X_cat_train\": X_cat_train,\n",
    "        \"X_cat_val\": X_cat_val,\n",
    "        \"X_cat_test\": X_cat_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"encoders\": encoders,\n",
    "        \"scaler\": scaler,\n",
    "        \"num_cols\": num_cols,\n",
    "    }\n",
    "\n",
    "\n",
    "# raw에서 먼저 split\n",
    "raw_y = (train_raw[\"voted\"] == 2).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69730f49",
   "metadata": {},
   "source": [
    "## 7. Train/Val 분리 및 피처 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_split, val_raw_split = train_test_split(\n",
    "    train_raw,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=raw_y\n",
    ")\n",
    "\n",
    "# cfg는 train split 기준으로만 계산\n",
    "cfg = {}\n",
    "edu = pd.to_numeric(train_raw_split[\"education\"], errors=\"coerce\").replace(0, np.nan)\n",
    "cfg[\"education_mean\"] = float(edu.mean())\n",
    "\n",
    "cfg[\"race_majors\"] = set(train_raw_split[\"race\"].value_counts(dropna=True).head(5).index)\n",
    "cfg[\"religion_majors\"] = set(train_raw_split[\"religion\"].value_counts(dropna=True).head(5).index)\n",
    "\n",
    "# build_features\n",
    "train_feat = build_features(train_raw_split, cfg=cfg, is_train=True)\n",
    "val_feat   = build_features(val_raw_split,   cfg=cfg, is_train=True)\n",
    "\n",
    "test_feat  = build_features(test_raw, cfg=cfg, is_train=False)\n",
    "\n",
    "\n",
    "prep = preprocess_split_fit_transform(\n",
    "    train_feat, val_feat, test_feat,\n",
    "    feature_cols=feature_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    target=target\n",
    ")\n",
    "\n",
    "X_num_train = prep[\"X_num_train\"]\n",
    "X_num_val   = prep[\"X_num_val\"]\n",
    "X_num_test  = prep[\"X_num_test\"]\n",
    "X_cat_train = prep[\"X_cat_train\"]\n",
    "X_cat_val   = prep[\"X_cat_val\"]\n",
    "X_cat_test  = prep[\"X_cat_test\"]\n",
    "\n",
    "y_train = prep[\"y_train\"]\n",
    "y_val   = prep[\"y_val\"]\n",
    "\n",
    "num_cols = prep[\"num_cols\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0dd2e7",
   "metadata": {},
   "source": [
    "## 8. Dataset & 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class NumericalEmbedding(nn.Module):\n",
    "    def __init__(self, num_features, d_token):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_features, d_token))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features, d_token))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  # (B, num_features, 1)\n",
    "        return x * self.weight + self.bias\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, cat_dims, num_features, d_token=64, n_layers=2, n_heads=4,\n",
    "                 dropout=0.2, attn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cat_embeds = nn.ModuleList([nn.Embedding(dim, d_token) for dim in cat_dims])\n",
    "        self.num_embed = NumericalEmbedding(num_features, d_token)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_token))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_token * 4,\n",
    "            dropout=attn_dropout,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_token),\n",
    "            nn.Linear(d_token, d_token),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_token, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        cat_tokens = []\n",
    "        for i, emb in enumerate(self.cat_embeds):\n",
    "            cat_tokens.append(emb(x_cat[:, i]))\n",
    "        cat_tokens = torch.stack(cat_tokens, dim=1) if len(cat_tokens) > 0 else None\n",
    "\n",
    "        num_tokens = self.num_embed(x_num)\n",
    "        tokens = num_tokens if cat_tokens is None else torch.cat([cat_tokens, num_tokens], dim=1)\n",
    "\n",
    "        cls = self.cls_token.expand(tokens.size(0), -1, -1)\n",
    "        tokens = torch.cat([cls, tokens], dim=1)\n",
    "\n",
    "        x = self.transformer(tokens)\n",
    "        cls_out = x[:, 0]\n",
    "        return self.head(cls_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a63714",
   "metadata": {},
   "source": [
    "## 9. 학습/평가 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model(model, train_loader, val_loader, y_val, device, epochs=EPOCHS, patience=PATIENCE):\n",
    "    model.to(device)\n",
    "\n",
    "    pos_weight = (len(y_train) - y_train.sum()) / (y_train.sum() + 1e-6)\n",
    "    pos_weight_t = torch.tensor([pos_weight], dtype=torch.float32, device=device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_t)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=3e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, min_lr=1e-5\n",
    "    )\n",
    "\n",
    "    best_auc = -1.0\n",
    "    best_state = None\n",
    "    patience_ctr = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb_num, xb_cat, yb in train_loader:\n",
    "            xb_num = xb_num.to(device)\n",
    "            xb_cat = xb_cat.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb_num, xb_cat)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # val AUC\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        with torch.no_grad():\n",
    "            for xb_num, xb_cat, _ in val_loader:\n",
    "                xb_num = xb_num.to(device)\n",
    "                xb_cat = xb_cat.to(device)\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "                val_probs.append(probs)\n",
    "\n",
    "        val_probs = np.concatenate(val_probs)\n",
    "        val_auc = roc_auc_score(y_val, val_probs)\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        if val_auc > best_auc + 1e-4:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1} | val AUC {val_auc:.4f}\")\n",
    "\n",
    "        if patience_ctr >= patience:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, best_auc\n",
    "\n",
    "\n",
    "def predict_proba(model, loader, device):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for xb_num, xb_cat in loader:\n",
    "            xb_num = xb_num.to(device)\n",
    "            xb_cat = xb_cat.to(device)\n",
    "            logits = model(xb_num, xb_cat)\n",
    "            p = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "            probs.append(p)\n",
    "    return np.concatenate(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c593f9",
   "metadata": {},
   "source": [
    "## 10. Optuna 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99538c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import optuna\n",
    "    from optuna.pruners import MedianPruner\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    print(\"Optuna not available:\", e)\n",
    "\n",
    "best_params = {\n",
    "    \"d_token\": 64,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 4,\n",
    "    \"dropout\": 0.2,\n",
    "    \"attn_dropout\": 0.2,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 3e-4,\n",
    "}\n",
    "\n",
    "if OPTUNA_AVAILABLE:\n",
    "    def objective(trial):\n",
    "        set_seed(SEED)\n",
    "\n",
    "        d_token = trial.suggest_categorical(\"d_token\", [32, 64, 96, 128])\n",
    "        n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
    "        if d_token % n_heads != 0:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "        attn_dropout = trial.suggest_float(\"attn_dropout\", 0.1, 0.4)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 8e-4, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 5e-4, log=True)\n",
    "\n",
    "        # trial용 split\n",
    "        raw_y = (train_raw[\"voted\"] == 2).astype(int)\n",
    "        tr_raw, va_raw = train_test_split(\n",
    "            train_raw,\n",
    "            test_size=0.2,\n",
    "            random_state=SEED,\n",
    "            stratify=raw_y\n",
    "        )\n",
    "\n",
    "        cfg = {}\n",
    "        edu = pd.to_numeric(tr_raw[\"education\"], errors=\"coerce\").replace(0, np.nan)\n",
    "        cfg[\"education_mean\"] = float(edu.mean())\n",
    "        cfg[\"race_majors\"] = set(tr_raw[\"race\"].value_counts(dropna=True).head(5).index)\n",
    "        cfg[\"religion_majors\"] = set(tr_raw[\"religion\"].value_counts(dropna=True).head(5).index)\n",
    "\n",
    "        tr_feat = build_features(tr_raw, cfg=cfg, is_train=True)\n",
    "        va_feat = build_features(va_raw, cfg=cfg, is_train=True)\n",
    "        te_feat = build_features(test_raw, cfg=cfg, is_train=False)\n",
    "\n",
    "        prep_local = preprocess_split_fit_transform(\n",
    "            tr_feat, va_feat, te_feat,\n",
    "            feature_cols=feature_cols,\n",
    "            cat_cols=cat_cols,\n",
    "            target=target\n",
    "        )\n",
    "\n",
    "        X_num_tr = prep_local[\"X_num_train\"]\n",
    "        X_cat_tr = prep_local[\"X_cat_train\"]\n",
    "        y_tr = prep_local[\"y_train\"]\n",
    "\n",
    "        X_num_va = prep_local[\"X_num_val\"]\n",
    "        X_cat_va = prep_local[\"X_cat_val\"]\n",
    "        y_va = prep_local[\"y_val\"]\n",
    "\n",
    "        train_ds = TabDataset(X_num_tr, X_cat_tr, y_tr)\n",
    "        val_ds = TabDataset(X_num_va, X_cat_va, y_va)\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1ea3c",
   "metadata": {},
   "source": [
    "## 11. 학습 실행 및 제출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = [len(prep_local[\"encoders\"][c].classes_) for c in cat_cols]\n",
    "        model = FTTransformer(\n",
    "            cat_dims=cat_dims,\n",
    "            num_features=prep_local[\"num_cols\"].__len__(),\n",
    "            d_token=d_token,\n",
    "            n_layers=n_layers,\n",
    "            n_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            attn_dropout=attn_dropout\n",
    "        )\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        pos_weight = (len(y_tr) - y_tr.sum()) / (y_tr.sum() + 1e-6)\n",
    "        pos_weight_t = torch.tensor([pos_weight], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_t)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_auc = -1.0\n",
    "        patience = 3\n",
    "        patience_ctr = 0\n",
    "\n",
    "        for epoch in range(20):\n",
    "            model.train()\n",
    "            for xb_num, xb_cat, yb in train_loader:\n",
    "                xb_num = xb_num.to(DEVICE)\n",
    "                xb_cat = xb_cat.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            # val auc\n",
    "            model.eval()\n",
    "            val_probs = []\n",
    "            with torch.no_grad():\n",
    "                for xb_num, xb_cat, _ in val_loader:\n",
    "                    xb_num = xb_num.to(DEVICE)\n",
    "                    xb_cat = xb_cat.to(DEVICE)\n",
    "                    logits = model(xb_num, xb_cat)\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "                    val_probs.append(probs)\n",
    "\n",
    "            val_probs = np.concatenate(val_probs)\n",
    "            val_auc = roc_auc_score(y_va, val_probs)\n",
    "            trial.report(val_auc, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            if val_auc > best_auc + 1e-4:\n",
    "                best_auc = val_auc\n",
    "                patience_ctr = 0\n",
    "            else:\n",
    "                patience_ctr += 1\n",
    "\n",
    "            if patience_ctr >= patience:\n",
    "                break\n",
    "\n",
    "        return best_auc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner(n_warmup_steps=5))\n",
    "    study.optimize(objective, n_trials=OPTUNA_TRIALS)\n",
    "    best_params = study.best_params\n",
    "    print(\"Optuna best params:\", best_params)\n",
    "\n",
    "\n",
    "cat_dims = [len(prep[\"encoders\"][c].classes_) for c in cat_cols]\n",
    "\n",
    "model = FTTransformer(\n",
    "    cat_dims=cat_dims,\n",
    "    num_features=len(num_cols),\n",
    "    d_token=best_params.get(\"d_token\", 64),\n",
    "    n_layers=best_params.get(\"n_layers\", 2),\n",
    "    n_heads=best_params.get(\"n_heads\", 4),\n",
    "    dropout=best_params.get(\"dropout\", 0.2),\n",
    "    attn_dropout=best_params.get(\"attn_dropout\", 0.2)\n",
    ")\n",
    "\n",
    "train_ds = TabDataset(X_num_train, X_cat_train, y_train)\n",
    "val_ds = TabDataset(X_num_val, X_cat_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model, best_auc = train_one_model(model, train_loader, val_loader, y_val, DEVICE)\n",
    "print(f\"Best Validation ROC-AUC: {best_auc:.4f}\")\n",
    "\n",
    "\n",
    "test_ds = TabDataset(X_num_test, X_cat_test, y=None)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_probs = predict_proba(model, test_loader, DEVICE)\n",
    "\n",
    "sub = pd.read_csv(\"../../data/raw/sample_submission.csv\")\n",
    "sub[\"voted\"] = test_probs\n",
    "sub.to_csv(\"submission_prob_7th_test.csv\", index=False)\n",
    "print(\"saved submission_prob_7th_test.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
