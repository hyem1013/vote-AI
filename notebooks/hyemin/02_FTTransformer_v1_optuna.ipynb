{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_FTTransformer_v1_optuna 요약\n",
    "\n",
    "- 모델: FT-Transformer + Optuna\n",
    "- 피처: v1 베이스 + cred_bin/카테고리\n",
    "- 학습/평가: 단일 split, Optuna 튜닝\n",
    "- 제출파일: submission_02_FTTransformer_v1_optuna.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5830f8",
   "metadata": {},
   "source": [
    "# 03_second_test\n",
    "- 02에서 사용한 피처 유지 + `cred_bin` 추가\n",
    "- hand/married는 **원본 카테고리** 사용\n",
    "- 모델: FT-Transformer + Optuna 튜닝 (선택)\n",
    "- 데이터 누수 방지: split 후 인코딩/결측/스케일 fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0fc5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42cfd5",
   "metadata": {},
   "source": [
    "## 0. 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "104a46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 하이퍼파라미터\n",
    "SEED = 42\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "PATIENCE = 6\n",
    "OPTUNA_TRIALS = 50  # 필요 시 조절\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041b598",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb95051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test_raw  = pd.read_csv(\"../../data/raw/test_x.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a2d42",
   "metadata": {},
   "source": [
    "## 2. 공통 전처리/파생변수 생성 (build_features 유지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71b6bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 공통 전처리/피처 생성 함수\n",
    "# -----------------------------\n",
    "def build_features(df_raw, cfg=None, is_train=True):\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # 0) voted -> voted_bin (train에만 존재)\n",
    "    if is_train and \"voted\" in df.columns:\n",
    "        df[\"voted_bin\"] = (df[\"voted\"] == 2).astype(int)\n",
    "\n",
    "    # 1) age_group -> ordinal\n",
    "    if \"age_group\" in df.columns:\n",
    "        age_map = {\"10s\":1, \"20s\":2, \"30s\":3, \"40s\":4, \"50s\":5, \"60s\":6, \"+70s\":7}\n",
    "        df[\"age_group_ord\"] = df[\"age_group\"].map(age_map).astype(\"float32\")\n",
    "\n",
    "    # 2) education (0=무응답 -> NaN -> train 평균으로 대치)\n",
    "    if \"education\" in df.columns:\n",
    "        df[\"education\"] = pd.to_numeric(df[\"education\"], errors=\"coerce\")\n",
    "        df.loc[df[\"education\"] == 0, \"education\"] = np.nan\n",
    "        if cfg is not None:\n",
    "            df[\"education\"] = df[\"education\"].fillna(cfg[\"education_mean\"])\n",
    "        df[\"education\"] = df[\"education\"].astype(\"float32\")\n",
    "\n",
    "    # 3) married_cat (원본 카테고리 유지, 0=무응답 NaN)\n",
    "    if \"married\" in df.columns:\n",
    "        df[\"married\"] = pd.to_numeric(df[\"married\"], errors=\"coerce\")\n",
    "        df.loc[df[\"married\"] == 0, \"married\"] = np.nan\n",
    "        df[\"married_cat\"] = df[\"married\"].astype(\"string\")\n",
    "\n",
    "    # 4) hand_cat (원본 카테고리 유지, 0=무응답 NaN)\n",
    "    if \"hand\" in df.columns:\n",
    "        df[\"hand\"] = pd.to_numeric(df[\"hand\"], errors=\"coerce\")\n",
    "        df.loc[df[\"hand\"] == 0, \"hand\"] = np.nan\n",
    "        df[\"hand_cat\"] = df[\"hand\"].astype(\"string\")\n",
    "\n",
    "    # 5) urban_ord (0=무응답 NaN)\n",
    "    if \"urban\" in df.columns:\n",
    "        df[\"urban\"] = pd.to_numeric(df[\"urban\"], errors=\"coerce\")\n",
    "        df.loc[df[\"urban\"] == 0, \"urban\"] = np.nan\n",
    "        df[\"urban_ord\"] = df[\"urban\"].astype(\"float32\")\n",
    "\n",
    "    # 6) race/religion 단순화: train에서 뽑은 top-k만 살리고 나머지 Other\n",
    "    def simplify_major_other(series, majors):\n",
    "        return series.apply(lambda x: x if x in majors else \"Other\")\n",
    "\n",
    "    if \"race\" in df.columns and cfg is not None:\n",
    "        df[\"race_simple\"] = simplify_major_other(df[\"race\"], cfg[\"race_majors\"]).astype(str)\n",
    "\n",
    "    if \"religion\" in df.columns and cfg is not None:\n",
    "        df[\"religion_simple\"] = simplify_major_other(df[\"religion\"], cfg[\"religion_majors\"]).astype(str)\n",
    "\n",
    "    # 7) Q_A: neg_att / pos_att / confident_ratio / neutral_ratio\n",
    "    neg_cols = [\"QbA\",\"QcA\",\"QjA\",\"QmA\",\"QoA\",\"QsA\"]\n",
    "    pos_cols = [\"QkA\",\"QqA\"]\n",
    "    other_cols = [\"QeA\",\"QfA\",\"QhA\",\"QrA\"]\n",
    "\n",
    "    for col in neg_cols + pos_cols + other_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    if all(c in df.columns for c in neg_cols):\n",
    "        df[\"neg_att\"] = df[neg_cols].mean(axis=1)\n",
    "\n",
    "    if all(c in df.columns for c in pos_cols):\n",
    "        df[\"pos_att\"] = df[pos_cols].mean(axis=1)\n",
    "\n",
    "    if all(c in df.columns for c in other_cols):\n",
    "        other = df[other_cols]\n",
    "        df[\"neutral_ratio\"] = (other == 3).mean(axis=1).astype(\"float32\")\n",
    "        df[\"confident_ratio\"] = ((other <= 2) | (other >= 4)).mean(axis=1).astype(\"float32\")\n",
    "\n",
    "    # 8) TP Big5 diff/strength\n",
    "    tp_pairs = {\n",
    "        \"extraversion\": (\"tp01\", \"tp06\"),\n",
    "        \"agreeableness\": (\"tp07\", \"tp02\"),\n",
    "        \"conscientiousness\": (\"tp03\", \"tp08\"),\n",
    "        \"neuroticism\": (\"tp04\", \"tp09\"),\n",
    "        \"openness\": (\"tp05\", \"tp10\"),\n",
    "    }\n",
    "    for trait, (a, b) in tp_pairs.items():\n",
    "        if a in df.columns and b in df.columns:\n",
    "            df[a] = pd.to_numeric(df[a], errors=\"coerce\")\n",
    "            df[b] = pd.to_numeric(df[b], errors=\"coerce\")\n",
    "            df[f\"{trait}_diff\"] = (df[a] - df[b]).astype(\"float32\")\n",
    "            df[f\"{trait}_strength\"] = df[f\"{trait}_diff\"].abs().astype(\"float32\")\n",
    "\n",
    "    # 9) 단어 인지: wr_sum / wf_sum / word_credibility\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "    if all(c in df.columns for c in wr_cols):\n",
    "        df[\"wr_sum\"] = df[wr_cols].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    if all(c in df.columns for c in wf_cols):\n",
    "        df[\"wf_sum\"] = df[wf_cols].sum(axis=1).astype(\"float32\")\n",
    "\n",
    "    if \"wr_sum\" in df.columns and \"wf_sum\" in df.columns:\n",
    "        df[\"word_credibility\"] = (df[\"wr_sum\"] - df[\"wf_sum\"]).astype(\"float32\")\n",
    "\n",
    "    # 9-1) 단어 인지 구간화 (EDA 기준)\n",
    "    if \"word_credibility\" in df.columns:\n",
    "        df[\"cred_bin\"] = pd.cut(\n",
    "            df[\"word_credibility\"],\n",
    "            bins=[-3, 1, 6, 13],\n",
    "            labels=[\"Low\", \"Mid\", \"High\"]\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db23af",
   "metadata": {},
   "source": [
    "## 3. 컬럼 정의 (02 구조 유지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1d73d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"voted_bin\"\n",
    "feature_cols = [\n",
    "    \"neg_att\", \"pos_att\", \"neutral_ratio\", \"confident_ratio\",\n",
    "    \"extraversion_diff\", \"extraversion_strength\",\n",
    "    \"agreeableness_diff\", \"agreeableness_strength\",\n",
    "    \"conscientiousness_diff\", \"conscientiousness_strength\",\n",
    "    \"neuroticism_diff\", \"neuroticism_strength\",\n",
    "    \"openness_diff\", \"openness_strength\",\n",
    "    \"wr_sum\", \"wf_sum\", \"word_credibility\", \"cred_bin\",\n",
    "    \"age_group_ord\", \"education\", \"urban_ord\",\n",
    "    \"hand_cat\", \"married_cat\",\n",
    "    \"race_simple\", \"religion_simple\",\n",
    "]\n",
    "\n",
    "cat_cols = [\"race_simple\", \"religion_simple\", \"cred_bin\", \"hand_cat\", \"married_cat\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988a59c",
   "metadata": {},
   "source": [
    "## 4. 전처리 함수 (누수 방지)\n",
    "- split 후 인코딩/결측/스케일 fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45abdc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_cat(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    s = s.fillna(\"__MISSING__\")\n",
    "    s = s.replace({\"<NA>\": \"__MISSING__\", \"nan\": \"__MISSING__\", \"NaN\": \"__MISSING__\"})\n",
    "    return s\n",
    "\n",
    "\n",
    "def _fit_label_encoders(df_train, cat_cols):\n",
    "    encoders = {}\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        s = _normalize_cat(df_train[col])\n",
    "        # __MISSING__ 토큰 보장\n",
    "        if \"__MISSING__\" not in s.unique():\n",
    "            s = pd.concat([s, pd.Series([\"__MISSING__\"])], ignore_index=True)\n",
    "        le.fit(s.astype(str))\n",
    "        encoders[col] = le\n",
    "    return encoders\n",
    "\n",
    "\n",
    "def _transform_with_encoder(series, le: LabelEncoder):\n",
    "    s = _normalize_cat(series)\n",
    "    classes = set(le.classes_)\n",
    "    s = s.apply(lambda x: x if x in classes else \"__MISSING__\")\n",
    "    return le.transform(s.astype(str))\n",
    "\n",
    "\n",
    "def preprocess_split_fit_transform(df_train, df_val, df_test, feature_cols, cat_cols, target):\n",
    "    # target\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "\n",
    "    # 인코더 fit (train only)\n",
    "    encoders = _fit_label_encoders(df_train, cat_cols)\n",
    "\n",
    "    # categorical transform\n",
    "    X_cat_train = np.stack([_transform_with_encoder(df_train[c], encoders[c]) for c in cat_cols], axis=1)\n",
    "    X_cat_val   = np.stack([_transform_with_encoder(df_val[c], encoders[c])   for c in cat_cols], axis=1)\n",
    "    X_cat_test  = np.stack([_transform_with_encoder(df_test[c], encoders[c])  for c in cat_cols], axis=1)\n",
    "\n",
    "    # numeric\n",
    "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "    train_num = df_train[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    val_num   = df_val[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    test_num  = df_test[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    train_means = train_num.mean()\n",
    "    train_num = train_num.fillna(train_means)\n",
    "    val_num   = val_num.fillna(train_means)\n",
    "    test_num  = test_num.fillna(train_means)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_num_train = scaler.fit_transform(train_num.values)\n",
    "    X_num_val   = scaler.transform(val_num.values)\n",
    "    X_num_test  = scaler.transform(test_num.values)\n",
    "\n",
    "    return {\n",
    "        \"X_num_train\": X_num_train,\n",
    "        \"X_num_val\": X_num_val,\n",
    "        \"X_num_test\": X_num_test,\n",
    "        \"X_cat_train\": X_cat_train,\n",
    "        \"X_cat_val\": X_cat_val,\n",
    "        \"X_cat_test\": X_cat_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"encoders\": encoders,\n",
    "        \"scaler\": scaler,\n",
    "        \"num_cols\": num_cols,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f10b5",
   "metadata": {},
   "source": [
    "## 5. 데이터 분리 (누수 방지)\n",
    "- split 먼저 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7785610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw에서 먼저 split\n",
    "raw_y = (train_raw[\"voted\"] == 2).astype(int)\n",
    "train_raw_split, val_raw_split = train_test_split(\n",
    "    train_raw,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=raw_y\n",
    ")\n",
    "\n",
    "# cfg는 train split 기준으로만 계산\n",
    "cfg = {}\n",
    "edu = pd.to_numeric(train_raw_split[\"education\"], errors=\"coerce\").replace(0, np.nan)\n",
    "cfg[\"education_mean\"] = float(edu.mean())\n",
    "\n",
    "cfg[\"race_majors\"] = set(train_raw_split[\"race\"].value_counts(dropna=True).head(5).index)\n",
    "cfg[\"religion_majors\"] = set(train_raw_split[\"religion\"].value_counts(dropna=True).head(5).index)\n",
    "\n",
    "# build_features\n",
    "train_feat = build_features(train_raw_split, cfg=cfg, is_train=True)\n",
    "val_feat   = build_features(val_raw_split,   cfg=cfg, is_train=True)\n",
    "\n",
    "test_feat  = build_features(test_raw, cfg=cfg, is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30029005",
   "metadata": {},
   "source": [
    "## 6. 전처리 적용 (train fit → val/test transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caff283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = preprocess_split_fit_transform(\n",
    "    train_feat, val_feat, test_feat,\n",
    "    feature_cols=feature_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    target=target\n",
    ")\n",
    "\n",
    "X_num_train = prep[\"X_num_train\"]\n",
    "X_num_val   = prep[\"X_num_val\"]\n",
    "X_num_test  = prep[\"X_num_test\"]\n",
    "X_cat_train = prep[\"X_cat_train\"]\n",
    "X_cat_val   = prep[\"X_cat_val\"]\n",
    "X_cat_test  = prep[\"X_cat_test\"]\n",
    "\n",
    "y_train = prep[\"y_train\"]\n",
    "y_val   = prep[\"y_val\"]\n",
    "\n",
    "num_cols = prep[\"num_cols\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fc131",
   "metadata": {},
   "source": [
    "## 7. Dataset / DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11d0985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd38563",
   "metadata": {},
   "source": [
    "## 8. FT-Transformer (CLS token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d7b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericalEmbedding(nn.Module):\n",
    "    def __init__(self, num_features, d_token):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(num_features, d_token))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features, d_token))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  # (B, num_features, 1)\n",
    "        return x * self.weight + self.bias\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, cat_dims, num_features, d_token=64, n_layers=2, n_heads=4,\n",
    "                 dropout=0.2, attn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cat_embeds = nn.ModuleList([nn.Embedding(dim, d_token) for dim in cat_dims])\n",
    "        self.num_embed = NumericalEmbedding(num_features, d_token)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_token))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_token * 4,\n",
    "            dropout=attn_dropout,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_token),\n",
    "            nn.Linear(d_token, d_token),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_token, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        cat_tokens = []\n",
    "        for i, emb in enumerate(self.cat_embeds):\n",
    "            cat_tokens.append(emb(x_cat[:, i]))\n",
    "        cat_tokens = torch.stack(cat_tokens, dim=1) if len(cat_tokens) > 0 else None\n",
    "\n",
    "        num_tokens = self.num_embed(x_num)\n",
    "        tokens = num_tokens if cat_tokens is None else torch.cat([cat_tokens, num_tokens], dim=1)\n",
    "\n",
    "        cls = self.cls_token.expand(tokens.size(0), -1, -1)\n",
    "        tokens = torch.cat([cls, tokens], dim=1)\n",
    "\n",
    "        x = self.transformer(tokens)\n",
    "        cls_out = x[:, 0]\n",
    "        return self.head(cls_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb971ba",
   "metadata": {},
   "source": [
    "## 9. 학습/평가 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12914575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model(model, train_loader, val_loader, y_val, device, epochs=EPOCHS, patience=PATIENCE):\n",
    "    model.to(device)\n",
    "\n",
    "    pos_weight = (len(y_train) - y_train.sum()) / (y_train.sum() + 1e-6)\n",
    "    pos_weight_t = torch.tensor([pos_weight], dtype=torch.float32, device=device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_t)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=3e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, min_lr=1e-5\n",
    "    )\n",
    "\n",
    "    best_auc = -1.0\n",
    "    best_state = None\n",
    "    patience_ctr = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb_num, xb_cat, yb in train_loader:\n",
    "            xb_num = xb_num.to(device)\n",
    "            xb_cat = xb_cat.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb_num, xb_cat)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # val AUC\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        with torch.no_grad():\n",
    "            for xb_num, xb_cat, _ in val_loader:\n",
    "                xb_num = xb_num.to(device)\n",
    "                xb_cat = xb_cat.to(device)\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "                val_probs.append(probs)\n",
    "\n",
    "        val_probs = np.concatenate(val_probs)\n",
    "        val_auc = roc_auc_score(y_val, val_probs)\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        if val_auc > best_auc + 1e-4:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1} | val AUC {val_auc:.4f}\")\n",
    "\n",
    "        if patience_ctr >= patience:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, best_auc\n",
    "\n",
    "\n",
    "def predict_proba(model, loader, device):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for xb_num, xb_cat in loader:\n",
    "            xb_num = xb_num.to(device)\n",
    "            xb_cat = xb_cat.to(device)\n",
    "            logits = model(xb_num, xb_cat)\n",
    "            p = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "            probs.append(p)\n",
    "    return np.concatenate(probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46fc49",
   "metadata": {},
   "source": [
    "## 10. Optuna 튜닝 (선택)\n",
    "- trial마다 split→인코딩/스케일 fit을 다시 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ece037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-28 11:40:18,084]\u001b[0m A new study created in memory with name: no-name-c495197c-995a-4874-af03-002959665c97\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:46:05,209]\u001b[0m Trial 0 finished with value: 0.7689048172335573 and parameters: {'d_token': 32, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.281696360362582, 'attn_dropout': 0.19517621253878412, 'lr': 0.00041565200495796684, 'weight_decay': 0.0003934919543241489}. Best is trial 0 with value: 0.7689048172335573.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:47:39,175]\u001b[0m Trial 1 finished with value: 0.7678406380550065 and parameters: {'d_token': 64, 'n_heads': 8, 'n_layers': 1, 'dropout': 0.32028251709746836, 'attn_dropout': 0.13884888576100793, 'lr': 0.0003879315145699164, 'weight_decay': 0.00015783449658642818}. Best is trial 0 with value: 0.7689048172335573.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:49:42,037]\u001b[0m Trial 2 finished with value: 0.7669107736981364 and parameters: {'d_token': 96, 'n_heads': 4, 'n_layers': 1, 'dropout': 0.14335565323642985, 'attn_dropout': 0.3324666328498742, 'lr': 0.00018260224430815503, 'weight_decay': 6.33520288615973e-05}. Best is trial 0 with value: 0.7689048172335573.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:53:14,650]\u001b[0m Trial 3 finished with value: 0.7686616589936193 and parameters: {'d_token': 64, 'n_heads': 4, 'n_layers': 2, 'dropout': 0.22186198700971793, 'attn_dropout': 0.2835414791686638, 'lr': 0.0003158968815358452, 'weight_decay': 2.8778451866742382e-05}. Best is trial 0 with value: 0.7689048172335573.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:56:08,568]\u001b[0m Trial 4 finished with value: 0.7643009401307678 and parameters: {'d_token': 32, 'n_heads': 8, 'n_layers': 1, 'dropout': 0.17677750614723953, 'attn_dropout': 0.25381984917189687, 'lr': 0.0001983893163668722, 'weight_decay': 1.873038005580311e-05}. Best is trial 0 with value: 0.7689048172335573.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:57:47,838]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 11:59:17,193]\u001b[0m Trial 6 finished with value: 0.7693737635300105 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 1, 'dropout': 0.11741223592296476, 'attn_dropout': 0.12611152223742433, 'lr': 0.00036551853929557424, 'weight_decay': 6.501064603152029e-05}. Best is trial 6 with value: 0.7693737635300105.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:00:22,265]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:01:59,616]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:03:13,469]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:03:53,784]\u001b[0m Trial 10 finished with value: 0.7669004829592175 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 1, 'dropout': 0.10104457137311262, 'attn_dropout': 0.10673010537891009, 'lr': 0.0007413451365975879, 'weight_decay': 0.00012532172602992755}. Best is trial 6 with value: 0.7693737635300105.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:05:26,920]\u001b[0m Trial 11 finished with value: 0.769137392798721 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 2, 'dropout': 0.3259232792218254, 'attn_dropout': 0.1803144338582381, 'lr': 0.0005393303719165971, 'weight_decay': 0.00030952218567976145}. Best is trial 6 with value: 0.7693737635300105.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:07:20,323]\u001b[0m Trial 12 finished with value: 0.7685986981607068 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 2, 'dropout': 0.35533451515476383, 'attn_dropout': 0.17934114697061668, 'lr': 0.0006063906083612023, 'weight_decay': 0.0001252423949123625}. Best is trial 6 with value: 0.7693737635300105.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:11:08,168]\u001b[0m Trial 13 finished with value: 0.7695831788506096 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.3316073301262162, 'attn_dropout': 0.13984107237761886, 'lr': 0.0004841276894713807, 'weight_decay': 0.00021277928115164858}. Best is trial 13 with value: 0.7695831788506096.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:15:49,142]\u001b[0m Trial 14 finished with value: 0.7703139429537875 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.17717907277544948, 'attn_dropout': 0.11172408404287634, 'lr': 0.0002386701465467518, 'weight_decay': 0.0002065124546155079}. Best is trial 14 with value: 0.7703139429537875.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:20:32,417]\u001b[0m Trial 15 finished with value: 0.7701658584909057 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.18432591584271638, 'attn_dropout': 0.10066506650573566, 'lr': 0.00024029696627482115, 'weight_decay': 0.00015522631225085569}. Best is trial 14 with value: 0.7703139429537875.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:22:57,731]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:27:42,182]\u001b[0m Trial 17 finished with value: 0.7701116314056808 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.18476361769765198, 'attn_dropout': 0.10197385770523167, 'lr': 0.00024207756811986088, 'weight_decay': 1.0515468184943681e-05}. Best is trial 14 with value: 0.7703139429537875.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:32:26,715]\u001b[0m Trial 18 finished with value: 0.7703839589032164 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.15314611187901495, 'attn_dropout': 0.2210019988004499, 'lr': 0.0001356482962794525, 'weight_decay': 9.444361814807754e-05}. Best is trial 18 with value: 0.7703839589032164.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:37:14,868]\u001b[0m Trial 19 finished with value: 0.77036481277667 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.1518402232802789, 'attn_dropout': 0.21978279542723506, 'lr': 0.00010824296790193877, 'weight_decay': 0.0001016507344319908}. Best is trial 18 with value: 0.7703839589032164.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:40:11,781]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:44:52,898]\u001b[0m Trial 21 finished with value: 0.7701366649053203 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.21150699359416844, 'attn_dropout': 0.22842248559110825, 'lr': 0.00013194655250229625, 'weight_decay': 9.245483313351632e-05}. Best is trial 18 with value: 0.7703839589032164.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:49:35,533]\u001b[0m Trial 22 finished with value: 0.7700053910821381 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.14969119766778216, 'attn_dropout': 0.29694650412085943, 'lr': 0.00014453511449419903, 'weight_decay': 9.809922141718302e-05}. Best is trial 18 with value: 0.7703839589032164.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:54:29,120]\u001b[0m Trial 23 finished with value: 0.7700273349273031 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.2578019944361461, 'attn_dropout': 0.22143927634903723, 'lr': 0.00010041577960275477, 'weight_decay': 0.00022848263657633473}. Best is trial 18 with value: 0.7703839589032164.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 12:59:32,524]\u001b[0m Trial 24 finished with value: 0.7707468351720426 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 3, 'dropout': 0.14792248767317773, 'attn_dropout': 0.16234337446518604, 'lr': 0.00012551279023131483, 'weight_decay': 9.110607337707916e-05}. Best is trial 24 with value: 0.7707468351720426.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:01:36,788]\u001b[0m Trial 25 finished with value: 0.7709462273615908 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 2, 'dropout': 0.13486458210360466, 'attn_dropout': 0.15394012574013158, 'lr': 0.00011774824099992459, 'weight_decay': 9.03987368104704e-05}. Best is trial 25 with value: 0.7709462273615908.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:03:43,131]\u001b[0m Trial 26 finished with value: 0.7710572359707791 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 2, 'dropout': 0.10075485148686888, 'attn_dropout': 0.15526933770775278, 'lr': 0.00015292413849661335, 'weight_decay': 4.3503448682757675e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:05:47,051]\u001b[0m Trial 27 finished with value: 0.7707580017185292 and parameters: {'d_token': 128, 'n_heads': 2, 'n_layers': 2, 'dropout': 0.12206518297332304, 'attn_dropout': 0.14627531423978185, 'lr': 0.0001597629113040978, 'weight_decay': 4.5369762807637773e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:07:53,701]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:09:15,756]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:15:42,229]\u001b[0m Trial 30 finished with value: 0.7709260351315609 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.12960226586394663, 'attn_dropout': 0.19701781416077735, 'lr': 0.00015452645257426153, 'weight_decay': 5.576338742417727e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:22:16,937]\u001b[0m Trial 31 finished with value: 0.7708570652856155 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.12774930852360697, 'attn_dropout': 0.2023069382437981, 'lr': 0.0001552225992927953, 'weight_decay': 5.976572720607487e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:27:37,055]\u001b[0m Trial 32 finished with value: 0.770873705629399 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.12793109059425178, 'attn_dropout': 0.1937149391761374, 'lr': 0.00011673177881506146, 'weight_decay': 5.598828881047315e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:34:02,155]\u001b[0m Trial 33 finished with value: 0.7709530635262154 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.10411340576564454, 'attn_dropout': 0.2021913172247069, 'lr': 0.00011972453017319615, 'weight_decay': 5.787366584083252e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:36:13,105]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:40:06,401]\u001b[0m Trial 35 finished with value: 0.7704359478135464 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.1650050777501757, 'attn_dropout': 0.24543516979478103, 'lr': 0.00014370998498842955, 'weight_decay': 2.6446221502156824e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:42:48,681]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:44:33,039]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:46:09,199]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:48:27,987]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:53:33,096]\u001b[0m Trial 40 finished with value: 0.770985736014083 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.20034848620419482, 'attn_dropout': 0.15493540957815588, 'lr': 0.00014871950803213314, 'weight_decay': 3.477175004650167e-05}. Best is trial 26 with value: 0.7710572359707791.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 13:58:35,299]\u001b[0m Trial 41 finished with value: 0.7711445491196673 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.2458160240948599, 'attn_dropout': 0.15590898554707383, 'lr': 0.00012002569389445415, 'weight_decay': 3.7148307526443774e-05}. Best is trial 41 with value: 0.7711445491196673.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:04:10,008]\u001b[0m Trial 42 finished with value: 0.7712368738340811 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.24567046241114915, 'attn_dropout': 0.15553654612226403, 'lr': 0.00011085386788733057, 'weight_decay': 3.648869980124139e-05}. Best is trial 42 with value: 0.7712368738340811.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:09:53,507]\u001b[0m Trial 43 finished with value: 0.7715928409543189 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.2606930468086733, 'attn_dropout': 0.12215130152572648, 'lr': 0.00010821417499047161, 'weight_decay': 3.4270609049790265e-05}. Best is trial 43 with value: 0.7715928409543189.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:11:49,553]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:17:27,690]\u001b[0m Trial 45 finished with value: 0.7708534404154053 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.2803271828489279, 'attn_dropout': 0.1709946128966003, 'lr': 0.0001406985787280378, 'weight_decay': 2.1459663220198892e-05}. Best is trial 43 with value: 0.7715928409543189.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:19:15,965]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:24:39,774]\u001b[0m Trial 47 finished with value: 0.7710247824348035 and parameters: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.3012657337489657, 'attn_dropout': 0.1385180813749883, 'lr': 0.0002856469451187924, 'weight_decay': 1.5016044844979626e-05}. Best is trial 43 with value: 0.7715928409543189.\u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:25:25,109]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2026-01-28 14:28:09,118]\u001b[0m Trial 49 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna best params: {'d_token': 128, 'n_heads': 8, 'n_layers': 2, 'dropout': 0.2606930468086733, 'attn_dropout': 0.12215130152572648, 'lr': 0.00010821417499047161, 'weight_decay': 3.4270609049790265e-05}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import optuna\n",
    "    from optuna.pruners import MedianPruner\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    print(\"Optuna not available:\", e)\n",
    "\n",
    "best_params = {\n",
    "    \"d_token\": 64,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 4,\n",
    "    \"dropout\": 0.2,\n",
    "    \"attn_dropout\": 0.2,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 3e-4,\n",
    "}\n",
    "\n",
    "if OPTUNA_AVAILABLE:\n",
    "    def objective(trial):\n",
    "        set_seed(SEED)\n",
    "\n",
    "        d_token = trial.suggest_categorical(\"d_token\", [32, 64, 96, 128])\n",
    "        n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
    "        if d_token % n_heads != 0:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "        attn_dropout = trial.suggest_float(\"attn_dropout\", 0.1, 0.4)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 8e-4, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 5e-4, log=True)\n",
    "\n",
    "        # trial용 split\n",
    "        raw_y = (train_raw[\"voted\"] == 2).astype(int)\n",
    "        tr_raw, va_raw = train_test_split(\n",
    "            train_raw,\n",
    "            test_size=0.2,\n",
    "            random_state=SEED,\n",
    "            stratify=raw_y\n",
    "        )\n",
    "\n",
    "        cfg = {}\n",
    "        edu = pd.to_numeric(tr_raw[\"education\"], errors=\"coerce\").replace(0, np.nan)\n",
    "        cfg[\"education_mean\"] = float(edu.mean())\n",
    "        cfg[\"race_majors\"] = set(tr_raw[\"race\"].value_counts(dropna=True).head(5).index)\n",
    "        cfg[\"religion_majors\"] = set(tr_raw[\"religion\"].value_counts(dropna=True).head(5).index)\n",
    "\n",
    "        tr_feat = build_features(tr_raw, cfg=cfg, is_train=True)\n",
    "        va_feat = build_features(va_raw, cfg=cfg, is_train=True)\n",
    "        te_feat = build_features(test_raw, cfg=cfg, is_train=False)\n",
    "\n",
    "        prep_local = preprocess_split_fit_transform(\n",
    "            tr_feat, va_feat, te_feat,\n",
    "            feature_cols=feature_cols,\n",
    "            cat_cols=cat_cols,\n",
    "            target=target\n",
    "        )\n",
    "\n",
    "        X_num_tr = prep_local[\"X_num_train\"]\n",
    "        X_cat_tr = prep_local[\"X_cat_train\"]\n",
    "        y_tr = prep_local[\"y_train\"]\n",
    "\n",
    "        X_num_va = prep_local[\"X_num_val\"]\n",
    "        X_cat_va = prep_local[\"X_cat_val\"]\n",
    "        y_va = prep_local[\"y_val\"]\n",
    "\n",
    "        train_ds = TabDataset(X_num_tr, X_cat_tr, y_tr)\n",
    "        val_ds = TabDataset(X_num_va, X_cat_va, y_va)\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        cat_dims = [len(prep_local[\"encoders\"][c].classes_) for c in cat_cols]\n",
    "        model = FTTransformer(\n",
    "            cat_dims=cat_dims,\n",
    "            num_features=prep_local[\"num_cols\"].__len__(),\n",
    "            d_token=d_token,\n",
    "            n_layers=n_layers,\n",
    "            n_heads=n_heads,\n",
    "            dropout=dropout,\n",
    "            attn_dropout=attn_dropout\n",
    "        )\n",
    "\n",
    "        model.to(DEVICE)\n",
    "        pos_weight = (len(y_tr) - y_tr.sum()) / (y_tr.sum() + 1e-6)\n",
    "        pos_weight_t = torch.tensor([pos_weight], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_t)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        best_auc = -1.0\n",
    "        patience = 3\n",
    "        patience_ctr = 0\n",
    "\n",
    "        for epoch in range(20):\n",
    "            model.train()\n",
    "            for xb_num, xb_cat, yb in train_loader:\n",
    "                xb_num = xb_num.to(DEVICE)\n",
    "                xb_cat = xb_cat.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb_num, xb_cat)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            # val auc\n",
    "            model.eval()\n",
    "            val_probs = []\n",
    "            with torch.no_grad():\n",
    "                for xb_num, xb_cat, _ in val_loader:\n",
    "                    xb_num = xb_num.to(DEVICE)\n",
    "                    xb_cat = xb_cat.to(DEVICE)\n",
    "                    logits = model(xb_num, xb_cat)\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "                    val_probs.append(probs)\n",
    "\n",
    "            val_probs = np.concatenate(val_probs)\n",
    "            val_auc = roc_auc_score(y_va, val_probs)\n",
    "            trial.report(val_auc, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            if val_auc > best_auc + 1e-4:\n",
    "                best_auc = val_auc\n",
    "                patience_ctr = 0\n",
    "            else:\n",
    "                patience_ctr += 1\n",
    "\n",
    "            if patience_ctr >= patience:\n",
    "                break\n",
    "\n",
    "        return best_auc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner(n_warmup_steps=5))\n",
    "    study.optimize(objective, n_trials=OPTUNA_TRIALS)\n",
    "    best_params = study.best_params\n",
    "    print(\"Optuna best params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610331f",
   "metadata": {},
   "source": [
    "## 11. 최종 학습 / 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edcc6720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | val AUC 0.7674\n",
      "Best Validation ROC-AUC: 0.7707\n"
     ]
    }
   ],
   "source": [
    "cat_dims = [len(prep[\"encoders\"][c].classes_) for c in cat_cols]\n",
    "\n",
    "model = FTTransformer(\n",
    "    cat_dims=cat_dims,\n",
    "    num_features=len(num_cols),\n",
    "    d_token=best_params.get(\"d_token\", 64),\n",
    "    n_layers=best_params.get(\"n_layers\", 2),\n",
    "    n_heads=best_params.get(\"n_heads\", 4),\n",
    "    dropout=best_params.get(\"dropout\", 0.2),\n",
    "    attn_dropout=best_params.get(\"attn_dropout\", 0.2)\n",
    ")\n",
    "\n",
    "train_ds = TabDataset(X_num_train, X_cat_train, y_train)\n",
    "val_ds = TabDataset(X_num_val, X_cat_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model, best_auc = train_one_model(model, train_loader, val_loader, y_val, DEVICE)\n",
    "print(f\"Best Validation ROC-AUC: {best_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af306423",
   "metadata": {},
   "source": [
    "## 12. Test 예측 및 제출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3133e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved submission_prob_second_test.csv\n"
     ]
    }
   ],
   "source": [
    "test_ds = TabDataset(X_num_test, X_cat_test, y=None)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_probs = predict_proba(model, test_loader, DEVICE)\n",
    "\n",
    "sub = pd.read_csv(\"../../data/raw/sample_submission.csv\")\n",
    "sub[\"voted\"] = test_probs\n",
    "sub.to_csv(\"submission_02_FTTransformer_v1_optuna.csv\", index=False)\n",
    "print(\"saved submission_02_FTTransformer_v1_optuna.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0f3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}