{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13_FTTransformer_v9_full ÏöîÏïΩ\n",
    "\n",
    "- Î™®Îç∏: FT-Transformer\n",
    "- ÌîºÏ≤ò: FEATURE_SET=full\n",
    "- ÌïôÏäµ/ÌèâÍ∞Ä: KFold 5, seed=42\n",
    "- Ï†úÏ∂úÌååÏùº: submission_13_FTTransformer_v9_full.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7be54c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Device: cpu\n",
      "üìä Config: 5-Fold, epochs=50, batch=512, feature_set=full\n",
      "Train: (45532, 78), Test: (11383, 77)\n",
      "ÌÉÄÍ≤ü Î∂ÑÌè¨(ÎØ∏Ìà¨Ìëú=1): 54.7%\n",
      "\n",
      "==================================================\n",
      "üìÇ Fold 1/5\n",
      "==================================================\n",
      "    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: 167,425\n",
      "    Epoch 10: loss=0.5070, val_auc=0.77511, best=0.77595\n",
      "    Epoch 20: loss=0.4962, val_auc=0.77596, best=0.77699\n",
      "    Early stopping at epoch 22\n",
      "  ‚úÖ Fold 1 AUC: 0.77699\n",
      "\n",
      "==================================================\n",
      "üìÇ Fold 2/5\n",
      "==================================================\n",
      "    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: 167,425\n",
      "    Epoch 10: loss=0.5050, val_auc=0.76530, best=0.76604\n",
      "    Early stopping at epoch 16\n",
      "  ‚úÖ Fold 2 AUC: 0.76604\n",
      "\n",
      "==================================================\n",
      "üìÇ Fold 3/5\n",
      "==================================================\n",
      "    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: 167,425\n",
      "    Epoch 10: loss=0.5004, val_auc=0.75807, best=0.76099\n",
      "    Early stopping at epoch 10\n",
      "  ‚úÖ Fold 3 AUC: 0.76099\n",
      "\n",
      "==================================================\n",
      "üìÇ Fold 4/5\n",
      "==================================================\n",
      "    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: 167,425\n",
      "    Epoch 10: loss=0.5039, val_auc=0.75886, best=0.75890\n",
      "    Epoch 20: loss=0.4919, val_auc=0.75963, best=0.76055\n",
      "    Early stopping at epoch 23\n",
      "  ‚úÖ Fold 4 AUC: 0.76055\n",
      "\n",
      "==================================================\n",
      "üìÇ Fold 5/5\n",
      "==================================================\n",
      "    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: 167,425\n",
      "    Epoch 10: loss=0.5016, val_auc=0.76236, best=0.76333\n",
      "    Early stopping at epoch 17\n",
      "  ‚úÖ Fold 5 AUC: 0.76333\n",
      "\n",
      "============================================================\n",
      "üéâ ÏµúÏ¢Ö Í≤∞Í≥º\n",
      "============================================================\n",
      "üèÜ OOF AUC: 0.75926\n",
      "üìä Fold AUCs: ['0.77699', '0.76604', '0.76099', '0.76055', '0.76333']\n",
      "üìä Mean ¬± Std: 0.76558 ¬± 0.00603\n",
      "\n",
      "üíæ Ï†ÄÏû• ÏôÑÎ£å: submission_ft_full_seed42.csv\n",
      "   ÏòàÏ∏° Î≤îÏúÑ: [0.1420, 0.9929]\n",
      "   ÏòàÏ∏° ÌèâÍ∑†: 0.5183\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 50\n",
    "PATIENCE = 8\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# ÌîºÏ≤ò ÏÑ∏Ìä∏: \"full\" / \"core\" / \"core+qa\"\n",
    "FEATURE_SET = \"full\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n",
    "print(f\"üìä Config: {N_FOLDS}-Fold, epochs={EPOCHS}, batch={BATCH_SIZE}, feature_set={FEATURE_SET}\")\n",
    "\n",
    "# ============================================================\n",
    "# utils\n",
    "# ============================================================\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "def smart_read_csv(primary_path: str, fallback_path: str):\n",
    "    if os.path.exists(primary_path):\n",
    "        return pd.read_csv(primary_path)\n",
    "    return pd.read_csv(fallback_path)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load\n",
    "# ============================================================\n",
    "train_raw = smart_read_csv(\"../../data/raw/train.csv\", \"train.csv\")\n",
    "test_raw  = smart_read_csv(\"../../data/raw/test_x.csv\", \"test_x.csv\")\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "print(f\"ÌÉÄÍ≤ü Î∂ÑÌè¨(ÎØ∏Ìà¨Ìëú=1): {train_raw['voted_bin'].mean():.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Clean\n",
    "# ============================================================\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 0 -> NaN (Î¨¥ÏùëÎãµ)\n",
    "    zero_to_nan_cols = [\"education\", \"engnat\", \"hand\", \"married\", \"urban\"]\n",
    "    for col in zero_to_nan_cols:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # familysize\n",
    "    if \"familysize\" in df.columns:\n",
    "        df.loc[df[\"familysize\"] == 0, \"familysize\"] = np.nan\n",
    "        df.loc[df[\"familysize\"] > 15, \"familysize\"] = np.nan\n",
    "\n",
    "    # TP 0 -> NaN\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    for col in tp_cols:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # QE clip (ms)\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    for col in qe_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].clip(lower=100, upper=60000)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 3. Feature Engineering\n",
    "# ============================================================\n",
    "def build_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # demographics\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    if \"age_group\" in df.columns:\n",
    "        df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "\n",
    "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(int) if \"gender\" in df.columns else 0\n",
    "\n",
    "    df[\"edu_low\"]  = (df[\"education\"] <= 2).astype(float) if \"education\" in df.columns else np.nan\n",
    "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float) if \"education\" in df.columns else np.nan\n",
    "\n",
    "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float) if \"married\" in df.columns else np.nan\n",
    "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float) if \"married\" in df.columns else np.nan\n",
    "\n",
    "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float) if \"urban\" in df.columns else np.nan\n",
    "    df[\"is_rural\"] = (df[\"urban\"] == 1).astype(float) if \"urban\" in df.columns else np.nan\n",
    "\n",
    "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float) if \"engnat\" in df.columns else np.nan\n",
    "\n",
    "    # QA\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    qa_cols = [c for c in qa_cols if c in df.columns]\n",
    "    if len(qa_cols) > 0:\n",
    "        df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
    "        df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
    "        df[\"qa_min\"] = df[qa_cols].min(axis=1)\n",
    "        df[\"qa_max\"] = df[qa_cols].max(axis=1)\n",
    "        df[\"qa_range\"] = df[\"qa_max\"] - df[\"qa_min\"]\n",
    "\n",
    "        df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / len(qa_cols)\n",
    "        df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / len(qa_cols)\n",
    "        df[\"qa_negative_ratio\"] = (df[qa_cols] <= 2).sum(axis=1) / len(qa_cols)\n",
    "        df[\"qa_positive_ratio\"] = (df[qa_cols] >= 4).sum(axis=1) / len(qa_cols)\n",
    "        df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(int)\n",
    "\n",
    "    # QE log + stats\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    qe_cols = [c for c in qe_cols if c in df.columns]\n",
    "    qe_log_cols = []\n",
    "    for col in qe_cols:\n",
    "        newc = f\"{col}_log\"\n",
    "        df[newc] = np.log1p(df[col])\n",
    "        qe_log_cols.append(newc)\n",
    "\n",
    "    if len(qe_cols) > 0:\n",
    "        df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
    "        df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
    "        df[\"qe_log_min\"] = df[qe_log_cols].min(axis=1)\n",
    "        df[\"qe_log_max\"] = df[qe_log_cols].max(axis=1)\n",
    "        df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / len(qe_cols)\n",
    "        df[\"qe_slow_ratio\"] = (df[qe_cols] > 10000).sum(axis=1) / len(qe_cols)\n",
    "        df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
    "\n",
    "        # careless proxy\n",
    "        df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df.get(\"qa_all_same\", 0) == 1)).astype(int)\n",
    "\n",
    "    # TP Big5\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    tp_cols = [c for c in tp_cols if c in df.columns]\n",
    "    if len(tp_cols) > 0:\n",
    "        df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / len(tp_cols)\n",
    "        # big5 diffs (Ï°¥Ïû¨ Í∞ÄÏ†ï)\n",
    "        if set([\"tp01\",\"tp06\"]).issubset(df.columns): df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "        if set([\"tp07\",\"tp02\"]).issubset(df.columns): df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "        if set([\"tp03\",\"tp08\"]).issubset(df.columns): df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "        if set([\"tp04\",\"tp09\"]).issubset(df.columns): df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "        if set([\"tp05\",\"tp10\"]).issubset(df.columns): df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "        df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
    "        df[\"tp_std\"] = df[tp_cols].std(axis=1)\n",
    "\n",
    "    # WR/WF\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    wr_cols = [c for c in wr_cols if c in df.columns]\n",
    "    wf_cols = [c for c in wf_cols if c in df.columns]\n",
    "    if len(wr_cols) > 0:\n",
    "        df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    if len(wf_cols) > 0:\n",
    "        df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "\n",
    "    if \"wr_sum\" in df.columns and \"wf_sum\" in df.columns:\n",
    "        df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "        df[\"vocab_low\"] = (df[\"wr_sum\"] <= 7).astype(int)\n",
    "        df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(int)\n",
    "\n",
    "    # interactions (Í∞ÄÎ≥çÍ≤å)\n",
    "    if \"age_ord\" in df.columns and \"education\" in df.columns:\n",
    "        df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
    "    if \"wr_sum\" in df.columns and \"education\" in df.columns:\n",
    "        df[\"vocab_edu\"] = df[\"wr_sum\"] * df[\"education\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 4. Target Encoding (optional but often helps)\n",
    "# ============================================================\n",
    "def target_encode(train_df, val_df, test_df, col, target_col, smoothing=100):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    agg = train_df.groupby(col)[target_col].agg([\"mean\", \"count\"])\n",
    "    agg[\"te\"] = (agg[\"count\"] * agg[\"mean\"] + smoothing * global_mean) / (agg[\"count\"] + smoothing)\n",
    "    te_map = agg[\"te\"].to_dict()\n",
    "\n",
    "    tr = train_df[col].map(te_map).fillna(global_mean).values\n",
    "    va = val_df[col].map(te_map).fillna(global_mean).values\n",
    "    te = test_df[col].map(te_map).fillna(global_mean).values\n",
    "    return tr, va, te\n",
    "\n",
    "def create_all_target_encodings(train_df, val_df, test_df, target_col=\"voted_bin\"):\n",
    "    te_dict = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "\n",
    "    # smoothing ÌÅ¨Í≤å (Ìù¨ÏÜå Ìäê Î∞©ÏßÄ)\n",
    "    SM_SINGLE = 100\n",
    "    SM_2WAY = 200\n",
    "    SM_3WAY = 500\n",
    "\n",
    "    single_cols = [\"age_group\", \"race\", \"religion\"]\n",
    "    for col in single_cols:\n",
    "        if col in train_df.columns:\n",
    "            tr, va, te = target_encode(train_df, val_df, test_df, col, target_col, smoothing=SM_SINGLE)\n",
    "            te_dict[\"train\"][f\"{col}_te\"] = tr\n",
    "            te_dict[\"val\"][f\"{col}_te\"] = va\n",
    "            te_dict[\"test\"][f\"{col}_te\"] = te\n",
    "\n",
    "    # combos (Î¨∏ÏûêÏó¥ Í≤∞Ìï©)\n",
    "    def make_cat(df, name, cols):\n",
    "        df[name] = df[cols].astype(str).agg(\"_\".join, axis=1)\n",
    "\n",
    "    for df_ in [train_df, val_df, test_df]:\n",
    "        for req in [[\"age_group\",\"education\"], [\"age_group\",\"married\"], [\"age_group\",\"race\"], [\"age_group\",\"education\",\"married\"]]:\n",
    "            if all(c in df_.columns for c in req):\n",
    "                pass\n",
    "\n",
    "    if all(c in train_df.columns for c in [\"age_group\",\"education\"]):\n",
    "        for d in [train_df, val_df, test_df]:\n",
    "            make_cat(d, \"age_edu_cat\", [\"age_group\",\"education\"])\n",
    "        tr, va, te = target_encode(train_df, val_df, test_df, \"age_edu_cat\", target_col, smoothing=SM_2WAY)\n",
    "        te_dict[\"train\"][\"age_edu_te\"] = tr\n",
    "        te_dict[\"val\"][\"age_edu_te\"] = va\n",
    "        te_dict[\"test\"][\"age_edu_te\"] = te\n",
    "\n",
    "    if all(c in train_df.columns for c in [\"age_group\",\"married\"]):\n",
    "        for d in [train_df, val_df, test_df]:\n",
    "            make_cat(d, \"age_married_cat\", [\"age_group\",\"married\"])\n",
    "        tr, va, te = target_encode(train_df, val_df, test_df, \"age_married_cat\", target_col, smoothing=SM_2WAY)\n",
    "        te_dict[\"train\"][\"age_married_te\"] = tr\n",
    "        te_dict[\"val\"][\"age_married_te\"] = va\n",
    "        te_dict[\"test\"][\"age_married_te\"] = te\n",
    "\n",
    "    if all(c in train_df.columns for c in [\"age_group\",\"race\"]):\n",
    "        for d in [train_df, val_df, test_df]:\n",
    "            make_cat(d, \"age_race_cat\", [\"age_group\",\"race\"])\n",
    "        tr, va, te = target_encode(train_df, val_df, test_df, \"age_race_cat\", target_col, smoothing=SM_2WAY)\n",
    "        te_dict[\"train\"][\"age_race_te\"] = tr\n",
    "        te_dict[\"val\"][\"age_race_te\"] = va\n",
    "        te_dict[\"test\"][\"age_race_te\"] = te\n",
    "\n",
    "    if all(c in train_df.columns for c in [\"age_group\",\"education\",\"married\"]):\n",
    "        for d in [train_df, val_df, test_df]:\n",
    "            make_cat(d, \"age_edu_married_cat\", [\"age_group\",\"education\",\"married\"])\n",
    "        tr, va, te = target_encode(train_df, val_df, test_df, \"age_edu_married_cat\", target_col, smoothing=SM_3WAY)\n",
    "        te_dict[\"train\"][\"age_edu_married_te\"] = tr\n",
    "        te_dict[\"val\"][\"age_edu_married_te\"] = va\n",
    "        te_dict[\"test\"][\"age_edu_married_te\"] = te\n",
    "\n",
    "    return te_dict\n",
    "\n",
    "# ============================================================\n",
    "# 5. Feature columns by set\n",
    "# ============================================================\n",
    "def get_feature_cols(df):\n",
    "    qa_cols = [c for c in [f\"Q{ch}A\" for ch in \"abcdefghijklmnopqrst\"] if c in df.columns]\n",
    "    qe_cols = [c for c in [f\"Q{ch}E\" for ch in \"abcdefghijklmnopqrst\"] if c in df.columns]\n",
    "    qe_log_cols = [f\"{c}_log\" for c in qe_cols]  # build_featuresÏóêÏÑú ÏÉùÏÑ±Îê®\n",
    "    tp_cols = [c for c in [f\"tp{i:02d}\" for i in range(1, 11)] if c in df.columns]\n",
    "    wr_cols = [c for c in [f\"wr_{i:02d}\" for i in range(1, 14)] if c in df.columns]\n",
    "    wf_cols = [c for c in [f\"wf_{i:02d}\" for i in range(1, 4)] if c in df.columns]\n",
    "\n",
    "    # Í≥µÌÜµ core\n",
    "    core_num = []\n",
    "    for c in [\"age_ord\",\"education\",\"married\",\"urban\",\"engnat\",\"familysize\",\"hand\",\"is_male\",\n",
    "              \"edu_low\",\"edu_high\",\"is_single\",\"is_married\",\"is_urban\",\"is_rural\",\"is_english_native\",\n",
    "              \"age_edu\",\"vocab_edu\",\n",
    "              \"tp_missing_ratio\",\"tp_mean\",\"tp_std\",\n",
    "              \"extraversion\",\"agreeableness\",\"conscientiousness\",\"neuroticism\",\"openness\",\n",
    "              \"wr_sum\",\"wf_sum\",\"word_credibility\",\"vocab_low\",\"vocab_high\",\n",
    "              \"qe_log_mean\",\"qe_log_std\",\"qe_log_min\",\"qe_log_max\",\"qe_fast_ratio\",\"qe_slow_ratio\",\"qe_total_log\",\n",
    "              \"qa_mean\",\"qa_std\",\"qa_min\",\"qa_max\",\"qa_range\",\"qa_extreme_ratio\",\"qa_neutral_ratio\",\"qa_negative_ratio\",\"qa_positive_ratio\",\"qa_all_same\",\n",
    "              \"is_careless\",\n",
    "             ]:\n",
    "        if c in df.columns:\n",
    "            core_num.append(c)\n",
    "\n",
    "    if FEATURE_SET == \"core\":\n",
    "        num_features = core_num\n",
    "    elif FEATURE_SET == \"core+qa\":\n",
    "        num_features = core_num + qa_cols\n",
    "    else:\n",
    "        # full: ÏõêÎ≥∏ÏùÑ ÏµúÎåÄÌïú Ìè¨Ìï®\n",
    "        num_features = core_num + qa_cols + qe_log_cols + tp_cols + wr_cols + wf_cols\n",
    "\n",
    "    # TE ÌîºÏ≤òÎäî ÎèôÏ†ÅÏúºÎ°ú Î∂ôÏùº Í≤É\n",
    "    te_features = [\n",
    "        \"age_group_te\",\"race_te\",\"religion_te\",\n",
    "        \"age_edu_te\",\"age_married_te\",\"age_race_te\",\"age_edu_married_te\"\n",
    "    ]\n",
    "    cat_features = [c for c in [\"gender\",\"race\",\"religion\"] if c in df.columns]\n",
    "    return num_features, te_features, cat_features\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X_num, X_cat, y=None):\n",
    "        self.X_num = torch.tensor(X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(X_cat, dtype=torch.long)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X_num[idx], self.X_cat[idx]\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "# ============================================================\n",
    "# FT-Transformer (minimal, strong baseline)\n",
    "# ============================================================\n",
    "class FTTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    FT-Transformer style:\n",
    "    - Each numerical feature -> token via Linear(1->d)\n",
    "    - Each categorical feature -> embedding token (d)\n",
    "    - [CLS] token + transformer encoder\n",
    "    - head on CLS\n",
    "    \"\"\"\n",
    "    def __init__(self, n_num, cat_dims, d_token=64, n_heads=8, n_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.n_num = n_num\n",
    "        self.n_cat = len(cat_dims)\n",
    "        self.d = d_token\n",
    "\n",
    "        # numeric tokenizers: one Linear per feature\n",
    "        self.num_tokenizers = nn.ModuleList([nn.Linear(1, d_token) for _ in range(n_num)])\n",
    "\n",
    "        # categorical embeddings\n",
    "        self.cat_embeds = nn.ModuleList([nn.Embedding(dim + 1, d_token) for dim in cat_dims])\n",
    "\n",
    "        # CLS token\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_token))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_token * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_token),\n",
    "            nn.Linear(d_token, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            if isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, std=0.02)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # x_num: (B, n_num)\n",
    "        B = x_num.size(0)\n",
    "        tokens = []\n",
    "\n",
    "        for i in range(self.n_num):\n",
    "            xi = x_num[:, i:i+1]  # (B,1)\n",
    "            tokens.append(self.num_tokenizers[i](xi).unsqueeze(1))  # (B,1,d)\n",
    "\n",
    "        for j in range(self.n_cat):\n",
    "            cj = x_cat[:, j]\n",
    "            tokens.append(self.cat_embeds[j](cj).unsqueeze(1))  # (B,1,d)\n",
    "\n",
    "        x = torch.cat(tokens, dim=1)  # (B, n_tokens, d)\n",
    "        cls = self.cls.expand(B, -1, -1)  # (B,1,d)\n",
    "        x = torch.cat([cls, x], dim=1)  # (B, 1+n_tokens, d)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        cls_out = x[:, 0, :]\n",
    "        return self.head(cls_out)\n",
    "\n",
    "# ============================================================\n",
    "# Train / Predict\n",
    "# ============================================================\n",
    "def train_fold(model, train_loader, val_loader, y_train, y_val, device):\n",
    "    model.to(device)\n",
    "\n",
    "    pos_ratio = float(np.mean(y_train))\n",
    "    pos_weight = torch.tensor([(1 - pos_ratio) / (pos_ratio + 1e-6)], device=device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "    best_auc = -1\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_num, X_cat, y in train_loader:\n",
    "            X_num, X_cat, y = X_num.to(device), X_cat.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_num, X_cat)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for X_num, X_cat, _ in val_loader:\n",
    "                X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "                p = torch.sigmoid(model(X_num, X_cat))\n",
    "                preds.append(p.cpu().numpy())\n",
    "        preds = np.concatenate(preds).ravel()\n",
    "        val_auc = roc_auc_score(y_val, preds)\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        if val_auc > best_auc + 1e-5:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"    Epoch {epoch+1}: loss={total_loss/len(train_loader):.4f}, val_auc={val_auc:.5f}, best={best_auc:.5f}\")\n",
    "\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, best_auc\n",
    "\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if len(batch) == 2:\n",
    "                X_num, X_cat = batch\n",
    "            else:\n",
    "                X_num, X_cat, _ = batch\n",
    "            X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "            p = torch.sigmoid(model(X_num, X_cat))\n",
    "            preds.append(p.cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    train_clean = clean_data(train_raw)\n",
    "    test_clean = clean_data(test_raw)\n",
    "\n",
    "    oof = np.zeros(len(train_clean))\n",
    "    test_pred = np.zeros(len(test_clean))\n",
    "    fold_aucs = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(train_clean, train_clean[\"voted_bin\"])):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"üìÇ Fold {fold+1}/{N_FOLDS}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        tr_df = train_clean.iloc[tr_idx].copy().reset_index(drop=True)\n",
    "        va_df = train_clean.iloc[va_idx].copy().reset_index(drop=True)\n",
    "        te_df = test_clean.copy()\n",
    "\n",
    "        tr_fe = build_features(tr_df)\n",
    "        va_fe = build_features(va_df)\n",
    "        te_fe = build_features(te_df)\n",
    "\n",
    "        num_features, te_features, cat_features = get_feature_cols(tr_fe)\n",
    "\n",
    "        # Target Encoding ÏÉùÏÑ±\n",
    "        te_dict = create_all_target_encodings(tr_fe, va_fe, te_fe, target_col=\"voted_bin\")\n",
    "\n",
    "        # numeric table\n",
    "        all_num = num_features + te_features\n",
    "\n",
    "        X_tr = tr_fe[num_features].copy()\n",
    "        X_va = va_fe[num_features].copy()\n",
    "        X_te = te_fe[num_features].copy()\n",
    "\n",
    "        # append TE (ÏóÜÏúºÎ©¥ global meanÏúºÎ°ú Îì§Ïñ¥Í∞ÄÍ≤åÎÅî te_dictÏóê ÏóÜÎäîÍ±¥ Í±¥ÎÑàÎúÄ)\n",
    "        for tename in te_features:\n",
    "            if tename in te_dict[\"train\"]:\n",
    "                X_tr[tename] = te_dict[\"train\"][tename]\n",
    "                X_va[tename] = te_dict[\"val\"][tename]\n",
    "                X_te[tename] = te_dict[\"test\"][tename]\n",
    "            else:\n",
    "                # Ìï¥Îãπ Ïª¨ÎüºÏù¥ ÏóÜÏúºÎ©¥ Í∑∏ÎÉ• 0ÏúºÎ°ú\n",
    "                X_tr[tename] = 0.0\n",
    "                X_va[tename] = 0.0\n",
    "                X_te[tename] = 0.0\n",
    "\n",
    "        # fillna by train median\n",
    "        for c in all_num:\n",
    "            med = X_tr[c].median()\n",
    "            if pd.isna(med):\n",
    "                med = 0.0\n",
    "            X_tr[c] = X_tr[c].fillna(med)\n",
    "            X_va[c] = X_va[c].fillna(med)\n",
    "            X_te[c] = X_te[c].fillna(med)\n",
    "\n",
    "        # scale (QuantileTransformer)\n",
    "        scaler = QuantileTransformer(\n",
    "            n_quantiles=2000,\n",
    "            output_distribution=\"normal\",\n",
    "            random_state=SEED\n",
    "        )\n",
    "        X_tr_s = scaler.fit_transform(X_tr.values)\n",
    "        X_va_s = scaler.transform(X_va.values)\n",
    "        X_te_s = scaler.transform(X_te.values)\n",
    "\n",
    "        # categorical -> label encoding (fold ÎÇ¥ÏóêÏÑú ÏùºÍ¥Ä)\n",
    "        cat_dims = []\n",
    "        Xc_tr_list, Xc_va_list, Xc_te_list = [], [], []\n",
    "\n",
    "        for col in cat_features:\n",
    "            le = LabelEncoder()\n",
    "            tr_col = tr_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            va_col = va_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "            te_col = te_fe[col].fillna(\"__NAN__\").astype(str)\n",
    "\n",
    "            all_vals = list(set(tr_col.unique()) | set(va_col.unique()) | set(te_col.unique()))\n",
    "            if \"__UNK__\" not in all_vals:\n",
    "                all_vals.append(\"__UNK__\")\n",
    "\n",
    "            le.fit(all_vals)\n",
    "            cat_dims.append(len(le.classes_))\n",
    "\n",
    "            Xc_tr_list.append(le.transform(tr_col))\n",
    "            Xc_va_list.append(le.transform(va_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "            Xc_te_list.append(le.transform(te_col.apply(lambda x: x if x in le.classes_ else \"__UNK__\")))\n",
    "\n",
    "        if len(cat_features) == 0:\n",
    "            # catÏù¥ ÏóÜÏúºÎ©¥ ÎçîÎØ∏ 1Ïª¨Îüº\n",
    "            Xc_tr = np.zeros((len(tr_fe), 1), dtype=np.int64)\n",
    "            Xc_va = np.zeros((len(va_fe), 1), dtype=np.int64)\n",
    "            Xc_te = np.zeros((len(te_fe), 1), dtype=np.int64)\n",
    "            cat_dims = [1]\n",
    "        else:\n",
    "            Xc_tr = np.stack(Xc_tr_list, axis=1)\n",
    "            Xc_va = np.stack(Xc_va_list, axis=1)\n",
    "            Xc_te = np.stack(Xc_te_list, axis=1)\n",
    "\n",
    "        y_tr = tr_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "        y_va = va_fe[\"voted_bin\"].values.astype(np.float32)\n",
    "\n",
    "        train_ds = TabDataset(X_tr_s, Xc_tr, y_tr)\n",
    "        val_ds = TabDataset(X_va_s, Xc_va, y_va)\n",
    "        test_ds = TabDataset(X_te_s, Xc_te)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "        val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        model = FTTransformer(\n",
    "            n_num=X_tr_s.shape[1],\n",
    "            cat_dims=cat_dims,\n",
    "            d_token=64,\n",
    "            n_heads=8,\n",
    "            n_layers=3,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        print(f\"    Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "        model, best_auc = train_fold(model, train_loader, val_loader, y_tr, y_va, DEVICE)\n",
    "        fold_aucs.append(best_auc)\n",
    "\n",
    "        oof[va_idx] = predict(model, val_loader, DEVICE)\n",
    "        test_pred += predict(model, test_loader, DEVICE) / N_FOLDS\n",
    "\n",
    "        print(f\"  ‚úÖ Fold {fold+1} AUC: {best_auc:.5f}\")\n",
    "\n",
    "    final_auc = roc_auc_score(train_clean[\"voted_bin\"], oof)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üèÜ OOF AUC: {final_auc:.5f}\")\n",
    "    print(f\"üìä Fold AUCs: {[f'{x:.5f}' for x in fold_aucs]}\")\n",
    "    print(f\"üìä Mean ¬± Std: {np.mean(fold_aucs):.5f} ¬± {np.std(fold_aucs):.5f}\")\n",
    "\n",
    "    out_name = \"submission_13_FTTransformer_v9_full.csv\"\n",
    "    sub = pd.DataFrame({\n",
    "        \"index\": test_raw[\"index\"] if \"index\" in test_raw.columns else np.arange(len(test_raw)),\n",
    "        \"voted\": test_pred\n",
    "    })\n",
    "    sub.to_csv(out_name, index=False)\n",
    "    print(f\"\\nüíæ Ï†ÄÏû• ÏôÑÎ£å: {out_name}\")\n",
    "    print(f\"   ÏòàÏ∏° Î≤îÏúÑ: [{test_pred.min():.4f}, {test_pred.max():.4f}]\")\n",
    "    print(f\"   ÏòàÏ∏° ÌèâÍ∑†: {test_pred.mean():.4f}\")\n",
    "\n",
    "    return final_auc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}