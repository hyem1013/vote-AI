{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17_v5_FTLight_v1 ÏöîÏïΩ\n",
    "\n",
    "- Î™®Îç∏: v5 Ïã§Ìóò(MLP/FT/ENS ÎπÑÍµê)\n",
    "- ÌîºÏ≤ò: TE_ONLY/RAW_ONLY/SUMMARY_ONLY Î™®Îìú\n",
    "- ÌïôÏäµ/ÌèâÍ∞Ä: KFold 5\n",
    "- Ï†úÏ∂úÌååÏùº: (ÏΩîÎìú ÎÇ¥ Ï†ÄÏû• ÏóÜÏùå)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d21a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FT vs MLP vs ensemble test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c0dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Device: cpu\n",
      "üìÇ Loading data...\n",
      "Train: (45532, 79), Test: (11383, 77)\n",
      "\n",
      "================================================================================\n",
      "üß™ EXPERIMENT: TE_ONLY\n",
      "================================================================================\n",
      "[Fold 1]  MLP=0.77012 | FT=0.76485 | ENS(0.5)=0.76895 | n_feat=5\n",
      "[Fold 2]  MLP=0.76065 | FT=0.75947 | ENS(0.5)=0.76119 | n_feat=5\n",
      "[Fold 3]  MLP=0.75592 | FT=0.75457 | ENS(0.5)=0.75694 | n_feat=5\n",
      "[Fold 4]  MLP=0.75340 | FT=0.74796 | ENS(0.5)=0.75204 | n_feat=5\n",
      "[Fold 5]  MLP=0.75609 | FT=0.74911 | ENS(0.5)=0.75367 | n_feat=5\n",
      "\n",
      "--- OOF SUMMARY ---\n",
      "MLP  OOF AUC: 0.75888 | fold mean: 0.75924\n",
      "FT   OOF AUC: 0.75462 | fold mean: 0.75519\n",
      "ENS  OOF AUC: 0.75823 | fold mean: 0.75856\n",
      "-------------------\n",
      "\n",
      "================================================================================\n",
      "üß™ EXPERIMENT: RAW_ONLY\n",
      "================================================================================\n",
      "[Fold 1]  MLP=0.76326 | FT=0.60543 | ENS(0.5)=0.75472 | n_feat=74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 460\u001b[39m\n\u001b[32m    457\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m12s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | MLP=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33moof_mlp\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | FT=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33moof_ft\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | ENS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33moof_ens\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 451\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    449\u001b[39m results = []\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mTE_ONLY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRAW_ONLY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSUMMARY_ONLY\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     results.append(\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    453\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m    454\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müèÅ FINAL COMPARISON (OOF AUC)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 411\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(mode)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# FT\u001b[39;00m\n\u001b[32m    410\u001b[39m ft = FTTransformer(n_features, d_token=\u001b[32m64\u001b[39m, n_layers=\u001b[32m2\u001b[39m, n_heads=\u001b[32m4\u001b[39m, dropout=\u001b[32m0.2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m ft, auc_ft = \u001b[43mtrain_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m pred_ft = predict(ft, va_pred_loader)\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Ensemble (simple avg)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mtrain_one\u001b[39m\u001b[34m(model, tr_loader, va_loader, y_va, lr)\u001b[39m\n\u001b[32m    299\u001b[39m x,y = x.to(DEVICE), y.to(DEVICE)\n\u001b[32m    300\u001b[39m opt.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m loss = crit(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, y)\n\u001b[32m    302\u001b[39m loss.backward()\n\u001b[32m    303\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 282\u001b[39m, in \u001b[36mFTTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28mcls\u001b[39m = \u001b[38;5;28mself\u001b[39m.cls.expand(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    281\u001b[39m x = torch.cat([\u001b[38;5;28mcls\u001b[39m, x], dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (B, 1+F, D)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.head(x[:,\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/transformer.py:524\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    521\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    532\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/transformer.py:928\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    926\u001b[39m x = src\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm_first:\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/transformer.py:949\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    943\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    944\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    947\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    948\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/modules/activation.py:1488\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1462\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1463\u001b[39m         query,\n\u001b[32m   1464\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1485\u001b[39m         is_causal=is_causal,\n\u001b[32m   1486\u001b[39m     )\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1510\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/torch/nn/functional.py:6487\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6484\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6485\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6487\u001b[39m attn_output = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m   6489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6490\u001b[39m attn_output = (\n\u001b[32m   6491\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6492\u001b[39m )\n\u001b[32m   6494\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 25        # <-- Îπ†Î•∏ ÌåêÎã®Ïö© (Ïú†ÎßùÌïòÎ©¥ 50~80)\n",
    "PATIENCE = 6       # <-- Îπ†Î•∏ ÌåêÎã®Ïö©\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TRAIN_PATH = \"../../data/raw/train.csv\"\n",
    "TEST_PATH  = \"../../data/raw/test_x.csv\"\n",
    "\n",
    "# Î°úÏª¨/ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú ÌååÏùºÎ™ÖÎßå ÏûàÎäî Í≤ΩÏö∞ ÎåÄÎπÑ\n",
    "FALLBACK_TRAIN = \"train.csv\"\n",
    "FALLBACK_TEST  = \"test_x.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# Utils\n",
    "# ============================================================\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "def smart_read_csv(path, fallback):\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    if os.path.exists(fallback):\n",
    "        return pd.read_csv(fallback)\n",
    "    raise FileNotFoundError(f\"Cannot find csv: {path} or {fallback}\")\n",
    "\n",
    "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n",
    "print(\"üìÇ Loading data...\")\n",
    "train_raw = smart_read_csv(TRAIN_PATH, FALLBACK_TRAIN)\n",
    "test_raw  = smart_read_csv(TEST_PATH,  FALLBACK_TEST)\n",
    "\n",
    "train_raw[\"voted_bin\"] = (train_raw[\"voted\"] == 2).astype(int)\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# Clean / Preprocess (ÎÑà ÏΩîÎìú Í∏∞Ï§Ä)\n",
    "# ============================================================\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Î¨¥ÏùëÎãµ (0 -> NaN)\n",
    "    for col in ['education', 'engnat', 'hand', 'married', 'urban']:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # familysize\n",
    "    if 'familysize' in df.columns:\n",
    "        df.loc[df['familysize'] == 0, 'familysize'] = np.nan\n",
    "        df.loc[df['familysize'] > 15, 'familysize'] = np.nan\n",
    "\n",
    "    # TP 0 -> NaN\n",
    "    for col in [f\"tp{i:02d}\" for i in range(1, 11)]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # Q_E clipping\n",
    "    for col in [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].clip(lower=100, upper=60000)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Demographic\n",
    "    age_map = {\"10s\": 1, \"20s\": 2, \"30s\": 3, \"40s\": 4, \"50s\": 5, \"60s\": 6, \"+70s\": 7}\n",
    "    df[\"age_ord\"] = df[\"age_group\"].map(age_map)\n",
    "    df[\"is_teenager\"] = (df[\"age_ord\"] == 1).astype(int)\n",
    "    df[\"is_young\"] = (df[\"age_ord\"] <= 2).astype(int)\n",
    "    df[\"is_old\"] = (df[\"age_ord\"] >= 6).astype(int)\n",
    "    df[\"edu_low\"] = (df[\"education\"] <= 2).astype(float)\n",
    "    df[\"edu_high\"] = (df[\"education\"] >= 3).astype(float)\n",
    "    df[\"is_single\"] = (df[\"married\"] == 1).astype(float)\n",
    "    df[\"is_married\"] = (df[\"married\"] == 2).astype(float)\n",
    "    df[\"is_urban\"] = (df[\"urban\"] == 3).astype(float)\n",
    "    df[\"is_english_native\"] = (df[\"engnat\"] == 1).astype(float)\n",
    "    df[\"is_male\"] = (df[\"gender\"] == \"Male\").astype(int)\n",
    "\n",
    "    # Q_A original cols + summary\n",
    "    qa_cols = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    df[\"qa_mean\"] = df[qa_cols].mean(axis=1)\n",
    "    df[\"qa_std\"] = df[qa_cols].std(axis=1)\n",
    "    df[\"qa_range\"] = df[qa_cols].max(axis=1) - df[qa_cols].min(axis=1)\n",
    "    df[\"qa_extreme_ratio\"] = ((df[qa_cols] == 1) | (df[qa_cols] == 5)).sum(axis=1) / 20\n",
    "    df[\"qa_neutral_ratio\"] = (df[qa_cols] == 3).sum(axis=1) / 20\n",
    "    df[\"qa_all_same\"] = (df[qa_cols].std(axis=1) == 0).astype(int)\n",
    "\n",
    "    # Q_E log + summary\n",
    "    qe_cols = [f\"Q{c}E\" for c in \"abcdefghijklmnopqrst\"]\n",
    "    for col in qe_cols:\n",
    "        df[f\"{col}_log\"] = np.log1p(df[col])\n",
    "    qe_log_cols = [f\"{col}_log\" for col in qe_cols]\n",
    "    df[\"qe_log_mean\"] = df[qe_log_cols].mean(axis=1)\n",
    "    df[\"qe_log_std\"] = df[qe_log_cols].std(axis=1)\n",
    "    df[\"qe_fast_ratio\"] = (df[qe_cols] < 500).sum(axis=1) / 20\n",
    "    df[\"qe_total_log\"] = df[qe_log_cols].sum(axis=1)\n",
    "    df[\"is_careless\"] = ((df[qe_cols].mean(axis=1) < 500) | (df[\"qa_all_same\"] == 1)).astype(int)\n",
    "\n",
    "    # TP + Big5 diff + summary\n",
    "    tp_cols = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "    df[\"tp_missing_ratio\"] = df[tp_cols].isna().sum(axis=1) / 10\n",
    "    df[\"extraversion\"] = df[\"tp01\"] - df[\"tp06\"]\n",
    "    df[\"agreeableness\"] = df[\"tp07\"] - df[\"tp02\"]\n",
    "    df[\"conscientiousness\"] = df[\"tp03\"] - df[\"tp08\"]\n",
    "    df[\"neuroticism\"] = df[\"tp04\"] - df[\"tp09\"]\n",
    "    df[\"openness\"] = df[\"tp05\"] - df[\"tp10\"]\n",
    "    df[\"tp_mean\"] = df[tp_cols].mean(axis=1)\n",
    "\n",
    "    # WR/WF + summary\n",
    "    wr_cols = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "    wf_cols = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "    df[\"wr_sum\"] = df[wr_cols].sum(axis=1)\n",
    "    df[\"wf_sum\"] = df[wf_cols].sum(axis=1)\n",
    "    df[\"word_credibility\"] = df[\"wr_sum\"] - df[\"wf_sum\"]\n",
    "    df[\"vocab_high\"] = (df[\"wr_sum\"] >= 11).astype(int)\n",
    "\n",
    "    # Interactions\n",
    "    df[\"age_edu\"] = df[\"age_ord\"] * df[\"education\"]\n",
    "    df[\"young_low_edu\"] = df[\"is_young\"] * df[\"edu_low\"]\n",
    "    df[\"young_single\"] = df[\"is_young\"] * df[\"is_single\"]\n",
    "    df[\"old_married\"] = df[\"is_old\"] * df[\"is_married\"]\n",
    "    df[\"teenager_low_edu\"] = df[\"is_teenager\"] * df[\"edu_low\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# Target Encoding (CV leak Î∞©ÏßÄ: fold-trainÎßåÏúºÎ°ú map)\n",
    "# ============================================================\n",
    "def target_encode(train_df, val_df, col, target_col, smoothing=10):\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    agg = train_df.groupby(col)[target_col].agg(['mean', 'count'])\n",
    "    te = (agg['count'] * agg['mean'] + smoothing * global_mean) / (agg['count'] + smoothing)\n",
    "    te_map = te.to_dict()\n",
    "    tr = train_df[col].map(te_map).fillna(global_mean).values\n",
    "    va = val_df[col].map(te_map).fillna(global_mean).values\n",
    "    return tr, va\n",
    "\n",
    "def make_te_features(tr_df, va_df, target_col=\"voted_bin\"):\n",
    "    te_names = []\n",
    "    out_tr = {}\n",
    "    out_va = {}\n",
    "\n",
    "    # single\n",
    "    for col in ['age_group', 'race', 'religion']:\n",
    "        tr, va = target_encode(tr_df, va_df, col, target_col, smoothing=10)\n",
    "        name = f\"{col}_te\"\n",
    "        out_tr[name], out_va[name] = tr, va\n",
    "        te_names.append(name)\n",
    "\n",
    "    # combos\n",
    "    tr_df = tr_df.copy()\n",
    "    va_df = va_df.copy()\n",
    "    tr_df['age_edu_cat'] = tr_df['age_group'].astype(str) + '_' + tr_df['education'].astype(str)\n",
    "    va_df['age_edu_cat'] = va_df['age_group'].astype(str) + '_' + va_df['education'].astype(str)\n",
    "    tr_df['age_edu_married_cat'] = tr_df['age_group'].astype(str) + '_' + tr_df['education'].astype(str) + '_' + tr_df['married'].astype(str)\n",
    "    va_df['age_edu_married_cat'] = va_df['age_group'].astype(str) + '_' + va_df['education'].astype(str) + '_' + va_df['married'].astype(str)\n",
    "\n",
    "    for col, sm in [('age_edu_cat', 5), ('age_edu_married_cat', 3)]:\n",
    "        tr, va = target_encode(tr_df, va_df, col, target_col, smoothing=sm)\n",
    "        name = f\"{col}_te\"\n",
    "        out_tr[name], out_va[name] = tr, va\n",
    "        te_names.append(name)\n",
    "\n",
    "    return te_names, out_tr, out_va\n",
    "\n",
    "# ============================================================\n",
    "# Feature Groups (A/B/C Ïã§Ìóò)\n",
    "# ============================================================\n",
    "QA_COLS = [f\"Q{c}A\" for c in \"abcdefghijklmnopqrst\"]\n",
    "QE_LOG_COLS = [f\"Q{c}E_log\" for c in \"abcdefghijklmnopqrst\"]\n",
    "TP_COLS = [f\"tp{i:02d}\" for i in range(1, 11)]\n",
    "WR_COLS = [f\"wr_{i:02d}\" for i in range(1, 14)]\n",
    "WF_COLS = [f\"wf_{i:02d}\" for i in range(1, 4)]\n",
    "\n",
    "SUMMARY_COLS = [\n",
    "    \"age_ord\",\"education\",\"married\",\"urban\",\"engnat\",\"familysize\",\"hand\",\n",
    "    \"is_teenager\",\"is_young\",\"is_old\",\"edu_low\",\"edu_high\",\n",
    "    \"is_single\",\"is_married\",\"is_urban\",\"is_english_native\",\"is_male\",\n",
    "    \"qa_mean\",\"qa_std\",\"qa_range\",\"qa_extreme_ratio\",\"qa_neutral_ratio\",\"qa_all_same\",\n",
    "    \"qe_log_mean\",\"qe_log_std\",\"qe_fast_ratio\",\"qe_total_log\",\"is_careless\",\n",
    "    \"tp_missing_ratio\",\"tp_mean\",\n",
    "    \"extraversion\",\"agreeableness\",\"conscientiousness\",\"neuroticism\",\"openness\",\n",
    "    \"wr_sum\",\"wf_sum\",\"word_credibility\",\"vocab_high\",\n",
    "    \"age_edu\",\"young_low_edu\",\"young_single\",\"old_married\",\"teenager_low_edu\",\n",
    "]\n",
    "\n",
    "def get_feature_set(mode):\n",
    "    \"\"\"\n",
    "    mode:\n",
    "      - \"TE_ONLY\": TEÎßå\n",
    "      - \"RAW_ONLY\": ÏõêÎ≥∏(qa + qe_log + tp + wr/wf + demographic ÏõêÎ≥∏ Î™áÍ∞ú) / TE ÏóÜÏùå\n",
    "      - \"SUMMARY_ONLY\": ÏöîÏïΩ/ÌååÏÉùÎßå / TE ÏóÜÏùå\n",
    "    \"\"\"\n",
    "    if mode == \"TE_ONLY\":\n",
    "        base = []  # TEÎ•º Îí§ÏóêÏÑú Î∂ôÏùº Í±∞Îùº ÎπÑÏõåÎë†\n",
    "        use_te = True\n",
    "    elif mode == \"RAW_ONLY\":\n",
    "        base = QA_COLS + QE_LOG_COLS + TP_COLS + WR_COLS + WF_COLS + [\n",
    "            \"age_ord\",\"education\",\"married\",\"urban\",\"engnat\",\"familysize\",\"hand\",\"is_male\"\n",
    "        ]\n",
    "        use_te = False\n",
    "    elif mode == \"SUMMARY_ONLY\":\n",
    "        base = SUMMARY_COLS\n",
    "        use_te = False\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of: TE_ONLY, RAW_ONLY, SUMMARY_ONLY\")\n",
    "    return base, use_te\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ============================================================\n",
    "# Models\n",
    "# ============================================================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=[256,128,64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers=[]\n",
    "        prev=input_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), nn.BatchNorm1d(h), nn.SiLU(), nn.Dropout(dropout)]\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,1)]\n",
    "        self.net=nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, n_features, d_token=64, n_layers=2, n_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(1, d_token)\n",
    "        self.cls = nn.Parameter(torch.randn(1,1,d_token)*0.02)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token, nhead=n_heads, dim_feedforward=d_token*4,\n",
    "            dropout=dropout, activation=\"gelu\", batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_token), nn.Linear(d_token,1))\n",
    "        self.n_features = n_features\n",
    "    def forward(self,x):\n",
    "        x = x.unsqueeze(-1)     # (B, F, 1)\n",
    "        x = self.embed(x)       # (B, F, D)\n",
    "        cls = self.cls.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)  # (B, 1+F, D)\n",
    "        x = self.tr(x)\n",
    "        return self.head(x[:,0])\n",
    "\n",
    "# ============================================================\n",
    "# Train / Predict\n",
    "# ============================================================\n",
    "def train_one(model, tr_loader, va_loader, y_va, lr=1e-3):\n",
    "    model.to(DEVICE)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    best_auc=-1\n",
    "    best_state=None\n",
    "    bad=0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for x,y in tr_loader:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        # val\n",
    "        model.eval()\n",
    "        preds=[]\n",
    "        with torch.no_grad():\n",
    "            for x,y in va_loader:\n",
    "                x = x.to(DEVICE)\n",
    "                preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "        preds = np.concatenate(preds).ravel()\n",
    "        auc = roc_auc_score(y_va, preds)\n",
    "\n",
    "        if auc > best_auc + 1e-5:\n",
    "            best_auc = auc\n",
    "            best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "            bad=0\n",
    "        else:\n",
    "            bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, best_auc\n",
    "\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    preds=[]\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            if isinstance(x, (tuple,list)):\n",
    "                x = x[0]\n",
    "            x = x.to(DEVICE)\n",
    "            preds.append(torch.sigmoid(model(x)).cpu().numpy())\n",
    "    return np.concatenate(preds).ravel()\n",
    "\n",
    "# ============================================================\n",
    "# Core Experiment Runner\n",
    "# ============================================================\n",
    "def run_experiment(mode=\"TE_ONLY\"):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üß™ EXPERIMENT: {mode}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    set_seed(SEED)\n",
    "\n",
    "    tr = clean_data(train_raw)\n",
    "    tr = build_features(tr)\n",
    "\n",
    "    y = tr[\"voted_bin\"].values.astype(np.float32)\n",
    "\n",
    "    base_cols, use_te = get_feature_set(mode)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    oof_mlp = np.zeros(len(tr))\n",
    "    oof_ft  = np.zeros(len(tr))\n",
    "\n",
    "    fold_auc_mlp=[]\n",
    "    fold_auc_ft=[]\n",
    "    fold_auc_ens=[]\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(tr, y), 1):\n",
    "        tr_df = tr.iloc[tr_idx].reset_index(drop=True)\n",
    "        va_df = tr.iloc[va_idx].reset_index(drop=True)\n",
    "\n",
    "        # Base features\n",
    "        X_tr = tr_df[base_cols].copy() if len(base_cols) else pd.DataFrame(index=range(len(tr_df)))\n",
    "        X_va = va_df[base_cols].copy() if len(base_cols) else pd.DataFrame(index=range(len(va_df)))\n",
    "\n",
    "        # TE features (only if mode says so)\n",
    "        te_cols = []\n",
    "        if use_te:\n",
    "            te_cols, te_tr, te_va = make_te_features(tr_df, va_df, target_col=\"voted_bin\")\n",
    "            for c in te_cols:\n",
    "                X_tr[c] = te_tr[c]\n",
    "                X_va[c] = te_va[c]\n",
    "\n",
    "        # NaN -> median (train fold)\n",
    "        for c in X_tr.columns:\n",
    "            med = X_tr[c].median()\n",
    "            if pd.isna(med):\n",
    "                med = 0\n",
    "            X_tr[c] = X_tr[c].fillna(med)\n",
    "            X_va[c] = X_va[c].fillna(med)\n",
    "\n",
    "        # scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr.values)\n",
    "        X_va_s = scaler.transform(X_va.values)\n",
    "\n",
    "        y_tr = y[tr_idx]\n",
    "        y_va = y[va_idx]\n",
    "\n",
    "        tr_loader = DataLoader(TabDataset(X_tr_s, y_tr), batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        va_loader = DataLoader(TabDataset(X_va_s, y_va), batch_size=BATCH_SIZE, shuffle=False)\n",
    "        va_pred_loader = DataLoader(TabDataset(X_va_s), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        n_features = X_tr_s.shape[1]\n",
    "\n",
    "        # MLP\n",
    "        mlp = MLP(n_features, hidden=[256,128,64], dropout=0.3)\n",
    "        mlp, auc_mlp = train_one(mlp, tr_loader, va_loader, y_va, lr=1e-3)\n",
    "        pred_mlp = predict(mlp, va_pred_loader)\n",
    "\n",
    "        # FT\n",
    "        ft = FTTransformer(n_features, d_token=64, n_layers=2, n_heads=4, dropout=0.2)\n",
    "        ft, auc_ft = train_one(ft, tr_loader, va_loader, y_va, lr=5e-4)\n",
    "        pred_ft = predict(ft, va_pred_loader)\n",
    "\n",
    "        # Ensemble (simple avg)\n",
    "        pred_ens = 0.5 * pred_mlp + 0.5 * pred_ft\n",
    "        auc_ens = roc_auc_score(y_va, pred_ens)\n",
    "\n",
    "        oof_mlp[va_idx] = pred_mlp\n",
    "        oof_ft[va_idx]  = pred_ft\n",
    "\n",
    "        fold_auc_mlp.append(auc_mlp)\n",
    "        fold_auc_ft.append(auc_ft)\n",
    "        fold_auc_ens.append(auc_ens)\n",
    "\n",
    "        print(f\"[Fold {fold}]  MLP={auc_mlp:.5f} | FT={auc_ft:.5f} | ENS(0.5)={auc_ens:.5f} | n_feat={n_features}\")\n",
    "\n",
    "    # OOF summary\n",
    "    oof_auc_mlp = roc_auc_score(y, oof_mlp)\n",
    "    oof_auc_ft  = roc_auc_score(y, oof_ft)\n",
    "    oof_auc_ens = roc_auc_score(y, 0.5*oof_mlp + 0.5*oof_ft)\n",
    "\n",
    "    print(\"\\n--- OOF SUMMARY ---\")\n",
    "    print(f\"MLP  OOF AUC: {oof_auc_mlp:.5f} | fold mean: {np.mean(fold_auc_mlp):.5f}\")\n",
    "    print(f\"FT   OOF AUC: {oof_auc_ft:.5f} | fold mean: {np.mean(fold_auc_ft):.5f}\")\n",
    "    print(f\"ENS  OOF AUC: {oof_auc_ens:.5f} | fold mean: {np.mean(fold_auc_ens):.5f}\")\n",
    "    print(\"-------------------\")\n",
    "\n",
    "    return {\n",
    "        \"mode\": mode,\n",
    "        \"oof_mlp\": oof_auc_mlp,\n",
    "        \"oof_ft\": oof_auc_ft,\n",
    "        \"oof_ens\": oof_auc_ens,\n",
    "        \"fold_mlp\": fold_auc_mlp,\n",
    "        \"fold_ft\": fold_auc_ft,\n",
    "        \"fold_ens\": fold_auc_ens,\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    for mode in [\"TE_ONLY\", \"RAW_ONLY\", \"SUMMARY_ONLY\"]:\n",
    "        results.append(run_experiment(mode))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèÅ FINAL COMPARISON (OOF AUC)\")\n",
    "    print(\"=\"*80)\n",
    "    for r in results:\n",
    "        print(f\"{r['mode']:12s} | MLP={r['oof_mlp']:.5f} | FT={r['oof_ft']:.5f} | ENS={r['oof_ens']:.5f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP + optunaÎ°ú Í∞ÄÏïºÍ≤†Ïùå"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
