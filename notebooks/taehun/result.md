# Voted Prediction Project: Final Analysis Report

본 리포트는 초기 베이스라인 모델 m1부터 최종 SOTA를 달성한 exp26까지의 모델 변천사, 데이터 처리 전략, 그리고 성능 지표를 상세히 기록합니다.

## 1. 모델 변천사 및 개발 로직

프로젝트는 단순한 구조 개선에서 시작하여 점차 모델 간의 다양성을 확보하고 데이터의 본질적 신호를 포착하는 방향으로 진화했습니다.

* **m1 (Base MLP): 기초 수립**
    * **배경:** 표준적인 MLP 구조와 기본적인 수동 스케일링을 통해 프로젝트의 하한선(Baseline)을 설정했습니다.
    * **변화 이유:** 데이터의 기본 분포를 반영하기 위해 질문 답변(Q_A)과 성격 지표(tp)에 적합한 수치적 정규화 로직을 도입했습니다.
* **m2 (AUC Optimization): 지표 최적화**
    * **배경:** 손실 함수(Loss)만 줄이는 것이 실제 평가 지표인 AUC 향상과 직결되지 않는 현상을 확인했습니다.
    * **변화 이유:** 모델 저장 기준을 Loss에서 Validation AUC로 변경하여 리더보드 평가 방식에 직접 대응하는 최적화 방식을 채택했습니다.
* **m4 (SNN/Focal Loss): 다양성 확보**
    * **배경:** 기존 모델들의 상관관계가 0.999에 달해 단순 앙상블 효과가 미미했습니다.
    * **변화 이유:** SELU 활성화 함수와 Focal Loss를 적용한 이질적 구조(SNN)를 도입하여 기존 모델이 포착하지 못한 어려운 샘플에 대한 정보를 확보했습니다.
* **m5 & m6 (Initial & Deep FE): 피처 확장과 시행착오**
    * **배경:** 모델 구조 변경만으로는 성능 한계에 직면하여 피처 엔지니어링을 통한 돌파구를 모색했습니다.
    * **변화 이유:** 마키아벨리즘 지표와 응답 시간 통계를 도입했으나 m6에서는 과도한 시간 관련 피처가 핵심 신호를 희석하는 현상이 발생하여 성능이 하락했습니다.
* **m7 (Refined Deep FE): 본질로의 회귀**
    * **배경:** 복잡한 피처보다 강력한 단일 지표와 데이터 정제가 중요함을 절감했습니다.
    * **변화 이유:** 노이즈를 유발하는 피처를 삭제하고 응답 일관성을 나타내는 Q_Var(분산) 지표를 도입하여 단일 모델 로컬 AUC 최고점을 달성했습니다.
* **exp26 & exp27 (Final Rank Ensemble): 최종 최적화**
    * **배경:** m1의 안정성과 m7의 예리한 분석력을 결합하고자 했습니다.
    * **변화 이유:** 전처리와 구조가 다른 두 모델의 스케일을 표준화하기 위해 Rank Averaging을 도입했습니다. 특정 모델에 가중치를 두는 것보다 5:5 비율로 결합하는 것이 모델 간 균형을 유지하고 변동성에 더 강한 일반화 성능을 보여주었습니다.

## 2. 피처 엔지니어링 및 전처리 전략

데이터의 노이즈를 제거하고 유의미한 심리학적 패턴을 추출하기 위해 다음과 같은 근거로 피처를 조절했습니다.

### 2.1 이상치 처리 (Outlier Handling)
* **가족 수(familysize) 필터링:** familysize가 50을 초과하는 데이터는 응답 신뢰도가 낮다고 판단하여 제거했습니다. 이는 극단적인 수치가 스케일링 및 모델 가중치 학습에 악영향을 주는 것을 방지하기 위함입니다.
* **불성실 응답 제거:** 질문 답변(Q_A)의 표준편차가 0인 데이터(모든 문항에 같은 번호 기입)를 필터링하여 모델이 학습해야 할 변별력 있는 패턴을 보존했습니다.
* **응답 시간(Q_E) Winzorization:** 시간 데이터의 상위 1% 등 극단적인 값은 로그 변환 전 clipping 처리를 통해 이상치로 인한 왜곡을 최소화했습니다.

### 2.2 피처 도입 및 제거 근거
* **응답 시간 로그 변환 (Log1p):** Q_E 데이터는 편차가 매우 커서 모델 학습을 방해하므로 로그 변환을 통해 분포를 정규화했습니다.
* **심리학적 지표 (Mach_Score, Views, Tactics):** 설문의 본질인 마키아벨리즘 성향을 정교하게 반영하기 위해 역채점 로직을 적용한 지표를 생성했습니다.
* **모순 지표 (Conflict_Index):** 상관관계가 높은 특정 문항 간의 응답 괴리율을 계산하여 응답자가 얼마나 신중하게 답변했는지를 수치화했습니다.
* **응답 분산 (Q_Var):** 20개 질문 답변의 분산을 측정하여 응답자의 일관성을 파악했습니다. 이는 m7 모델에서 성능 향상을 이끈 핵심 지표였습니다.
* **시간 비중 피처 제거:** m6에서 시도했던 상대적 시간 비중 피처들은 다중공선성 문제를 일으키고 모델이 노이즈를 학습하게 하여 m7에서는 과감히 삭제되었습니다.

## 3. 모델 성능 비교 요약표

| 모델 ID | 주요 특징 | Local AUC | 메인 LB (Pub) | 비고 |
| :--- | :--- | :--- | :--- | :--- |
| m1 | 기본 MLP (Base) | 0.77212 | 0.78116 | 초기 베이스라인 에이스 |
| m2 | AUC 최적화 모델 | 0.77312 | 0.78108 | 검증 지표를 AUC로 설정 |
| m1+m4 | 92:8 가중 블렌딩 | - | 0.78119 | SNN과의 결합으로 성능 개선 |
| m7 | Refined Deep FE | 0.77375 | - | 단일 모델 최고 로컬 성능 (방향 보정 필요) |
| **exp26** | **m1+m7 Rank (5:5)** | **0.77364** | **0.78150** | **최종 SOTA 달성 모델** |
| exp27 | m1+m7 Rank (4:6) | 0.77379 | - | 로컬 점수는 높으나 일반화 한계 노출 |

**결론:** 본 프로젝트는 데이터 정합성 해결(Index Alignment)과 모델 간의 방향성 통일을 통해 초기 성능의 한계를 극복했습니다. 특히 로컬 성능에만 의존하지 않고 모델 간의 균형을 맞춘 5:5 랭크 앙상블을 통해 최종적인 일반화 성능을 확보할 수 있었습니다.