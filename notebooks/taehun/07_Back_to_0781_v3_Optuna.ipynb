{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb2a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-31 23:10:36,454] A new study created in memory with name: no-name-a285bcc4-cce2-42e7-af8a-4beee1f2c159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Phase 1: Hyperparameter Optimization (Optuna)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-31 23:11:36,535] Trial 0 finished with value: 0.7696615005139787 and parameters: {'h1': 512, 'h2': 16, 'drop_rate': 0.5760850656580785}. Best is trial 0 with value: 0.7696615005139787.\n",
      "[I 2026-01-31 23:12:27,649] Trial 1 finished with value: 0.769289650857918 and parameters: {'h1': 224, 'h2': 24, 'drop_rate': 0.5545884692375175}. Best is trial 0 with value: 0.7696615005139787.\n",
      "[I 2026-01-31 23:13:19,917] Trial 2 finished with value: 0.7693281368839825 and parameters: {'h1': 256, 'h2': 40, 'drop_rate': 0.5228758292886999}. Best is trial 0 with value: 0.7696615005139787.\n",
      "[I 2026-01-31 23:14:09,848] Trial 3 finished with value: 0.7698969326095025 and parameters: {'h1': 160, 'h2': 64, 'drop_rate': 0.3140080126847166}. Best is trial 3 with value: 0.7698969326095025.\n",
      "[I 2026-01-31 23:15:00,428] Trial 4 finished with value: 0.7705013786202648 and parameters: {'h1': 320, 'h2': 16, 'drop_rate': 0.4293558393863447}. Best is trial 4 with value: 0.7705013786202648.\n",
      "[I 2026-01-31 23:15:50,510] Trial 5 finished with value: 0.7699486464844302 and parameters: {'h1': 192, 'h2': 40, 'drop_rate': 0.34039619743152905}. Best is trial 4 with value: 0.7705013786202648.\n",
      "[I 2026-01-31 23:16:40,201] Trial 6 finished with value: 0.7699835599386732 and parameters: {'h1': 288, 'h2': 24, 'drop_rate': 0.3172230846366886}. Best is trial 4 with value: 0.7705013786202648.\n",
      "[I 2026-01-31 23:17:29,855] Trial 7 finished with value: 0.7706650580442266 and parameters: {'h1': 288, 'h2': 64, 'drop_rate': 0.37915667558151395}. Best is trial 7 with value: 0.7706650580442266.\n",
      "[I 2026-01-31 23:18:20,574] Trial 8 finished with value: 0.7699922595423091 and parameters: {'h1': 192, 'h2': 16, 'drop_rate': 0.4472686387851209}. Best is trial 7 with value: 0.7706650580442266.\n",
      "[I 2026-01-31 23:19:11,521] Trial 9 finished with value: 0.7690327932870685 and parameters: {'h1': 192, 'h2': 56, 'drop_rate': 0.5597937287943511}. Best is trial 7 with value: 0.7706650580442266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best Parameters]: {'h1': 288, 'h2': 64, 'drop_rate': 0.37915667558151395}\n",
      "\n",
      ">>> Phase 2: Final Training with 5-Repeat 7-Fold\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e4853f72de4434bf5d7f87b8e6d9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeat 1/5:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732a61f657054bd487b3ef9055071854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeat 2/5:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80f90b7e0b64486b63b8bd2684610c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeat 3/5:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e04f2c6dd9e41d08c925a5083657ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeat 4/5:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3376823a36e7405fb0118c6c08900158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeat 5/5:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Mean Validation AUC: 0.77272\n",
      ">>> Saving submission file...\n",
      "File Saved: ./submissions/Optuna_Hybrid_0131_2354_AUC_0.7727.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# 1. 경로 및 환경 설정\n",
    "DATA_PATH = \"../../data/raw/\"\n",
    "SUB_PATH = \"./submissions/\"\n",
    "DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "if not os.path.exists(SUB_PATH):\n",
    "    os.makedirs(SUB_PATH)\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "# 2. 데이터 전처리 (사용자 검증 로직 100% 반영)\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE', 'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE', 'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}\n",
    "\n",
    "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
    "test_data = pd.read_csv(f'{DATA_PATH}test_x.csv')\n",
    "train_data = train_data.drop(train_data[train_data.familysize > 50].index)\n",
    "\n",
    "train_y = train_data['voted']\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1).astype(replace_dict)\n",
    "test_x = test_data.drop(drop_list, axis=1).astype(replace_dict)\n",
    "\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "\n",
    "train_y = (2 - train_y.to_numpy()).astype(np.float32)\n",
    "train_x = train_x.to_numpy().astype(np.float32)\n",
    "test_x = test_x.to_numpy().astype(np.float32)\n",
    "\n",
    "train_x_t = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y_t = torch.tensor(train_y, dtype=torch.float32)\n",
    "test_x_t = torch.tensor(test_x, dtype=torch.float32)\n",
    "\n",
    "# 수동 스케일링 로직\n",
    "train_x_t[:, :20] = (train_x_t[:, :20] - 3.) / 2.\n",
    "test_x_t[:, :20] = (test_x_t[:, :20] - 3.) / 2.\n",
    "train_x_t[:, 20] = (train_x_t[:, 20] - 5.) / 4.\n",
    "test_x_t[:, 20] = (test_x_t[:, 20] - 5.) / 4.\n",
    "train_x_t[:, 21:31] = (train_x_t[:, 21:31] - 3.5) / 3.5\n",
    "test_x_t[:, 21:31] = (test_x_t[:, 21:31] - 3.5) / 3.5\n",
    "\n",
    "# 3. 모델 정의\n",
    "class DynamicMLP(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, drop_rate):\n",
    "        super(DynamicMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(input_dim, h1, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(h1, h2, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(h2, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 4. Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    h1 = trial.suggest_int(\"h1\", 128, 512, step=32)\n",
    "    h2 = trial.suggest_int(\"h2\", 16, 64, step=8)\n",
    "    drop_rate = trial.suggest_float(\"drop_rate\", 0.3, 0.6)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_aucs = []\n",
    "    \n",
    "    for t_idx, v_idx in skf.split(train_x_t, train_y_t):\n",
    "        t_loader = DataLoader(TensorDataset(train_x_t[t_idx], train_y_t[t_idx]), batch_size=72, shuffle=True)\n",
    "        v_loader = DataLoader(TensorDataset(train_x_t[v_idx], train_y_t[v_idx]), batch_size=72, shuffle=False)\n",
    "        \n",
    "        model = DynamicMLP(91, h1, h2, drop_rate).to(DEVICE)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=7.8e-2)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        \n",
    "        best_auc = 0\n",
    "        for epoch in range(15):\n",
    "            model.train()\n",
    "            for xx, yy in t_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xx.to(DEVICE)).view(-1), yy.to(DEVICE))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            v_preds = []\n",
    "            with torch.no_grad():\n",
    "                for vx, _ in v_loader:\n",
    "                    v_preds.extend(torch.sigmoid(model(vx.to(DEVICE)).view(-1)).cpu().numpy())\n",
    "            auc = roc_auc_score(train_y_t[v_idx].numpy(), v_preds)\n",
    "            best_auc = max(best_auc, auc)\n",
    "        cv_aucs.append(best_auc)\n",
    "    return np.mean(cv_aucs)\n",
    "\n",
    "# 5. 메인 실행 루프\n",
    "if __name__ == \"__main__\":\n",
    "    print(\">>> Phase 1: Hyperparameter Optimization (Optuna)\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(f\"\\n[Best Parameters]: {best_params}\")\n",
    "\n",
    "    print(\"\\n>>> Phase 2: Final Training with 5-Repeat 7-Fold\")\n",
    "    N_REPEAT = 5\n",
    "    N_SKFOLD = 7\n",
    "    final_predictions = np.zeros((len(test_x_t), 1))\n",
    "    total_val_aucs = []\n",
    "\n",
    "    for r in range(N_REPEAT):\n",
    "        skf = StratifiedKFold(n_splits=N_SKFOLD, random_state=r, shuffle=True)\n",
    "        pbar = tqdm(enumerate(skf.split(train_x_t, train_y_t)), total=N_SKFOLD, desc=f\"Repeat {r+1}/{N_REPEAT}\")\n",
    "        \n",
    "        for f, (t_idx, v_idx) in pbar:\n",
    "            t_loader = DataLoader(TensorDataset(train_x_t[t_idx], train_y_t[t_idx]), batch_size=72, shuffle=True)\n",
    "            v_loader = DataLoader(TensorDataset(train_x_t[v_idx], train_y_t[v_idx]), batch_size=72, shuffle=False)\n",
    "            \n",
    "            model = DynamicMLP(91, best_params['h1'], best_params['h2'], best_params['drop_rate']).to(DEVICE)\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=7.8e-2)\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=8, eta_min=4e-4)\n",
    "            criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "            \n",
    "            best_fold_auc = 0\n",
    "            best_fold_pred = np.zeros((len(test_x_t), 1))\n",
    "            \n",
    "            for epoch in range(48):\n",
    "                model.train()\n",
    "                for xx, yy in t_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(model(xx.to(DEVICE)).view(-1), yy.to(DEVICE))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step(epoch)\n",
    "                \n",
    "                model.eval()\n",
    "                v_preds = []\n",
    "                with torch.no_grad():\n",
    "                    for vx, _ in v_loader:\n",
    "                        v_preds.extend(torch.sigmoid(model(vx.to(DEVICE)).view(-1)).cpu().numpy())\n",
    "                \n",
    "                curr_auc = roc_auc_score(train_y_t[v_idx].numpy(), v_preds)\n",
    "                if curr_auc > best_fold_auc:\n",
    "                    best_fold_auc = curr_auc\n",
    "                    with torch.no_grad():\n",
    "                        p = (2. - torch.sigmoid(model(test_x_t.to(DEVICE)).view(-1, 1))).cpu().numpy()\n",
    "                        best_fold_pred = p\n",
    "            \n",
    "            total_val_aucs.append(best_fold_auc)\n",
    "            final_predictions += best_fold_pred / (N_REPEAT * N_SKFOLD)\n",
    "            pbar.set_postfix({'Fold_AUC': f'{best_fold_auc:.4f}'})\n",
    "            del model; gc.collect()\n",
    "\n",
    "    mean_auc = np.mean(total_val_aucs)\n",
    "    print(f\"\\nFinal Mean Validation AUC: {mean_auc:.5f}\")\n",
    "\n",
    "    # 점수 상관없이 무조건 생성\n",
    "    print(\">>> Saving submission file...\")\n",
    "    submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "    submission['voted'] = final_predictions\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "    filename = f\"{SUB_PATH}Optuna_Hybrid_{timestamp}_AUC_{mean_auc:.4f}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"File Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395a8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
