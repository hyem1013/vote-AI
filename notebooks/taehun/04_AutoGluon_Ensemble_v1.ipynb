{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf78331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5 학습 시작...\n",
      "   Fold 1 완료: MLP AUC=0.7688, FT AUC=0.7790\n",
      "\n",
      "Fold 2/5 학습 시작...\n",
      "   Fold 2 완료: MLP AUC=0.7621, FT AUC=0.7726\n",
      "\n",
      "Fold 3/5 학습 시작...\n",
      "   Fold 3 완료: MLP AUC=0.7556, FT AUC=0.7627\n",
      "\n",
      "Fold 4/5 학습 시작...\n",
      "   Fold 4 완료: MLP AUC=0.7534, FT AUC=0.7617\n",
      "\n",
      "Fold 5/5 학습 시작...\n",
      "   Fold 5 완료: MLP AUC=0.7593, FT AUC=0.7655\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.auto import tqdm\n",
    "from rtdl_revisiting_models import FTTransformer\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# [1] 환경 설정 및 시드 고정\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available(): torch.mps.manual_seed(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DATA_PATH = \"../../data/raw/\"\n",
    "SUB_PATH = \"./submissions/\"\n",
    "\n",
    "# [2] 전처리 파이프라인 (MLP용 & FT용 분리)\n",
    "def get_smoothed_map(train_df, col, target_col, m=10):\n",
    "    overall_mean = train_df[target_col].mean()\n",
    "    stats = train_df.groupby(col)[target_col].agg(['count', 'mean'])\n",
    "    smooth_map = (stats['count'] * stats['mean'] + m * overall_mean) / (stats['count'] + m)\n",
    "    return smooth_map, overall_mean\n",
    "\n",
    "def load_and_preprocess():\n",
    "    train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "    test = pd.read_csv(DATA_PATH + 'test_x.csv')\n",
    "    train['voted'] = train['voted'].replace({2: 1, 1: 0})\n",
    "\n",
    "    def common_engineering(df):\n",
    "        qa_cols = [f'Q{i}A' for i in 'abcdefghijklmnopqrst']\n",
    "        df['mach_score'] = df[qa_cols].mean(axis=1)\n",
    "        qe_cols = [f'Q{i}E' for i in 'abcdefghijklmnopqrst']\n",
    "        for col in qe_cols:\n",
    "            df[col] = np.log1p(df[col].clip(upper=df[col].quantile(0.99)))\n",
    "        df['familysize'] = df['familysize'].clip(upper=df['familysize'].quantile(0.99))\n",
    "        df['tp_Extraversion'] = (df['tp01'] + (7 - df['tp06'])) / 2\n",
    "        df['tp_Agreeableness'] = ((7 - df['tp02']) + df['tp07']) / 2\n",
    "        df['tp_Conscientiousness'] = (df['tp03'] + (7 - df['tp08'])) / 2\n",
    "        df['tp_EmotionalStability'] = ((7 - df['tp04']) + df['tp09']) / 2\n",
    "        df['tp_Openness'] = (df['tp05'] + (7 - df['tp10'])) / 2\n",
    "        df['wr_total'] = df[[f'wr_{i:02d}' for i in range(1, 14)]].sum(axis=1)\n",
    "        df['wf_total'] = df[[f'wf_{i:02d}' for i in range(1, 4)]].sum(axis=1)\n",
    "        df['gender_val'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
    "        df['age_encoded'] = df['age_group'].str.extract('(\\d+)').astype(float).fillna(60).replace(0, 60)\n",
    "        return df\n",
    "\n",
    "    train = common_engineering(train)\n",
    "    test = common_engineering(test)\n",
    "\n",
    "    # --- MLP용 전처리 (Target Encoding) ---\n",
    "    target_enc_cols = ['race', 'religion', 'urban', 'education', 'hand', 'married', 'engnat']\n",
    "    train_mlp = train.copy()\n",
    "    test_mlp = test.copy()\n",
    "    for col in target_enc_cols:\n",
    "        smooth_map, global_mean = get_smoothed_map(train, col, 'voted', m=10)\n",
    "        train_mlp[f'{col}_enc'] = train[col].map(smooth_map)\n",
    "        test_mlp[f'{col}_enc'] = test[col].map(smooth_map).fillna(global_mean)\n",
    "\n",
    "    # --- FT용 전처리 (Label Encoding) ---\n",
    "    cat_cols = ['race', 'religion', 'urban', 'education', 'hand', 'married', 'engnat', 'gender']\n",
    "    train_ft = train.copy()\n",
    "    test_ft = test.copy()\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([train[col].astype(str), test[col].astype(str)])\n",
    "        le.fit(combined)\n",
    "        train_ft[col] = le.transform(train_ft[col].astype(str))\n",
    "        test_ft[col] = le.transform(test_ft[col].astype(str))\n",
    "\n",
    "    # 컬럼 드랍 리스트\n",
    "    drop_list = [f'tp{i:02d}' for i in range(1, 11)] + [f'wr_{i:02d}' for i in range(1, 14)] + \\\n",
    "                [f'wf_{i:02d}' for i in range(1, 4)] + ['age_group', 'index', 'gender']\n",
    "    \n",
    "    # MLP 최종 데이터\n",
    "    X_mlp = train_mlp.drop(columns=['voted'] + drop_list + target_enc_cols, errors='ignore')\n",
    "    X_test_mlp = test_mlp.drop(columns=drop_list + target_enc_cols, errors='ignore')\n",
    "    \n",
    "    # FT 최종 데이터\n",
    "    X_ft_all = train_ft.drop(columns=['voted'] + drop_list, errors='ignore')\n",
    "    num_cols = [c for c in X_ft_all.columns if c not in cat_cols]\n",
    "    cardinalities = [train_ft[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return X_mlp, X_test_mlp, train_ft[num_cols], test_ft[num_cols], train_ft[cat_cols], test_ft[cat_cols], train['voted'], cardinalities\n",
    "\n",
    "# 데이터 로드 실행\n",
    "X_mlp, X_test_mlp, ft_num, ft_test_num, ft_cat, ft_test_cat, y, cardinalities = load_and_preprocess()\n",
    "\n",
    "# 스케일링\n",
    "sc_mlp = StandardScaler()\n",
    "X_mlp_sc = sc_mlp.fit_transform(X_mlp)\n",
    "X_test_mlp_sc = sc_mlp.transform(X_test_mlp)\n",
    "\n",
    "sc_ft = StandardScaler()\n",
    "ft_num_sc = sc_ft.fit_transform(ft_num)\n",
    "ft_test_num_sc = sc_ft.transform(ft_test_num)\n",
    "\n",
    "# [3] OOF 추출 (5-Fold)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "mlp_oof = np.zeros(len(y))\n",
    "ft_oof = np.zeros(len(y))\n",
    "mlp_test_preds = np.zeros(len(X_test_mlp))\n",
    "ft_test_preds = np.zeros(len(ft_test_num))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_mlp_sc, y)):\n",
    "    print(f\"\\nFold {fold+1}/{n_splits} 학습 시작...\")\n",
    "    \n",
    "    # --- MLP Fold 학습 ---\n",
    "    X_tr_m = torch.tensor(X_mlp_sc[train_idx], dtype=torch.float32).to(DEVICE)\n",
    "    y_tr_m = torch.tensor(y.values[train_idx], dtype=torch.float32).view(-1, 1).to(DEVICE)\n",
    "    X_va_m = torch.tensor(X_mlp_sc[val_idx], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    mlp_model = nn.Sequential(\n",
    "        nn.Linear(X_mlp_sc.shape[1], 256), nn.LeakyReLU(0.05), nn.Dropout(0.3),\n",
    "        nn.Linear(256, 32), nn.ReLU(), nn.Linear(32, 1)\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    opt_m = optim.AdamW(mlp_model.parameters(), lr=0.001)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loader_m = DataLoader(TensorDataset(X_tr_m, y_tr_m), batch_size=1024, shuffle=True)\n",
    "    for _ in range(25):\n",
    "        mlp_model.train()\n",
    "        for bx, by in loader_m:\n",
    "            opt_m.zero_grad(); crit(mlp_model(bx), by).backward(); opt_m.step()\n",
    "    \n",
    "    mlp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        mlp_oof[val_idx] = torch.sigmoid(mlp_model(X_va_m).squeeze()).cpu().numpy()\n",
    "        mlp_test_preds += torch.sigmoid(mlp_model(torch.tensor(X_test_mlp_sc, dtype=torch.float32).to(DEVICE)).squeeze()).cpu().numpy() / n_splits\n",
    "\n",
    "    # --- FT-Transformer Fold 학습 ---\n",
    "    X_n_tr = torch.tensor(ft_num_sc[train_idx], dtype=torch.float32).to(DEVICE)\n",
    "    X_c_tr = torch.tensor(ft_cat.values[train_idx], dtype=torch.long).to(DEVICE)\n",
    "    y_tr_f = torch.tensor(y.values[train_idx], dtype=torch.float32).view(-1, 1).to(DEVICE)\n",
    "    X_n_va = torch.tensor(ft_num_sc[val_idx], dtype=torch.float32).to(DEVICE)\n",
    "    X_c_va = torch.tensor(ft_cat.values[val_idx], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    ft_model = FTTransformer(\n",
    "        n_cont_features=ft_num_sc.shape[1], cat_cardinalities=cardinalities, d_out=1,\n",
    "        _is_default=False, n_blocks=3, d_block=128, attention_n_heads=8,\n",
    "        ffn_d_hidden_multiplier=4/3, attention_dropout=0.2, ffn_dropout=0.2, residual_dropout=0.0\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    opt_f = optim.AdamW(ft_model.parameters(), lr=0.0005)\n",
    "    loader_f = DataLoader(TensorDataset(X_n_tr, X_c_tr, y_tr_f), batch_size=512, shuffle=True)\n",
    "    \n",
    "    for _ in range(15): # 시간 단축을 위해 15 에포크\n",
    "        ft_model.train()\n",
    "        for bn, bc, by in loader_f:\n",
    "            opt_f.zero_grad(); crit(ft_model(bn, bc), by).backward(); opt_f.step()\n",
    "            \n",
    "    ft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        ft_oof[val_idx] = torch.sigmoid(ft_model(X_n_va, X_c_va).squeeze()).cpu().numpy()\n",
    "        ft_test_preds += torch.sigmoid(ft_model(torch.tensor(ft_test_num_sc, dtype=torch.float32).to(DEVICE), \n",
    "                                               torch.tensor(ft_test_cat.values, dtype=torch.long).to(DEVICE)).squeeze()).cpu().numpy() / n_splits\n",
    "    print(f\"   Fold {fold+1} 완료: MLP AUC={roc_auc_score(y.values[val_idx], mlp_oof[val_idx]):.4f}, FT AUC={roc_auc_score(y.values[val_idx], ft_oof[val_idx]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6243ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20260130_040248\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Thu Sep 12 23:35:29 PDT 2024; root:xnu-10063.141.1.701.1~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Pytorch Version:    2.9.1\n",
      "CUDA Version:       CUDA is not available\n",
      "GPU Count:          WARNING: Exception was raised when calculating GPU count (AssertionError)\n",
      "Memory Avail:       2.56 GB / 16.00 GB (16.0%)\n",
      "Disk Space Avail:   369.02 GB / 460.43 GB (80.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "Running DyStack sub-fit ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "딥러닝 전용 AutoGluon 앙상블 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 225s\n",
      "AutoGluon will save models to \"/Users/admin/AI_HC/prj_01/vote-AI-1/notebooks/taehun/AutogluonModels/ag-20260130_040248/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    40472\n",
      "Train Data Columns: 2\n",
      "Label Column:       target\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2621.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.62 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['custom_mlp', 'custom_ft']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['custom_mlp', 'custom_ft']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.62 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'FT_TRANSFORMER': [{}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 149.92s of the 224.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=5, gpus=0, memory=0.40%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 딥러닝 계열 모델만 사용하도록 지정\u001b[39;00m\n\u001b[32m     16\u001b[39m deep_learning_models = {\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNN_TORCH\u001b[39m\u001b[33m'\u001b[39m: {},           \u001b[38;5;66;03m# PyTorch 기반 신경망\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFASTAI\u001b[39m\u001b[33m'\u001b[39m: {},             \u001b[38;5;66;03m# FastAI 기반 신경망\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFT_TRANSFORMER\u001b[39m\u001b[33m'\u001b[39m: {},     \u001b[38;5;66;03m# AutoGluon 내장 FT-Transformer\u001b[39;00m\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m predictor = \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroc_auc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_learning_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 머신러닝 트리 모델 제외\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_quality\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# 스태킹(Stacking) 활성화\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;66;43;03m# M1 Pro GPU 가속 활용 시도\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m900\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# 15분 정도 충분히 탐색\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# [5] 앙상블 리더보드에서 최고 AUC 값 가져오기\u001b[39;00m\n\u001b[32m     35\u001b[39m leaderboard = predictor.leaderboard(silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/common/utils/decorators.py:34\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     33\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1393\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamic_stacking:\n\u001b[32m   1388\u001b[39m     logger.log(\n\u001b[32m   1389\u001b[39m         \u001b[32m20\u001b[39m,\n\u001b[32m   1390\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDyStack is enabled (dynamic_stacking=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1391\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1392\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1393\u001b[39m     num_stack_levels, time_limit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dynamic_stacking\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mds_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m     logger.info(\n\u001b[32m   1395\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting main fit with num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1396\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mFor future fit calls on this dataset, you can skip DyStack to save time: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1397\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`predictor.fit(..., dynamic_stacking=False, num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1398\u001b[39m     )\n\u001b[32m   1400\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (time_limit <= \u001b[32m0\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1493\u001b[39m, in \u001b[36mTabularPredictor._dynamic_stacking\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, enable_callbacks, holdout_data)\u001b[39m\n\u001b[32m   1490\u001b[39m         _, holdout_data, _, _ = \u001b[38;5;28mself\u001b[39m._validate_fit_data(train_data=X, tuning_data=holdout_data)\n\u001b[32m   1491\u001b[39m         ds_fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33mds_fit_context\u001b[39m\u001b[33m\"\u001b[39m] = os.path.join(ds_fit_context, \u001b[33m\"\u001b[39m\u001b[33msub_fit_custom_ho\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m     stacked_overfitting = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sub_fit_memory_save_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_ag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_ag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1503\u001b[39m     \u001b[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001b[39;00m\n\u001b[32m   1504\u001b[39m     is_stratified = \u001b[38;5;28mself\u001b[39m.problem_type \u001b[38;5;129;01min\u001b[39;00m [BINARY, MULTICLASS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1713\u001b[39m, in \u001b[36mTabularPredictor._sub_fit_memory_save_wrapper\u001b[39m\u001b[34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[39m\n\u001b[32m   1710\u001b[39m     normal_fit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_fit:\n\u001b[32m-> \u001b[39m\u001b[32m1713\u001b[39m     stacked_overfitting, ho_leaderboard, exception = \u001b[43m_dystack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1724\u001b[39m     logger.log(\u001b[32m40\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarning: Exception encountered during DyStack sub-fit:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:5888\u001b[39m, in \u001b[36m_dystack\u001b[39m\u001b[34m(predictor, train_data, time_limit, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[39m\n\u001b[32m   5886\u001b[39m logger.log(\u001b[32m20\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning DyStack sub-fit ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5887\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5888\u001b[39m     \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5889\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   5890\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1418\u001b[39m, in \u001b[36mTabularPredictor._fit\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[39m\n\u001b[32m   1416\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, ag_fit_kwargs: \u001b[38;5;28mdict\u001b[39m, ag_post_fit_kwargs: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28mself\u001b[39m.save(silent=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_post_fit_vars()\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_fit(**ag_post_fit_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:159\u001b[39m, in \u001b[36mAbstractTabularLearner.fit\u001b[39m\u001b[34m(self, X, X_val, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLearner is already fit.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_fit_input(X=X, X_val=X_val, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:133\u001b[39m, in \u001b[36mDefaultLearner._fit\u001b[39m\u001b[34m(self, X, X_val, X_test, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, raise_on_model_failure, **trainer_fit_kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m.eval_metric = trainer.eval_metric\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit_trainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_cleaner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_cleaner\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrainer_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.save_trainer(trainer=trainer)\n\u001b[32m    150\u001b[39m time_end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/auto_trainer.py:140\u001b[39m, in \u001b[36mAutoTrainer.fit\u001b[39m\u001b[34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, callbacks, label_cleaner, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_cleaner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    138\u001b[39m     core_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlabel_cleaner\u001b[39m\u001b[33m\"\u001b[39m] = label_cleaner\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_and_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:3345\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_and_ensemble\u001b[39m\u001b[34m(self, X, y, X_val, y_val, X_test, y_test, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[39m\n\u001b[32m   3343\u001b[39m     \u001b[38;5;28mself\u001b[39m._num_rows_test = \u001b[38;5;28mlen\u001b[39m(X_test)\n\u001b[32m   3344\u001b[39m \u001b[38;5;28mself\u001b[39m._num_cols_train = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(X.columns))\n\u001b[32m-> \u001b[39m\u001b[32m3345\u001b[39m model_names_fit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_multi_levels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3347\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3350\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3358\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_model_names()) == \u001b[32m0\u001b[39m:\n\u001b[32m   3360\u001b[39m     \u001b[38;5;66;03m# TODO v1.0: Add toggle to raise exception if no models trained\u001b[39;00m\n\u001b[32m   3361\u001b[39m     logger.log(\u001b[32m30\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWarning: AutoGluon did not successfully train any models\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:506\u001b[39m, in \u001b[36mAbstractTabularTrainer.train_multi_levels\u001b[39m\u001b[34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size, callbacks)\u001b[39m\n\u001b[32m    504\u001b[39m         core_kwargs_level[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = core_kwargs_level.get(\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m, time_limit_core)\n\u001b[32m    505\u001b[39m         aux_kwargs_level[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = aux_kwargs_level.get(\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m, time_limit_aux)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     base_model_names, aux_models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_new_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcore_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m     model_names_fit += base_model_names + aux_models\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.model_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_names_fit) != \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:736\u001b[39m, in \u001b[36mAbstractTabularTrainer.stack_new_level\u001b[39m\u001b[34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[39m\n\u001b[32m    734\u001b[39m     core_kwargs[\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m] = core_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + name_suffix\n\u001b[32m    735\u001b[39m     aux_kwargs[\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m] = aux_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + name_suffix\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m core_models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_new_level_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m aux_models = []\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_weighted_ensemble:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:887\u001b[39m, in \u001b[36mAbstractTabularTrainer.stack_new_level_core\u001b[39m\u001b[34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, fit_strategy, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[39m\n\u001b[32m    881\u001b[39m fit_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    882\u001b[39m     num_classes=\u001b[38;5;28mself\u001b[39m.num_classes,\n\u001b[32m    883\u001b[39m     feature_metadata=feature_metadata,\n\u001b[32m    884\u001b[39m )\n\u001b[32m    886\u001b[39m \u001b[38;5;66;03m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:3277\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi\u001b[39m\u001b[34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, delay_bag_sets, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_repeat_start == \u001b[32m0\u001b[39m:\n\u001b[32m   3276\u001b[39m     time_start = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     model_names_trained = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_initial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3279\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_prune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_prune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3286\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3288\u001b[39m     n_repeat_start = n_repeats_initial\n\u001b[32m   3289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:2872\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_initial\u001b[39m\u001b[34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[39m\n\u001b[32m   2870\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2871\u001b[39m     time_ratio = hpo_time_ratio \u001b[38;5;28;01mif\u001b[39;00m hpo_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2872\u001b[39m     models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2882\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2883\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2885\u001b[39m multi_fold_time_elapsed = time.time() - multi_fold_time_start\n\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:3029\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_fold\u001b[39m\u001b[34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, fit_strategy, **kwargs)\u001b[39m\n\u001b[32m   3026\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_early_stop:\n\u001b[32m   3027\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m models_valid\n\u001b[32m-> \u001b[39m\u001b[32m3029\u001b[39m         models_valid += \u001b[43m_detached_train_multi_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_self\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_limit_model_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit_model_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m fit_strategy == \u001b[33m\"\u001b[39m\u001b[33mparallel\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3043\u001b[39m     models_valid = \u001b[38;5;28mself\u001b[39m._train_multi_fold_parallel(\n\u001b[32m   3044\u001b[39m         X=X,\n\u001b[32m   3045\u001b[39m         y=y,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3052\u001b[39m         **kwargs,\n\u001b[32m   3053\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:4624\u001b[39m, in \u001b[36m_detached_train_multi_fold\u001b[39m\u001b[34m(_self, model, X, y, time_split, time_start, time_limit, time_limit_model_split, hyperparameter_tune_kwargs, is_ray_worker, kwargs)\u001b[39m\n\u001b[32m   4621\u001b[39m         time_start_model=time.time()\n\u001b[32m   4622\u001b[39m         time_left=time_limit-(time_start_model-time_start)\n\u001b[32m-> \u001b[39m\u001b[32m4624\u001b[39m model_name_trained_lst = \u001b[43m_self\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train_single_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4626\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4634\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self.low_memory:\n\u001b[32m   4635\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:2645\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_single_full\u001b[39m\u001b[34m(self, X, y, model, X_unlabeled, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, label_cleaner, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m         bagged_model_fit_kwargs = \u001b[38;5;28mself\u001b[39m._get_bagged_model_fit_kwargs(\n\u001b[32m   2642\u001b[39m             k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start\n\u001b[32m   2643\u001b[39m         )\n\u001b[32m   2644\u001b[39m         model_fit_kwargs.update(bagged_model_fit_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2645\u001b[39m     model_names_trained = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_and_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors_ignore\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors_ignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors_raise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks \u001b[38;5;129;01mand\u001b[39;00m check_callbacks:\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28mself\u001b[39m._callbacks_after_fit(model_names=model_names_trained, stack_name=stack_name, level=level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:2201\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_and_save\u001b[39m\u001b[34m(self, X, y, model, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, time_limit, stack_name, level, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, **model_fit_kwargs)\u001b[39m\n\u001b[32m   2199\u001b[39m exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2201\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2203\u001b[39m     fit_end_time = time.time()\n\u001b[32m   2204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight_evaluation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py:2085\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_single\u001b[39m\u001b[34m(self, X, y, model, X_val, y_val, X_test, y_test, total_resources, **model_fit_kwargs)\u001b[39m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train_single\u001b[39m(\n\u001b[32m   2070\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2071\u001b[39m     X: pd.DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2079\u001b[39m     **model_fit_kwargs,\n\u001b[32m   2080\u001b[39m ) -> AbstractModel:\n\u001b[32m   2081\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2082\u001b[39m \u001b[33;03m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[32m   2083\u001b[39m \u001b[33;03m    Returns trained model object.\u001b[39;00m\n\u001b[32m   2084\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2085\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2086\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py:1125\u001b[39m, in \u001b[36mAbstractModel.fit\u001b[39m\u001b[34m(self, log_resources, log_resources_prefix, **kwargs)\u001b[39m\n\u001b[32m   1123\u001b[39m             torch_cudnn_deterministic_og = torch.backends.cudnn.deterministic\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1127\u001b[39m         out = \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:270\u001b[39m, in \u001b[36mStackerEnsembleModel._fit\u001b[39m\u001b[34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    269\u001b[39m     time_limit = time_limit - (time.time() - start_time)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:393\u001b[39m, in \u001b[36mBaggedEnsembleModel._fit\u001b[39m\u001b[34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[39m\n\u001b[32m    391\u001b[39m         \u001b[38;5;66;03m# Reserve time for final refit model\u001b[39;00m\n\u001b[32m    392\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] * folds_to_fit / (folds_to_fit + \u001b[32m1.2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_folds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_bag_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# FIXME: Cleanup self\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m refit_folds:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:887\u001b[39m, in \u001b[36mBaggedEnsembleModel._fit_folds\u001b[39m\u001b[34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_fit_args \u001b[38;5;129;01min\u001b[39;00m fold_fit_args_list:\n\u001b[32m    886\u001b[39m     fold_fitting_strategy.schedule_fold_model_fit(**fold_fit_args)\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[43mfold_fitting_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_all_folds_scheduled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Do this to maintain model name order based on kfold split regardless of which model finished first in parallel mode\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_fit_args \u001b[38;5;129;01min\u001b[39;00m fold_fit_args_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:796\u001b[39m, in \u001b[36mParallelFoldFittingStrategy.after_all_folds_scheduled\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_pseudo_sequential(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_base_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_node_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:710\u001b[39m, in \u001b[36mParallelFoldFittingStrategy._run_parallel\u001b[39m\u001b[34m(self, X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\u001b[39m\n\u001b[32m    708\u001b[39m unfinished = job_refs\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished:\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     finished, unfinished = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43munfinished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m     finished = finished[\u001b[32m0\u001b[39m]\n\u001b[32m    712\u001b[39m     fold_ctx = job_fold_map.get(finished, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/voteai/lib/python3.11/site-packages/ray/_private/worker.py:3213\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[39m\n\u001b[32m   3211\u001b[39m timeout = timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m10\u001b[39m**\u001b[32m6\u001b[39m\n\u001b[32m   3212\u001b[39m timeout_milliseconds = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3213\u001b[39m ready_ids, remaining_ids = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3218\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/_raylet.pyx:3172\u001b[39m, in \u001b[36mray._raylet.CoreWorker.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/includes/common.pxi:98\u001b[39m, in \u001b[36mray._raylet.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# [4] AutoGluon 앙상블 시작 (Deep Learning Only)\n",
    "print(\"\\n딥러닝 전용 AutoGluon 앙상블 최적화 시작...\")\n",
    "\n",
    "# 이전에 만든 고성능 OOF 점수를 피처로 사용\n",
    "train_ag = pd.DataFrame({\n",
    "    'custom_mlp': mlp_oof,\n",
    "    'custom_ft': ft_oof,\n",
    "    'target': y.values\n",
    "    })\n",
    "test_ag = pd.DataFrame({\n",
    "    'custom_mlp': mlp_test_preds, \n",
    "    'custom_ft': ft_test_preds\n",
    "    })\n",
    "\n",
    "# 딥러닝 계열 모델만 사용하도록 지정\n",
    "deep_learning_models = {\n",
    "    'NN_TORCH': {},           # PyTorch 기반 신경망\n",
    "    'FASTAI': {},             # FastAI 기반 신경망\n",
    "    'FT_TRANSFORMER': {},     # AutoGluon 내장 FT-Transformer\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label='target', \n",
    "    eval_metric='roc_auc'\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    hyperparameters=deep_learning_models, # 머신러닝 트리 모델 제외\n",
    "    presets='best_quality',               # 스태킹(Stacking) 활성화\n",
    "    num_gpus=1,                           # M1 Pro GPU 가속 활용 시도\n",
    "    time_limit=900,                       # 15분 정도 충분히 탐색\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# [5] 앙상블 리더보드에서 최고 AUC 값 가져오기\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "best_auc = leaderboard.iloc[0]['score_val'] \n",
    "print(f\"\\nDeep Learning Ensemble Best AUC: {best_auc:.4f}\")\n",
    "\n",
    "# [6] 최종 예측 및 파일 저장 (AUC 포함)\n",
    "# 최적의 앙상블 가중치 조합으로 예측\n",
    "final_probs = predictor.predict_proba(test_ag).iloc[:, 1]\n",
    "sample_sub = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n",
    "sample_sub[\"voted\"] = final_probs\n",
    "\n",
    "# 파일명에 딥러닝 앙상블임을 명시하고 AUC 포함\n",
    "file_name = f\"sub_DL_Ensemble_MLP_FT_AUC_{best_auc:.4f}.csv\"\n",
    "save_full_path = os.path.join(SUB_PATH, file_name)\n",
    "\n",
    "# 경로 생성 및 저장\n",
    "if not os.path.exists(SUB_PATH):\n",
    "    os.makedirs(SUB_PATH)\n",
    "\n",
    "sample_sub.to_csv(save_full_path, index=False)\n",
    "print(f\"\\n딥러닝 전용 제출 파일이 저장되었습니다: {save_full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369c7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voteai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
